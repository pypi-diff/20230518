# Comparing `tmp/axonius_api_client-5.0.3-py2.py3-none-any.whl.zip` & `tmp/axonius_api_client-5.0.4-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,18 +1,18 @@
-Zip file size: 907564 bytes, number of entries: 605
+Zip file size: 907724 bytes, number of entries: 605
 -rw-r--r--  2.0 unx     3139 b- defN 23-May-02 15:09 axonius_api_client/__init__.py
--rw-r--r--  2.0 unx    34635 b- defN 23-May-10 13:21 axonius_api_client/connect.py
+-rw-r--r--  2.0 unx    35191 b- defN 23-May-18 12:08 axonius_api_client/connect.py
 -rw-r--r--  2.0 unx     4025 b- defN 23-Apr-27 20:53 axonius_api_client/data.py
--rw-r--r--  2.0 unx    15429 b- defN 23-May-02 15:09 axonius_api_client/exceptions.py
+-rw-r--r--  2.0 unx    15664 b- defN 23-May-18 12:08 axonius_api_client/exceptions.py
 -rw-r--r--  2.0 unx     5153 b- defN 23-Mar-09 15:18 axonius_api_client/features.py
--rw-r--r--  2.0 unx    31439 b- defN 23-May-04 10:06 axonius_api_client/http.py
+-rw-r--r--  2.0 unx    32317 b- defN 23-May-18 12:08 axonius_api_client/http.py
 -rw-r--r--  2.0 unx    12568 b- defN 23-Apr-27 20:55 axonius_api_client/logs.py
 -rw-r--r--  2.0 unx    23869 b- defN 23-May-02 15:09 axonius_api_client/setup_env.py
--rw-r--r--  2.0 unx    76766 b- defN 23-May-10 11:49 axonius_api_client/tools.py
--rw-r--r--  2.0 unx     1021 b- defN 23-May-10 13:21 axonius_api_client/version.py
+-rw-r--r--  2.0 unx    77381 b- defN 23-May-18 12:08 axonius_api_client/tools.py
+-rw-r--r--  2.0 unx     1021 b- defN 23-May-18 12:08 axonius_api_client/version.py
 -rw-r--r--  2.0 unx     1368 b- defN 23-May-10 11:49 axonius_api_client/api/__init__.py
 -rw-r--r--  2.0 unx    19821 b- defN 23-May-10 11:49 axonius_api_client/api/api_endpoint.py
 -rw-r--r--  2.0 unx    54346 b- defN 23-May-10 11:49 axonius_api_client/api/api_endpoints.py
 -rw-r--r--  2.0 unx     3284 b- defN 23-May-04 07:13 axonius_api_client/api/mixins.py
 -rw-r--r--  2.0 unx      161 b- defN 21-Dec-14 21:37 axonius_api_client/api/adapters/__init__.py
 -rw-r--r--  2.0 unx    25244 b- defN 23-May-02 15:09 axonius_api_client/api/adapters/adapters.py
 -rw-r--r--  2.0 unx    46857 b- defN 23-May-04 07:14 axonius_api_client/api/adapters/cnx.py
@@ -128,15 +128,15 @@
 -rw-r--r--  2.0 unx     3987 b- defN 23-Apr-27 20:24 axonius_api_client/api/system/activity_logs.py
 -rw-r--r--  2.0 unx    11606 b- defN 23-May-02 15:09 axonius_api_client/api/system/dashboard.py
 -rw-r--r--  2.0 unx    14794 b- defN 23-Apr-21 17:55 axonius_api_client/api/system/dashboard_spaces.py
 -rw-r--r--  2.0 unx    12622 b- defN 23-Apr-27 20:24 axonius_api_client/api/system/data_scopes.py
 -rw-r--r--  2.0 unx    28157 b- defN 23-May-03 15:58 axonius_api_client/api/system/instances.py
 -rw-r--r--  2.0 unx     3778 b- defN 23-May-02 15:09 axonius_api_client/api/system/meta.py
 -rw-r--r--  2.0 unx     3966 b- defN 23-Apr-27 20:25 axonius_api_client/api/system/remote_support.py
--rw-r--r--  2.0 unx    21550 b- defN 23-May-03 15:58 axonius_api_client/api/system/settings.py
+-rw-r--r--  2.0 unx    21550 b- defN 23-May-18 12:08 axonius_api_client/api/system/settings.py
 -rw-r--r--  2.0 unx     6590 b- defN 23-May-02 15:09 axonius_api_client/api/system/signup.py
 -rw-r--r--  2.0 unx    19278 b- defN 23-Apr-27 20:25 axonius_api_client/api/system/system_roles.py
 -rw-r--r--  2.0 unx    19313 b- defN 23-May-02 15:09 axonius_api_client/api/system/system_users.py
 -rw-r--r--  2.0 unx      236 b- defN 21-Dec-14 21:37 axonius_api_client/api/wizards/__init__.py
 -rw-r--r--  2.0 unx    22147 b- defN 23-May-02 15:09 axonius_api_client/api/wizards/wizard.py
 -rw-r--r--  2.0 unx    12635 b- defN 23-May-02 15:09 axonius_api_client/api/wizards/wizard_csv.py
 -rw-r--r--  2.0 unx     4997 b- defN 23-May-02 15:09 axonius_api_client/api/wizards/wizard_text.py
@@ -356,15 +356,15 @@
 -rw-r--r--  2.0 unx      677 b- defN 23-Apr-27 20:42 axonius_api_client/cli/grp_tools/cmd_write_config.py
 -rw-r--r--  2.0 unx     2101 b- defN 23-Mar-10 18:37 axonius_api_client/cli/grp_tools/grp_common.py
 -rw-r--r--  2.0 unx      554 b- defN 23-Mar-10 18:37 axonius_api_client/cli/grp_tools/grp_options.py
 -rw-r--r--  2.0 unx      334 b- defN 23-May-02 15:09 axonius_api_client/constants/__init__.py
 -rw-r--r--  2.0 unx     2973 b- defN 23-May-02 15:09 axonius_api_client/constants/adapters.py
 -rw-r--r--  2.0 unx     2868 b- defN 23-May-06 11:18 axonius_api_client/constants/api.py
 -rw-r--r--  2.0 unx    18484 b- defN 23-May-03 15:58 axonius_api_client/constants/asset_helpers.py
--rw-r--r--  2.0 unx     1258 b- defN 23-May-04 10:06 axonius_api_client/constants/ctypes.py
+-rw-r--r--  2.0 unx      998 b- defN 23-May-18 12:08 axonius_api_client/constants/ctypes.py
 -rw-r--r--  2.0 unx     5056 b- defN 23-Apr-27 20:53 axonius_api_client/constants/enforcements.py
 -rw-r--r--  2.0 unx    38018 b- defN 23-May-10 11:49 axonius_api_client/constants/fields.py
 -rw-r--r--  2.0 unx     2669 b- defN 23-May-02 15:09 axonius_api_client/constants/general.py
 -rw-r--r--  2.0 unx     4180 b- defN 23-May-02 15:09 axonius_api_client/constants/logs.py
 -rw-r--r--  2.0 unx     1151 b- defN 22-Mar-30 12:19 axonius_api_client/constants/tables.py
 -rw-r--r--  2.0 unx    15197 b- defN 23-May-02 15:09 axonius_api_client/constants/wizards.py
 -rw-r--r--  2.0 unx      119 b- defN 21-Dec-14 21:37 axonius_api_client/examples/__init__.py
@@ -589,19 +589,19 @@
 -rw-r--r--  2.0 unx       42 b- defN 21-Dec-14 21:37 axonius_api_client/tests/tests_cli/tests_grp_tools/__init__.py
 -rw-r--r--  2.0 unx     5082 b- defN 23-May-02 15:09 axonius_api_client/tests/tests_cli/tests_grp_tools/test_cmd_shell.py
 -rw-r--r--  2.0 unx      995 b- defN 23-Mar-09 15:18 axonius_api_client/tests/tests_cli/tests_grp_tools/test_cmd_sysinfo.py
 -rw-r--r--  2.0 unx     1271 b- defN 23-Apr-27 21:15 axonius_api_client/tests/tests_cli/tests_grp_tools/test_cmd_write_config.py
 -rw-r--r--  2.0 unx       42 b- defN 21-Dec-14 21:37 axonius_api_client/tests/tests_pkg/__init__.py
 -rw-r--r--  2.0 unx     6783 b- defN 23-May-02 15:09 axonius_api_client/tests/tests_pkg/test_connect.py
 -rw-r--r--  2.0 unx     2481 b- defN 23-Mar-09 15:18 axonius_api_client/tests/tests_pkg/test_data.py
--rw-r--r--  2.0 unx     9914 b- defN 23-May-02 15:09 axonius_api_client/tests/tests_pkg/test_http.py
+-rw-r--r--  2.0 unx    10027 b- defN 23-May-18 12:08 axonius_api_client/tests/tests_pkg/test_http.py
 -rw-r--r--  2.0 unx     4045 b- defN 23-Apr-21 17:55 axonius_api_client/tests/tests_pkg/test_logs.py
 -rw-r--r--  2.0 unx     8318 b- defN 23-May-02 15:09 axonius_api_client/tests/tests_pkg/test_setup_env.py
 -rw-r--r--  2.0 unx    42244 b- defN 23-May-02 15:09 axonius_api_client/tests/tests_pkg/test_tools.py
 -rw-r--r--  2.0 unx     3189 b- defN 23-May-02 15:09 axonius_api_client/tests/tests_pkg/test_url_parser.py
--rw-r--r--  2.0 unx     1064 b- defN 23-May-10 13:21 axonius_api_client-5.0.3.dist-info/LICENSE
--rw-r--r--  2.0 unx     2767 b- defN 23-May-10 13:21 axonius_api_client-5.0.3.dist-info/METADATA
--rw-r--r--  2.0 unx      110 b- defN 23-May-10 13:21 axonius_api_client-5.0.3.dist-info/WHEEL
--rw-r--r--  2.0 unx       57 b- defN 23-May-10 13:21 axonius_api_client-5.0.3.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       19 b- defN 23-May-10 13:21 axonius_api_client-5.0.3.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    69263 b- defN 23-May-10 13:21 axonius_api_client-5.0.3.dist-info/RECORD
-605 files, 3438137 bytes uncompressed, 791658 bytes compressed:  77.0%
+-rw-r--r--  2.0 unx     1064 b- defN 23-May-18 12:14 axonius_api_client-5.0.4.dist-info/LICENSE
+-rw-r--r--  2.0 unx     2767 b- defN 23-May-18 12:14 axonius_api_client-5.0.4.dist-info/METADATA
+-rw-r--r--  2.0 unx      110 b- defN 23-May-18 12:14 axonius_api_client-5.0.4.dist-info/WHEEL
+-rw-r--r--  2.0 unx       57 b- defN 23-May-18 12:14 axonius_api_client-5.0.4.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       19 b- defN 23-May-18 12:14 axonius_api_client-5.0.4.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    69263 b- defN 23-May-18 12:14 axonius_api_client-5.0.4.dist-info/RECORD
+605 files, 3440274 bytes uncompressed, 791818 bytes compressed:  77.0%
```

## zipnote {}

```diff
@@ -1791,26 +1791,26 @@
 
 Filename: axonius_api_client/tests/tests_pkg/test_tools.py
 Comment: 
 
 Filename: axonius_api_client/tests/tests_pkg/test_url_parser.py
 Comment: 
 
-Filename: axonius_api_client-5.0.3.dist-info/LICENSE
+Filename: axonius_api_client-5.0.4.dist-info/LICENSE
 Comment: 
 
-Filename: axonius_api_client-5.0.3.dist-info/METADATA
+Filename: axonius_api_client-5.0.4.dist-info/METADATA
 Comment: 
 
-Filename: axonius_api_client-5.0.3.dist-info/WHEEL
+Filename: axonius_api_client-5.0.4.dist-info/WHEEL
 Comment: 
 
-Filename: axonius_api_client-5.0.3.dist-info/entry_points.txt
+Filename: axonius_api_client-5.0.4.dist-info/entry_points.txt
 Comment: 
 
-Filename: axonius_api_client-5.0.3.dist-info/top_level.txt
+Filename: axonius_api_client-5.0.4.dist-info/top_level.txt
 Comment: 
 
-Filename: axonius_api_client-5.0.3.dist-info/RECORD
+Filename: axonius_api_client-5.0.4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## axonius_api_client/connect.py

```diff
@@ -1,21 +1,18 @@
-# -*- coding: utf-8 -*-
 """Easy all-in-one connection handler."""
 import logging
 import logging.handlers
 import platform
 import re
 import types
 import typing as t
 
 import requests
 
 from . import api, logs, tools, version
-from .projects import cert_human
-from .projects.cf_token import constants as cf_constants
 from .auth import AuthApiKey, AuthCredentials, AuthModel, AuthNull
 from .constants.ctypes import PathLike
 from .constants.logs import (
     LOG_FILE_MAX_FILES,
     LOG_FILE_MAX_MB,
     LOG_FILE_NAME,
     LOG_FILE_PATH,
@@ -26,14 +23,16 @@
     LOG_LEVEL_CONSOLE,
     LOG_LEVEL_ENDPOINTS,
     LOG_LEVEL_FILE,
     LOG_LEVEL_PACKAGE,
 )
 from .exceptions import ConnectError, InvalidCredentials
 from .http import Http, T_Cookies, T_Headers
+from .projects import cert_human
+from .projects.cf_token import constants as cf_constants
 from .setup_env import get_env_ax
 
 
 class Connect:
     """Easy all-in-one connection handler for using the API client.
 
     Examples:
@@ -92,39 +91,39 @@
 
     TOOLS: types.ModuleType = tools
     """Tools module."""
 
     LOG_LOGGER: logging.Logger = logs.LOG
     """Logger for the entire package, where console and file output handlers will be attached to."""
 
-    LOG: logging.Logger = None
+    LOG: t.Optional[logging.Logger] = None
     """Logger for this class."""
 
     LOG_HTTP_MAX: bool = False
     """Shortcut to include_output ALL http logging *warning: very heavy log output*."""
 
     STARTED: bool = False
     """Flag to indicate if client has been started."""
 
     WRAPERROR: bool = True
     """Flag to indicate if client should wrap exceptions."""
 
-    _url: str = None
+    _url: str = ""
     """Initially supplied URL of the Axonius instance."""
 
-    ARGS_HANDLER_CON: dict = None
+    ARGS_HANDLER_CON: dict = {}
     """Arguments to use when setting up console logging."""
 
-    ARGS_HANDLER_FILE: dict = None
+    ARGS_HANDLER_FILE: dict = {}
     """Arguments to use when setting up file logging."""
 
-    ARGS_API: dict = None
+    ARGS_API: dict = {}
     """Arguments to use when setting up models."""
 
-    ARGS_ORIG: dict = None
+    ARGS_ORIG: dict = {}
     """Original arguments supplied to the constructor."""
 
     HANDLER_CON: t.Optional[logging.StreamHandler] = None
     """Console logging handler."""
 
     HANDLER_FILE: t.Optional[logging.handlers.RotatingFileHandler] = None
     """File logging handler."""
@@ -200,15 +199,15 @@
 log_body_lines = 10000
 """
     """Override values used when log_http_max is True."""
 
     HTTP_MAX_CLI: str = ", ".join(HTTP_MAX.splitlines())
     """CLI Help string for log_http_max."""
 
-    def __init__(
+    def __init__(  # noqa: PLR0913
         self,
         url: str,
         key: str,
         secret: str,
         log_console: bool = False,
         log_file: bool = False,
         log_file_rotate: bool = False,
@@ -261,16 +260,16 @@
         cf_error_login: bool = cf_constants.FLOW_ERROR,
         cf_error_access: bool = cf_constants.FLOW_ERROR,
         cf_timeout_access: t.Optional[int] = cf_constants.TIMEOUT_ACCESS,
         cf_timeout_login: t.Optional[int] = cf_constants.TIMEOUT_LOGIN,
         http: t.Optional[Http] = None,
         auth: t.Optional[AuthModel] = None,
         auth_null: t.Optional[AuthModel] = None,
-        **kwargs,
-    ):
+        **kwargs: t.Dict[str, t.Any],
+    ) -> None:
         """Easy all-in-one connection handler.
 
         Args:
             url: URL, hostname, or IP address of Axonius instance
             key: API Key from account page in Axonius instance
             secret: API Secret from account page in Axonius instance
             log_console: include_output logging to console
@@ -304,14 +303,15 @@
             log_level_file: log level to use for file loggers
             log_console_fmt: format string to use for console logging
             log_file_fmt: format string to use for file logging
             log_file_name: name of file to log to
             log_file_path: path to directory to log to
             log_file_max_mb: max size of log file in MB
             log_file_max_files: max number of log files to keep
+            log_file_rotate: rotate log file on startup
             log_body_lines: max length of request/response body to log
             log_hide_secrets: hide secrets in logs
             log_http_max: Shortcut to include_output ALL http logging *warning: heavy log output*
             wraperror: wrap certain errors in a more user friendly format
             cf_url: URL to use in `access token` and `access login` commands,
                 will fallback to url if not supplied
             cf_token: access token supplied by user, will be checked for validity if not empty
@@ -351,15 +351,16 @@
             log_level_http = "debug"
             log_level_package = "debug"
             log_level_console = "debug"
             log_level_file = "debug"
             log_request_attrs = "all"
             log_response_attrs = "all"
             if not isinstance(log_body_lines, int) or (
-                isinstance(log_body_lines, int) and log_body_lines < 10000
+                isinstance(log_body_lines, int)
+                and log_body_lines < 10000  # noqa: PLR2004
             ):
                 log_body_lines = 10000
 
         self.ARGS_HANDLER_CON: dict = {
             "obj": log_logger,
             "level": log_level_console,
             "fmt": log_console_fmt,
@@ -415,27 +416,28 @@
         self.set_log_level_package(value=log_level_package)
         self.set_log_level_endpoints(value=log_level_endpoints)
         self.control_log_file(enable=log_file, rotate=log_file_rotate)
         self.control_log_console(enable=log_console)
         self.HTTP = self.http = self._init_http(http=http)
         self.AUTH = self.auth = self._init_auth(auth=auth, log_level=log_level_auth)
         self.AUTH_NULL: AuthModel = self._init_auth_null(
-            auth_null=auth_null, log_level=log_level_auth
+            auth_null=auth_null,
+            log_level=log_level_auth,
         )
         self._init()
 
-    def start(self):
+    def start(self) -> None:
         """Connect to and authenticate with Axonius."""
         if not self.STARTED:
             sysinfo_dump: dict = tools.sysinfo()
             self.LOG.debug(f"SYSTEM INFO: {tools.json_dump(sysinfo_dump)}")
 
             try:
                 self.AUTH.login()
-            except Exception as exc:
+            except Exception as exc:  # noqa: BLE001
                 if not self.WRAPERROR:
                     raise
 
                 pre = f"Unable to connect to {self.url!r}"
                 connect_exc = ConnectError(f"{pre}: {exc}")
 
                 if isinstance(exc, requests.ConnectTimeout):
@@ -445,15 +447,15 @@
                 elif isinstance(exc, requests.ConnectionError):
                     reason = self._get_exc_reason(exc=exc)
                     connect_exc = ConnectError(f"{pre}: {reason}")
                 elif isinstance(exc, InvalidCredentials):
                     connect_exc = ConnectError(f"{pre}: Invalid Credentials supplied")
 
                 connect_exc.exc = exc
-                raise connect_exc
+                raise connect_exc from exc
 
             self.STARTED = True
             self.LOG.info(str(self))
 
     # --> MODELS
     @property
     def activity_logs(self) -> api.ActivityLogs:
@@ -556,69 +558,78 @@
         return self._get_model(model=api.Users)
 
     @property
     def vulnerabilities(self) -> api.Vulnerabilities:
         """Work with vulnerability assets."""
         return self._get_model(model=api.Vulnerabilities)
 
-    def set_wraperror(self, value: bool = True):
+    def set_wraperror(self, value: bool = True) -> None:
         """Set whether to wrap errors in a more user-friendly format."""
         self.WRAPERROR = tools.coerce_bool(value)
 
     # <-- METHODS
 
     @staticmethod
-    def set_log_hide_secrets(value: bool = True):
+    def set_log_hide_secrets(value: bool = True) -> None:
         """Set whether to hide secrets in logs."""
         logs.HideFormatter.HIDE_ENABLED = tools.coerce_bool(value)
 
-    def set_log_level_console(self, value: t.Union[str, int] = LOG_LEVEL_CONSOLE):
+    def set_log_level_console(
+        self,
+        value: t.Union[str, int] = LOG_LEVEL_CONSOLE,
+    ) -> None:
         """Set the log level for this client's console output."""
         if isinstance(self.ARGS_HANDLER_CON, dict):
             self.ARGS_HANDLER_CON["level"] = logs.str_level(value)
         if self.HANDLER_CON:
             logs.set_log_level(obj=self.HANDLER_CON, level=value)
 
-    def set_log_level_file(self, value: t.Union[str, int] = LOG_LEVEL_FILE):
+    def set_log_level_file(self, value: t.Union[str, int] = LOG_LEVEL_FILE) -> None:
         """Set the log level for this client's file output."""
         if isinstance(self.ARGS_HANDLER_FILE, dict):
             self.ARGS_HANDLER_FILE["level"] = logs.str_level(value)
         if self.HANDLER_FILE:
             logs.set_log_level(obj=self.HANDLER_FILE, level=value)
 
-    def set_log_level_api(self, value: t.Union[str, int] = LOG_LEVEL_API):
+    def set_log_level_api(self, value: t.Union[str, int] = LOG_LEVEL_API) -> None:
         """Set the log level for this client's api objects."""
         self.API_LOG_LEVEL: str = logs.str_level(value)
         for obj in self.API_CACHE.values():
             if isinstance(obj, api.ModelMixins):
                 logs.set_log_level(obj=obj.LOG, level=self.API_LOG_LEVEL)
 
-    def set_log_level_connect(self, value: t.Union[str, int] = "debug"):
+    def set_log_level_connect(self, value: t.Union[str, int] = "debug") -> None:
         """Set the log level for this client."""
-        logs.set_log_level(obj=self.LOG, level=value)
+        if self.LOG:
+            logs.set_log_level(obj=self.LOG, level=value)
 
-    def set_log_level_http(self, value: t.Union[str, int] = Http.LOG_LEVEL):
+    def set_log_level_http(self, value: t.Union[str, int] = Http.LOG_LEVEL) -> None:
         """Set the log level for this client's http object."""
         if isinstance(self.HTTP, Http):
             logs.set_log_level(obj=self.HTTP.LOG, level=value)
 
-    def set_log_level_auth(self, value: t.Union[str, int] = LOG_LEVEL_AUTH):
+    def set_log_level_auth(self, value: t.Union[str, int] = LOG_LEVEL_AUTH) -> None:
         """Set the log level for this client's auth objects."""
         for obj in self.AUTH, self.AUTH_NULL:
             if isinstance(obj, AuthModel):
                 logs.set_log_level(obj=obj.LOG, level=value)
 
-    def set_log_level_package(self, value: t.Union[str, int] = LOG_LEVEL_PACKAGE):
+    def set_log_level_package(
+        self,
+        value: t.Union[str, int] = LOG_LEVEL_PACKAGE,
+    ) -> None:
         """Set the log level for this client's package."""
         logs.set_log_level(obj=self.LOG_LOGGER, level=value)
 
     @staticmethod
-    def set_log_level_endpoints(value: t.Union[str, int] = LOG_LEVEL_ENDPOINTS):
+    def set_log_level_endpoints(value: t.Union[str, int] = LOG_LEVEL_ENDPOINTS) -> None:
         """Set the log level for this client's endpoints."""
-        from .api.api_endpoint import LOGGER as LOGGER_ENDPOINT
+        from axonius_api_client.api.api_endpoint import (
+            LOGGER as LOGGER_ENDPOINT,
+        )
 
         logs.set_log_level(obj=LOGGER_ENDPOINT, level=value)
 
     def control_log_console(self, enable: bool = False) -> bool:
         """Add logging to console for this client."""
         enable = tools.coerce_bool(enable)
         if enable and not self.HANDLER_CON:
@@ -645,25 +656,26 @@
             self.LOG.debug("Logging to file disabled.")
             self.HANDLER_FILE.close()
             logs.del_file(obj=self.LOG_LOGGER)
             self.HANDLER_FILE = None
             return True
         return False
 
-    def rotate_log_files(self, value: bool = False):
+    def rotate_log_files(self, value: bool = False) -> None:
         """Rollover log file."""
         value = tools.coerce_bool(value)
         if value and self.HANDLER_FILE:
             self.LOG.debug("Forcing file logs to rotate")
             self.HANDLER_FILE.flush()
             try:
                 self.HANDLER_FILE.doRollover()
-                self.LOG.debug("Forced file logs to rotate")
-            except Exception as exc:  # pragma: no cover
+            except Exception as exc:  # pragma: no cover  # noqa: BLE001
                 self.LOG.exception("Failed to force file logs to rotate: %s", exc)
+            else:
+                self.LOG.debug("Forced file logs to rotate")
 
     @property
     def url(self) -> str:
         """Get the URL of the current instance."""
         return self.HTTP.url if self.HTTP else self._url
 
     @property
@@ -672,33 +684,37 @@
         return self.AUTH.get_api_keys()
 
     @property
     def current_user(self) -> t.Optional[api.json_api.account.CurrentUser]:
         """Get the current user (returns 404 for service accounts)."""
         try:
             return self.AUTH.get_current_user()
-        except Exception:
+        except Exception:  # noqa: BLE001
             return None
 
     @property
-    def about(self):
+    def about(self) -> dict:
         """Cached data from the /about endpoint."""
         if self.ABOUT_CACHE:
             return self.ABOUT_CACHE
         value = self.meta.about(error=False)
         if value:
             self.ABOUT_CACHE = value
         return value
 
     @property
     def version(self) -> str:
         """Get the Axonius instance version."""
         data = "none yet"
         if self.STARTED:
-            data = self.about.get("Version") or self.about.get("Installed Version") or "DEMO"
+            data = (
+                self.about.get("Version")
+                or self.about.get("Installed Version")
+                or "DEMO"
+            )
             data = data.replace("_", ".")
         return data
 
     @property
     def build_date(self) -> str:
         """Get the Axonius instance build date."""
         data = "none yet"
@@ -706,23 +722,24 @@
             data = self.about.get("Build Date", "UNKNOWN")
         return data
 
     @property
     def str_ax_version(self) -> str:
         """Get the Axonius instance version & build date for use in str."""
         days = f"({tools.dt_days_ago(self.build_date)} days ago)"
-        return f"Axonius Version {self.version!r}, Build Date: {self.build_date!r} {days}"
+        return (
+            f"Axonius Version {self.version!r}, Build Date: {self.build_date!r} {days}"
+        )
 
     @property
     def str_ax_user(self) -> str:
         """Get the Axonius instance user for use in str."""
         value = "User: ??"
-        if self.STARTED:
-            if self.current_user:
-                value = self.current_user.str_connect
+        if self.STARTED and self.current_user:
+            value = self.current_user.str_connect
         return value
 
     @property
     def ssl_days_left(self) -> t.Optional[int]:
         """Get the number of days left until the SSL certificate expires."""
         value = None
         if isinstance(self.HTTP, Http):
@@ -734,16 +751,16 @@
     @property
     def str_ax_cert(self) -> str:
         """Get the Axonius instance SSL certificate for use in str."""
         value = "SSL: ??"
         if isinstance(self.HTTP, Http):
             cert: t.Optional[cert_human.Cert] = self.HTTP.get_cert()
             if isinstance(cert, cert_human.Cert):
-                dt = str(cert.not_valid_after)
-                value = f"SSL Issued To: {cert.subject_short!r}, Expires On: {dt!r}"
+                not_valid_after = str(cert.not_valid_after)
+                value = f"SSL Issued To: {cert.subject_short!r}, Expires On: {not_valid_after!r}"
         return value
 
     @property
     def str_state(self) -> str:
         """Get the connection state for use in str."""
         value = "Not connected"
         if self.STARTED:
@@ -785,28 +802,29 @@
                 return reason_re.sub(r"\1", reason).rstrip("')")
         return reason
 
     def _check_binding(self, value: t.Any) -> t.Any:
         """Check if an object is already bound to a different client."""
         client = getattr(value, "CLIENT", value)
         if isinstance(client, self.__class__) and client is not self:
-            raise ConnectError(
-                f"{value} is already set to {client!r} and cannot be set to {self!r}"
-            )
-        setattr(value, "CLIENT", self)
+            err = f"{value} is already set to {client!r} and cannot be set to {self!r}"
+            raise ConnectError(err)
+        value.CLIENT = self
         return value
 
     def _init_http(self, http: t.Optional[Http] = None) -> Http:
         """Initialize the HTTP object."""
         if not isinstance(http, Http):
             http: Http = Http(**self.ARGS_HTTP)
         return self._check_binding(http)
 
     def _init_auth(
-        self, auth: t.Optional[AuthModel] = None, log_level: t.Union[str, int] = LOG_LEVEL_AUTH
+        self,
+        auth: t.Optional[AuthModel] = None,
+        log_level: t.Union[str, int] = LOG_LEVEL_AUTH,
     ) -> AuthModel:
         """Initialize the Auth object."""
         if not isinstance(auth, AuthModel):
             if self.CREDENTIALS:
                 auth: AuthCredentials = AuthCredentials(
                     username=self.__key,
                     password=self.__secret,
@@ -819,26 +837,31 @@
                     secret=self.__secret,
                     http=self.http,
                     log_level=log_level,
                 )
         return self._check_binding(auth)
 
     def _init_auth_null(
-        self, auth_null: t.Optional[AuthModel] = None, log_level: t.Union[str, int] = LOG_LEVEL_AUTH
+        self,
+        auth_null: t.Optional[AuthModel] = None,
+        log_level: t.Union[str, int] = LOG_LEVEL_AUTH,
     ) -> AuthModel:
         """Initialize the null Auth object."""
         if not isinstance(auth_null, AuthModel):
             auth_null: AuthNull = AuthNull(http=self.http, log_level=log_level)
         return self._check_binding(auth_null)
 
     def _init(self):
         """Custom init for this class."""
 
     def _get_model(
-        self, model: t.Type[api.ModelMixins], start: bool = True, auth: t.Optional[AuthModel] = None
+        self,
+        model: t.Type[api.ModelMixins],
+        start: bool = True,
+        auth: t.Optional[AuthModel] = None,
     ) -> t.Any:
         """Create or get an API model.
 
         Args:
             model: model to create or get
             start: start :attr:`AUTH` if not already started
             auth: auth to use for this model, if not supplied default to :attr:`AUTH`
```

## axonius_api_client/exceptions.py

```diff
@@ -1,8 +1,7 @@
-# -*- coding: utf-8 -*-
 """Exceptions and warnings."""
 import typing as t
 
 import requests
 
 
 def get_exc_str(exc: t.Optional[Exception] = None) -> str:
@@ -31,15 +30,15 @@
 class UnknownFieldSchema(ApiWarning):
     """Warning for unknown field schema mappings."""
 
 
 class AxonError(Exception):
     """Base class for all exceptions in this package."""
 
-    def __init__(self, msg: t.Union[str, t.List[t.Any]]):
+    def __init__(self, msg: t.Union[str, t.List[t.Any]]) -> None:
         """Pass."""
         if isinstance(msg, (list, tuple)):
             msg = "\n".join([str(x) for x in msg])
         super().__init__(msg)
 
 
 class AxonTypeError(AxonError):
@@ -48,15 +47,15 @@
     def __init__(
         self,
         attr: str,
         value: t.Any,
         expected: t.Any,
         src: t.Any = None,
         extra: t.Any = None,
-    ):
+    ) -> None:
         """Pass."""
         self.src: t.Any = src
         self.attr: str = attr
         self.value: t.Any = value
         self.expected: t.Any = expected
         self.extra: t.Any = extra
         err: str = f"Incorrect value type supplied to {attr!r}"
@@ -88,15 +87,15 @@
     def __init__(
         self,
         confirm: t.Any = False,
         prompt: t.Any = False,
         reason: t.Any = "",
         src: t.Any = None,
         extra: t.Any = None,
-    ):
+    ) -> None:
         """Pass."""
         self.confirm: t.Any = confirm
         self.reason: t.Any = reason
         msgs: t.List[str] = [
             f"Unable to {reason}",
             f"confirm is {confirm} and prompt is {prompt}, confirm must be {True}",
         ]
@@ -126,15 +125,15 @@
 class NotFoundError(ApiError):
     """Error when something is not found."""
 
 
 class SavedQueryNotFoundError(NotFoundError):
     """Error when something is not found."""
 
-    def __init__(self, details: str, sqs: t.List[t.Union[dict, object]]):
+    def __init__(self, details: str, sqs: t.List[t.Union[dict, object]]) -> None:
         """Pass."""
         from .parsers.tables import tablize_sqs
 
         self.sqs = sqs
         self.details = details
         self.msg = f"Saved Query not found with {details}"
         try:
@@ -146,22 +145,24 @@
             self.msg_table = tablize_sqs(data=sqs, err=self.msg)
         super().__init__(self.msg_table)
 
 
 class SavedQueryTagsNotFoundError(SavedQueryNotFoundError):
     """Error when something is not found."""
 
-    def __init__(self, value: t.List[str], valid: t.List[str]):
+    def __init__(self, value: t.List[str], valid: t.List[str]) -> None:
         """Pass."""
         self.value = value
         self.valid = valid
 
         value_txt = ", ".join(value)
         valid_txt = "\n" + "\n".join(valid)
-        self.msg = f"Saved Query not found with tags: {value_txt}, valid tags:{valid_txt}"
+        self.msg = (
+            f"Saved Query not found with tags: {value_txt}, valid tags:{valid_txt}"
+        )
         super(NotFoundError, self).__init__(self.msg)
 
 
 class AlreadyExists(ApiError):
     """Error when something exists with same name."""
 
 
@@ -223,16 +224,19 @@
     cnx_new: t.ClassVar[t.Optional[dict]] = None
 
 
 class ResponseError(ApiError):
     """Errors when checking responses."""
 
     def __init__(
-        self, msg: t.Optional[str] = None, response=None, exc: t.Optional[Exception] = None
-    ):
+        self,
+        msg: t.Optional[str] = None,
+        response=None,
+        exc: t.Optional[Exception] = None,
+    ) -> None:
         """Error in responses received from REST API.
 
         Args:
             response (:obj:`requests.Response`): response that originated the error
             msg: error message to include in exception
             exc: original exception that was thrown if any
         """
@@ -240,15 +244,18 @@
         self.exc: Exception = exc
         self.msg: str = msg
         self.errmsg: str = self.build_errmsg(response=response, msg=msg, exc=exc)
         super().__init__(self.errmsg)
 
     @classmethod
     def build_errmsg(
-        cls, response, msg: t.Optional[str] = None, exc: t.Optional[Exception] = None
+        cls,
+        response,
+        msg: t.Optional[str] = None,
+        exc: t.Optional[Exception] = None,
     ) -> str:
         """Build an error message from a response.
 
         Args:
             response (:obj:`requests.Response`): response that originated the error
             msg: error message to include in exception
             exc: exception that was thrown if any
@@ -318,25 +325,25 @@
 class NoTriggerDefinedError(ApiError):
     """Pass."""
 
 
 class StopFetch(ApiError):
     """Pass."""
 
-    def __init__(self, reason: str, state: dict):
+    def __init__(self, reason: str, state: dict) -> None:
         """Pass."""
         self.reason = reason
         self.state = state
         super().__init__(reason)
 
 
 class SchemaError(ApiError):
     """Pass."""
 
-    def __init__(self, obj, schema, exc, data):
+    def __init__(self, obj, schema, exc, data) -> None:
         """Pass."""
         from .tools import json_log, prettify_obj
 
         self.schema = schema
         self.exc = exc
         self.obj = obj
         self.data = data
@@ -369,15 +376,15 @@
 
     def __init__(
         self,
         api_endpoint,
         err: str,
         details: t.Optional[t.List[str]] = None,
         exc: t.Optional[Exception] = None,
-    ):
+    ) -> None:
         """Pass."""
         self.api_endpoint = api_endpoint
         self.err = err
         self.details = details or []
         self.exc = exc
         self.errors = [
             err,
@@ -419,15 +426,15 @@
 class ResponseLoadObjectError(RequestError):
     """Pass."""
 
 
 class FeatureNotEnabledError(ApiError):
     """Pass."""
 
-    def __init__(self, name: str, extra: t.Optional[str] = None):
+    def __init__(self, name: str, extra: t.Optional[str] = None) -> None:
         """Pass."""
         msg = (
             f"The {name} feature is not enabled on this instance, "
             "please contact support@axonius.com to enable"
         )
         if extra is not None:
             msg = f"{msg}:\n{extra}"
@@ -453,15 +460,15 @@
 class FolderAlreadyExistsError(AlreadyExists):
     """Error when something exists with same name."""
 
 
 class FolderNotFoundError(NotFoundError):
     """Error when something is not found."""
 
-    def __init__(self, msg: str, folder: t.Optional[object] = None):
+    def __init__(self, msg: str, folder: t.Optional[object] = None) -> None:
         """Pass."""
         self.folder: t.Optional[object] = folder
         super().__init__(msg)
 
 
 class SearchError(AxonError):
     """Pass."""
@@ -508,67 +515,77 @@
 
         self.value: bytes = value
         self.encoding_format: t.Optional[str] = encoding_format
         self.encoding_errors: t.Optional[str] = encoding_errors
         super().__init__(
             f"The input byte string {trim_value_repr(self.value)} cannot be decoded to a valid "
             f"ObjectId string using encoding_format {self.encoding_format!r} "
-            f" and encoding_errors {self.encoding_errors!r}."
+            f" and encoding_errors {self.encoding_errors!r}.",
         )
 
 
 class InvalidObjectIdError(ValueError, AxonError):
     """Raised when an input string is not a valid ObjectId.
 
     Attributes:
         value (str): The input string.
     """
 
-    def __init__(self, value: str):
+    def __init__(self, value: str) -> None:
         """Initialize a new instance of the InvalidObjectIdError exception.
 
         Args:
             value (str): The input string.
         """
         from .tools import trim_value_repr
 
         self.value: t.Any = value
-        super().__init__(f"The input string {trim_value_repr(self.value)} is not a valid ObjectId.")
+        super().__init__(
+            f"The input string {trim_value_repr(self.value)} is not a valid ObjectId.",
+        )
 
 
 class InvalidTypeError(TypeError, AxonError):
     """Raised when an input value is not one of the allowed types.
 
     Attributes:
         value (t.Any): The input value.
         allowed_types (t.Tuple[type]): The tuple of allowed types.
     """
 
-    def __init__(self, value: t.Any, allowed_types: t.Optional[t.Tuple[type]] = ()) -> None:
+    def __init__(
+        self,
+        value: t.Any,
+        allowed_types: t.Optional[t.Tuple[type]] = (),
+    ) -> None:
         """Initialize a new instance of the InvalidTypeError exception.
 
         Args:
             value (t.Any): The input value.
             allowed_types (t.Optional[t.Tuple[type]], optional): The tuple of allowed types.
         """
         self.value: t.Any = value
         self.allowed_types: t.Optional[t.Tuple[type]] = allowed_types
         from .tools import get_type_str
 
         super().__init__(
             f"The input value {self.value!r} type {get_type_str(self.value)} is not "
-            f"one of the allowed types: {get_type_str(allowed_types)}."
+            f"one of the allowed types: {get_type_str(allowed_types)}.",
         )
 
 
 class FormatError(KeyError, AxonError):
     """Raised when there is a KeyError in when doing a string formatting."""
 
     def __init__(
-        self, template: str, error: Exception, args: t.Any = None, kwargs: t.Dict[str, t.Any] = None
+        self,
+        template: str,
+        error: Exception,
+        args: t.Any = None,
+        kwargs: t.Dict[str, t.Any] = None,
     ) -> None:
         """Initialize a new instance of the FormatError exception.
 
         Args:
             template (str): The string template that had the problem.
             error (Exception): The original error that occurred.
             *args (t.Any): The args passed to the template
```

## axonius_api_client/http.py

```diff
@@ -1,46 +1,52 @@
-# -*- coding: utf-8 -*-
 """HTTP client."""
 import logging
 import pathlib
 import typing as t
 import warnings
 
-import OpenSSL
+import OpenSSL  # noqa: TCH002
 import requests
 import requests.cookies
 import requests.structures
 import urllib3
 import urllib3.exceptions
 
 from . import version
-from .projects import cert_human
-from .projects.cf_token import constants as cf_constants
-from .projects.cf_token.flows import flow_get_token
-from .projects.cf_token.tools import is_url, get_env_url
-from .projects.url_parser import UrlParser
 from .constants.api import TIMEOUT_CONNECT, TIMEOUT_RESPONSE
 from .constants.ctypes import PathLike, PatternLikeListy
-from .constants.logs import LOG_LEVEL_HTTP, MAX_BODY_LEN, REQUEST_ATTR_MAP, RESPONSE_ATTR_MAP
+from .constants.logs import (
+    LOG_LEVEL_HTTP,
+    MAX_BODY_LEN,
+    REQUEST_ATTR_MAP,
+    RESPONSE_ATTR_MAP,
+)
 from .exceptions import HttpError
 from .logs import get_obj_log, set_log_level
-
+from .projects import cert_human
+from .projects.cf_token import constants as cf_constants
+from .projects.cf_token.flows import flow_get_token
+from .projects.cf_token.tools import get_env_url, is_url
+from .projects.url_parser import UrlParser
 from .setup_env import get_env_user_agent
 from .tools import (
     coerce_bool,
     coerce_int_float,
     coerce_str,
     join_url,
     json_log,
     listify,
     path_read,
     tilde_re,
 )
 
-INJECT_RESULTS: t.Tuple[bool, t.List[str]] = cert_human.ssl_capture.inject_into_urllib3()
+INJECT_RESULTS: t.Tuple[
+    bool,
+    t.List[str],
+] = cert_human.ssl_capture.inject_into_urllib3()
 T_Cookies: t.Type = t.Union[dict, requests.cookies.RequestsCookieJar]
 T_Headers: t.Type = t.Union[dict, requests.structures.CaseInsensitiveDict]
 
 HIDE_HEADERS: t.Tuple[str, ...] = (
     "~cookie",
     "~auth",
     "~token",
@@ -161,15 +167,15 @@
     URL_CERT_CHAIN: t.Optional[t.List[cert_human.Cert]] = None
     """Cert chain for URL."""
 
     CLIENT: t.Optional[object] = None
     """Client object that created this object."""
     # TBD: Connect needs an interface for proper type hinting without circular reference
 
-    def __init__(
+    def __init__(  # noqa: PLR0913
         self,
         url: t.Union[UrlParser, str],
         certpath: t.Optional[PathLike] = None,
         certwarn: bool = CERT_WARN,
         certverify: bool = CERT_VERIFY,
         headers: t.Optional[T_Headers] = None,
         cookies: t.Optional[T_Cookies] = None,
@@ -202,15 +208,15 @@
         cf_echo_verbose: bool = cf_constants.FLOW_ECHO_VERBOSE,
         cf_error: bool = cf_constants.CLIENT_ERROR,
         cf_error_login: bool = cf_constants.FLOW_ERROR,
         cf_error_access: bool = cf_constants.FLOW_ERROR,
         cf_timeout_access: t.Optional[int] = cf_constants.TIMEOUT_ACCESS,
         cf_timeout_login: t.Optional[int] = cf_constants.TIMEOUT_LOGIN,
         **kwargs,
-    ):
+    ) -> None:
         """HTTP client that wraps around :obj:`requests.Session`.
 
         Notes:
             * If certpath is supplied, certverify is ignored
             * private key supplied to cert_client_key or cert_client_both
               can **NOT** be password encrypted
 
@@ -220,14 +226,17 @@
             certwarn: show insecure warning once or never show insecure warning
             certverify: raise exception if cert is self-signed or only if cert is invalid
             headers: headers to send with every request
             cookies: cookies to send with every request
             log_level: log level to use for this object
             log_body_lines: max length of request and response bodies to log
             log_hide_headers: headers to hide when logging
+            log_hide_str: string to use to hide sensitive data in logs
+            log_request_attrs: attributes of request to log
+            log_response_attrs: attributes of response to log
             save_last: save last request and response to :attr:`last_request` and
                 :attr:`last_response`
             save_history: save all requests and responses to :attr:`history`
             connect_timeout: seconds to wait for connections to open to :attr:`url`
             response_timeout: seconds to wait for responses from :attr:`url`
             log_request_body: log the request body
             log_response_body: log the response body
@@ -268,15 +277,18 @@
         self.LOG_LEVEL: t.Union[int, str] = log_level
         self.LOG: logging.Logger = get_obj_log(obj=self, level=self.LOG_LEVEL)
 
         self.HISTORY: t.List[requests.Response] = []
         self.LAST_REQUEST: t.Optional[requests.PreparedRequest] = None
         self.LAST_RESPONSE: t.Optional[requests.Response] = None
 
-        self.LOG_BODY_LINES: t.Optional[int] = coerce_int_float(log_body_lines, error=False)
+        self.LOG_BODY_LINES: t.Optional[int] = coerce_int_float(
+            log_body_lines,
+            error=False,
+        )
         self.LOG_HIDE_HEADERS: PatternLikeListy = tilde_re(listify(log_hide_headers))
         self.LOG_HIDE_STR: t.Optional[str] = log_hide_str
         self.LOG_LEVEL_URLLIB: str = log_level_urllib
         self.LOG_REQUEST_BODY: bool = coerce_bool(log_request_body)
         self.LOG_RESPONSE_BODY: bool = coerce_bool(log_response_body)
 
         self.log_request_attrs = log_request_attrs
@@ -310,18 +322,20 @@
         self.CERT_VERIFY: bool = certverify
 
         self.CERT_CLIENT_BOTH: t.Optional[PathLike] = cert_client_both
         self.CERT_CLIENT_CERT: t.Optional[PathLike] = cert_client_cert
         self.CERT_CLIENT_KEY: t.Optional[PathLike] = cert_client_key
 
         self.CONNECT_TIMEOUT: t.Optional[t.Union[int, float]] = coerce_int_float(
-            connect_timeout, error=False
+            connect_timeout,
+            error=False,
         )
         self.RESPONSE_TIMEOUT: t.Optional[t.Union[int, float]] = coerce_int_float(
-            response_timeout, error=False
+            response_timeout,
+            error=False,
         )
 
         self.HTTP_PROXY: t.Optional[str] = http_proxy
         self.HTTPS_PROXY: t.Optional[str] = https_proxy
 
         self.SAVE_HISTORY: bool = coerce_bool(save_history)
         self.SAVE_LAST: bool = coerce_bool(save_last)
@@ -378,15 +392,19 @@
             error_login: raise exc if `access login` command fails
             echo: echo commands and results to stdout
             echo_verbose: echo checks to stdout
 
         Returns:
             None or token, depending on `error` and `error_access` and `error_login`
         """
-        url = url if is_url(url) else get_env_url(error=True, error_empty=False) or self.url
+        url = (
+            url
+            if is_url(url)
+            else get_env_url(error=True, error_empty=False) or self.url
+        )
         token = flow_get_token(
             url=url,
             path=path,
             timeout_access=timeout_access,
             timeout_login=timeout_login,
             error=error,
             error_access=error_access,
@@ -399,23 +417,27 @@
             echo=echo,
             echo_verbose=echo_verbose,
         )
         self.HTTP_HEADERS["cf-access-token"] = token
         self.session.headers["cf-access-token"] = token
         return token
 
-    def safe_request(self, error: bool = False, **kwargs) -> t.Optional[requests.Response]:
+    def safe_request(
+        self,
+        error: bool = False,
+        **kwargs,
+    ) -> t.Optional[requests.Response]:
         """Make a request, but catch all exceptions and return None."""
         kwargs.setdefault("verify", False)
         kwargs.setdefault("connect_timeout", 10)
         kwargs.setdefault("response_timeout", 10)
         # noinspection PyBroadException
         try:
             return self(**kwargs)
-        except Exception:  # pragma: no cover
+        except Exception:  # pragma: no cover  # noqa: BLE001
             if error:
                 raise
         return None  # pragma: no cover
 
     def get_cert(self, error: bool = False) -> t.Optional[cert_human.Cert]:
         """Get the SSL certificate from url."""
         if not isinstance(self.URL_CERT, cert_human.Cert):
@@ -430,16 +452,21 @@
 
     def get_cert_chain(self, error: bool = False) -> t.List[cert_human.Cert]:
         """Get the SSL certificate chain from url."""
         if not (isinstance(self.URL_CERT_CHAIN, list) and self.URL_CERT_CHAIN):
             response: t.Optional[requests.Response] = self.safe_request(error=error)
             value = []
             if response:
-                chain: t.List[OpenSSL.crypto.X509] = listify(response.raw.captured_chain)
-                source: dict = {"url": self.url, "method": f"{self.get_cert_chain.__name__}"}
+                chain: t.List[OpenSSL.crypto.X509] = listify(
+                    response.raw.captured_chain,
+                )
+                source: dict = {
+                    "url": self.url,
+                    "method": f"{self.get_cert_chain.__name__}",
+                }
                 value = [cert_human.Cert(cert=x, source=source) for x in chain]
             self.URL_CERT_CHAIN = value
         return self.URL_CERT_CHAIN
 
     def parse_url(self, url: t.Union[str, UrlParser]) -> UrlParser:
         """Pass."""
         if isinstance(url, UrlParser):
@@ -484,32 +511,37 @@
 
     def set_session_cert(self):
         """Configure :attr:`session` with the client cert."""
         if self.CERT_CLIENT_BOTH:
             # TBD: verify cert and key
             self.CERT_CLIENT_BOTH, _ = path_read(obj=self.CERT_CLIENT_BOTH, binary=True)
             self.LOG.debug(
-                f"Resolved client cert with both cert and key to {self.CERT_CLIENT_BOTH}"
+                f"Resolved client cert with both cert and key to {self.CERT_CLIENT_BOTH}",
             )
             self.session.cert = str(self.CERT_CLIENT_BOTH)
 
         if (self.CERT_CLIENT_CERT or self.CERT_CLIENT_KEY) and not (
             self.CERT_CLIENT_CERT and self.CERT_CLIENT_KEY
         ):
+            msg = "Must supply 'cert_client_cert' and 'cert_client_key' or 'cert_client_both'"
             raise HttpError(
-                "Must supply 'cert_client_cert' and 'cert_client_key' or 'cert_client_both'"
+                msg,
             )
 
         if self.CERT_CLIENT_CERT and self.CERT_CLIENT_KEY:
             # TBD: verify cert and key
             self.CERT_CLIENT_CERT, _ = path_read(obj=self.CERT_CLIENT_CERT, binary=True)
-            self.LOG.debug(f"Resolved client cert with cert only to {self.CERT_CLIENT_CERT}")
+            self.LOG.debug(
+                f"Resolved client cert with cert only to {self.CERT_CLIENT_CERT}",
+            )
 
             self.CERT_CLIENT_KEY, _ = path_read(obj=self.CERT_CLIENT_KEY, binary=True)
-            self.LOG.debug(f"Resolved client cert with key only to {self.CERT_CLIENT_KEY}")
+            self.LOG.debug(
+                f"Resolved client cert with key only to {self.CERT_CLIENT_KEY}",
+            )
             self.session.cert = (str(self.CERT_CLIENT_CERT), str(self.CERT_CLIENT_KEY))
 
     def set_urllib_warnings(self):
         """Filter urllib warnings to show once or ignore.
 
         Notes:
             if self.CERT_WARN is True, show warning once
@@ -518,15 +550,18 @@
         if self.CERT_WARN is True:
             warnings.simplefilter("once", urllib3.exceptions.InsecureRequestWarning)
         elif self.CERT_WARN is False:
             warnings.simplefilter("ignore", urllib3.exceptions.InsecureRequestWarning)
 
     def set_urllib_log(self):
         """Set the urllib3 logging level to :attr:`LOG_LEVEL_URLLIB`."""
-        set_log_level(obj=logging.getLogger("urllib3.connectionpool"), level=self.LOG_LEVEL_URLLIB)
+        set_log_level(
+            obj=logging.getLogger("urllib3.connectionpool"),
+            level=self.LOG_LEVEL_URLLIB,
+        )
 
     def __call__(
         self,
         path: t.Optional[str] = None,
         route: t.Optional[str] = None,
         method: str = "get",
         data: t.Optional[str] = None,
@@ -542,14 +577,15 @@
         Args:
             path: path to append to :attr:`url`
             route: route to append to :attr:`url`
             method: HTTP method to use
             data: body to send
             params: parameters to url encode
             headers: headers to send
+            cookies: cookies to send
             json: obj to encode as json
             files: files to send
             **kwargs: overrides for object attributes
 
                 * connect_timeout: seconds to wait for connection to open for this request
                 * response_timeout: seconds to wait for response for this request
                 * proxies: proxies for this request
@@ -611,29 +647,36 @@
 
         send_args = self.session.merge_environment_settings(
             url=prepped_request.url,
             **pre_send_args,
         )
         log_if_headers(f"Request arguments after environment merge: {send_args}")
 
-        response = self.session.send(request=prepped_request, timeout=timeout, **send_args)
+        response = self.session.send(
+            request=prepped_request,
+            timeout=timeout,
+            **send_args,
+        )
 
         if self.SAVE_LAST:
             self.LAST_RESPONSE = response
 
         if self.SAVE_HISTORY:
             self.HISTORY.append(response)
 
         self._do_log_response(response=response)
 
         return response
 
     def __str__(self) -> str:
         """Show object info."""
-        return "{c.__module__}.{c.__name__}(url={url!r})".format(c=self.__class__, url=self.url)
+        return "{c.__module__}.{c.__name__}(url={url!r})".format(
+            c=self.__class__,
+            url=self.url,
+        )
 
     def __repr__(self) -> str:
         """Show object info."""
         return self.__str__()
 
     @property
     def user_agent(self) -> str:
@@ -656,15 +699,17 @@
                 method=request.method,
                 headers=self._clean_headers(headers=headers),
                 cookies=self._clean_headers(headers=cookies),
             )
             self.LOG.debug(f"REQUEST ATTRS: {lattrs}")
 
         if self.LOG_REQUEST_BODY:
-            self.LOG.debug(self.log_body(body=request.body, body_type="REQUEST", src=request))
+            self.LOG.debug(
+                self.log_body(body=request.body, body_type="REQUEST", src=request),
+            )
 
     def _clean_headers(self, headers: dict) -> dict:
         """Clean headers with sensitive information.
 
         Args:
             headers: headers to clean values of
         """
@@ -679,15 +724,15 @@
                     ):
                         return self.LOG_HIDE_STR
             return value
 
         # noinspection PyBroadException
         try:
             return {k: getval(k, v) for k, v in headers.items()}
-        except Exception:  # pragma: no cover
+        except Exception:  # pragma: no cover  # noqa: BLE001
             return headers
 
     def _do_log_response(self, response):
         """Log attributes and/or body of a response.
 
         Args:
             response (:obj:`requests.Response`): response to log attrs/body of
@@ -702,15 +747,17 @@
                 elapsed=response.elapsed,
                 headers=self._clean_headers(headers=response.headers),
                 cookies=self._clean_headers(headers=response.cookies),
             )
             self.LOG.debug(f"RESPONSE ATTRS: {lattrs}")
 
         if self.LOG_RESPONSE_BODY:
-            self.LOG.debug(self.log_body(body=response.text, body_type="RESPONSE", src=response))
+            self.LOG.debug(
+                self.log_body(body=response.text, body_type="RESPONSE", src=response),
+            )
 
     @property
     def log_request_attrs(self) -> t.List[str]:
         """Get the request attributes that should be logged."""
         return self._get_log_attrs("request")
 
     @log_request_attrs.setter
@@ -736,15 +783,20 @@
         """Get the log attributes for a specific type.
 
         Args:
             attr_type: 'request' or 'response'
         """
         return getattr(self, "_LOG_ATTRS", {}).get(attr_type, [])
 
-    def _set_log_attrs(self, attr_map: dict, attr_type: str, value: t.Union[str, t.List[str]]):
+    def _set_log_attrs(
+        self,
+        attr_map: dict,
+        attr_type: str,
+        value: t.Union[str, t.List[str]],
+    ):
         """Set the log attributes for a specific type.
 
         Args:
             attr_map: map of attributes to format strings
             attr_type: 'request' or 'response'
             value: user supplied attrs to log
         """
@@ -769,22 +821,26 @@
         for item in value:
             if item in attr_map:
                 value = attr_map[item]
                 entry = f"{item}={value}"
                 if entry not in log_attrs:
                     log_attrs.append(entry)
 
-    def log_body(self, body: t.Any, body_type: str, src: t.Optional[t.Any] = None) -> str:
+    def log_body(
+        self,
+        body: t.Any,
+        body_type: str,
+        src: t.Optional[t.Any] = None,
+    ) -> str:
         """Get a string for logging a request or response body.
 
         Args:
             body: content to log
             body_type: 'request' or 'response'
             src: source of the body
 
         """
         body = json_log(obj=coerce_str(value=body), trim=self.LOG_BODY_LINES)
         return f"{body_type} BODY from {src}:\n{body}"
 
     def _init(self):
         """Pass."""
-        pass
```

## axonius_api_client/tools.py

```diff
@@ -1,10 +1,10 @@
-# -*- coding: utf-8 -*-
 """Utilities and tools."""
 import codecs
+import contextlib
 import csv
 import dataclasses
 import datetime
 import inspect
 import io
 import ipaddress
 import json
@@ -21,14 +21,15 @@
 
 import bson
 import click
 import dateutil.parser
 import dateutil.relativedelta
 import dateutil.tz
 import marshmallow
+import typing_extensions as te
 
 from . import INIT_DOTENV, PACKAGE_FILE, PACKAGE_ROOT, VERSION
 from .constants.api import GUI_PAGE_SIZES, REFRESH, FolderDefaults
 from .constants.ctypes import (
     PathLike,
     PatternLike,
     PatternLikeListy,
@@ -63,15 +64,17 @@
 from .exceptions import FormatError, ToolsError
 from .setup_env import find_dotenv, get_env_ax
 
 LOG: logging.Logger = logging.getLogger(PACKAGE_ROOT).getChild("tools")
 
 
 def type_str(
-    value: t.Any, max_len: int = 60, join: t.Optional[str] = ", "
+    value: t.Any,
+    max_len: int = 60,
+    join: t.Optional[str] = ", ",
 ) -> t.Union[str, t.List[str]]:
     """Pass."""
     length = len(str(value))
     svalue = f"{str(value)[:max_len]}...snip..." if length >= max_len else f"{value}"
     items = [
         f"type={type(value)}",
         f"length={length}",
@@ -106,21 +109,26 @@
     if resolve:
         resolved = resolved.resolve()
 
     vstr = f"(supplied {type_str(path)})"
     rstr = f"Resolved path {str(resolved)!r}"
 
     if as_file and not resolved.is_file():
-        raise ToolsError(f"{rstr} does not exist as a file {vstr}")
+        msg = f"{rstr} does not exist as a file {vstr}"
+        raise ToolsError(msg)
 
     if as_dir and not resolved.is_dir():
-        raise ToolsError(f"{rstr} does not exist as a directory {vstr}")
+        msg = f"{rstr} does not exist as a directory {vstr}"
+        raise ToolsError(msg)
 
     if isinstance(exts, list) and exts and resolved.suffix not in exts:
-        raise ToolsError(f"{rstr} with extension {resolved.suffix!r} is not one of {exts}")
+        msg = f"{rstr} with extension {resolved.suffix!r} is not one of {exts}"
+        raise ToolsError(
+            msg,
+        )
 
     return resolved
 
 
 def is_existing_file(path: t.Any, **kwargs) -> bool:
     """Check if the supplied value refers to an existing file."""
     if isinstance(path, pathlib.Path) and path.is_file():
@@ -160,15 +168,19 @@
     Args:
         obj: object to coerce to list
         dictkeys: if obj is dict, return list of keys of obj
     """
 
     def stripper(values: t.List[str]) -> t.List[str]:
         """Pass."""
-        return [y for y in [x.strip(strip_chars) for x in values] if y] if strip else values
+        return (
+            [y for y in [x.strip(strip_chars) for x in values] if y]
+            if strip
+            else values
+        )
 
     if "value" in kwargs:
         obj = kwargs["value"]
 
     if obj is None:
         return []
     if isinstance(obj, (types.GeneratorType, list)):
@@ -178,24 +190,30 @@
     if isinstance(obj, dict):
         return list(obj) if dictkeys else [obj]
     if split:
         if isinstance(obj, bytes):
             obj = obj.decode(encoding=encoding, errors=errors)
         if isinstance(obj, str):
             split_args = (
-                {"maxsplit": split_max} if isinstance(split_max, int) and split_max >= 0 else {}
+                {"maxsplit": split_max}
+                if isinstance(split_max, int) and split_max >= 0
+                else {}
             )
             if is_pattern(value=split_sep):
                 return stripper(split_sep.split(obj, **split_args))
             return stripper(obj.split(sep=split_sep, **split_args))
 
     return [obj]
 
 
-def grouper(iterable: t.Iterable, n: int, fillvalue: t.Optional[t.Any] = None) -> t.Iterator:
+def grouper(
+    iterable: t.Iterable,
+    n: int,
+    fillvalue: t.Optional[t.Any] = None,
+) -> t.Iterator:
     """Split an iterable into chunks.
 
     Args:
         iterable: iterable to split into chunks of size `n`
         n: length to split iterable into
         fillvalue: value to use as filler for last chunk
     """
@@ -223,26 +241,34 @@
         return as_none
 
     pre = f"{errmsg}\n" if errmsg else ""
 
     try:
         value = int(obj)
     except Exception as exc:
+        msg = f"{pre}Supplied value {obj!r} of type {trype(obj)} is not an integer.\n{exc}"
         raise ToolsError(
-            f"{pre}Supplied value {obj!r} of type {trype(obj)} is not an integer.\n{exc}"
+            msg,
         )
 
     if max_value is not None and value > max_value:
-        raise ToolsError(f"{pre}Supplied value {obj!r} is greater than max value of {max_value}.")
+        msg = f"{pre}Supplied value {obj!r} is greater than max value of {max_value}."
+        raise ToolsError(
+            msg,
+        )
 
     if min_value is not None and value < min_value:
-        raise ToolsError(f"{pre}Supplied value {obj!r} is less than min value of {min_value}.")
+        msg = f"{pre}Supplied value {obj!r} is less than min value of {min_value}."
+        raise ToolsError(
+            msg,
+        )
 
     if valid_values and value not in valid_values:
-        raise ToolsError(f"{pre}Supplied value {obj!r} is not one of {valid_values}.")
+        msg = f"{pre}Supplied value {obj!r} is not one of {valid_values}."
+        raise ToolsError(msg)
 
     return value
 
 
 def coerce_int_float(
     value: t.Union[int, float, str, bytes],
     as_float: bool = False,
@@ -274,16 +300,17 @@
         if "." in value and value.replace(".", "").isdigit():
             return float(value)
 
         if value.isdigit():
             return float(value) if as_float else int(value)
 
     if error:
+        msg = f"Supplied value {value!r} of type {trype(value)} is not an integer or float."
         raise ToolsError(
-            f"Supplied value {value!r} of type {trype(value)} is not an integer or float."
+            msg,
         )
 
     return value if ret_value is True else as_none
 
 
 def coerce_bool(
     obj: t.Any,
@@ -318,15 +345,16 @@
     if coerce_obj in YES:
         return True
 
     if coerce_obj in NO:
         return False
 
     if not error or (
-        allow_none and (obj is None or str(coerce_obj).lower().strip() in ["none", "null"])
+        allow_none
+        and (obj is None or str(coerce_obj).lower().strip() in ["none", "null"])
     ):
         return obj if as_original else as_none
 
     vtype = trype(obj)
     msg = listify(errmsg)
     msg += [
         f"Supplied value {coerce_obj!r} of type {vtype} must be one of:",
@@ -349,17 +377,16 @@
 def is_int(obj: t.Any, digit: bool = False) -> bool:
     """Check if obj is int typeable.
 
     Args:
         obj: object to check
         digit: allow checking str/bytes
     """
-    if digit:
-        if (isinstance(obj, str) or isinstance(obj, bytes)) and obj.isdigit():
-            return True
+    if digit and (isinstance(obj, (str, bytes))) and obj.isdigit():
+        return True
 
     return not isinstance(obj, bool) and isinstance(obj, int)
 
 
 def join_url(url: str, *parts) -> str:
     """Join a URL to any number of parts.
 
@@ -380,15 +407,15 @@
 def strip_right(obj: t.Union[t.List[str], str], fix: str) -> t.Union[t.List[str], str]:
     """Strip text from the right side of obj.
 
     Args:
         obj: str(s) to strip fix from
         fix: str to remove from obj(s)
     """
-    if isinstance(obj, list) and all([isinstance(x, str) for x in obj]):
+    if isinstance(obj, list) and all(isinstance(x, str) for x in obj):
         return [strip_right(obj=x, fix=fix) for x in obj]
 
     if isinstance(obj, str):
         plen = len(fix)
 
         if obj.endswith(fix):
             return obj[:-plen]
@@ -399,15 +426,15 @@
 def strip_left(obj: t.Union[t.List[str], str], fix: str) -> t.Union[t.List[str], str]:
     """Strip text from the left side of obj.
 
     Args:
         obj: str(s) to strip fix from
         fix: str to remove from obj(s)
     """
-    if isinstance(obj, list) and all([isinstance(x, str) for x in obj]):
+    if isinstance(obj, list) and all(isinstance(x, str) for x in obj):
         return [strip_left(obj=x, fix=fix) for x in obj]
 
     if isinstance(obj, str):
         plen = len(fix)
 
         if obj.startswith(fix):
             return obj[plen:]
@@ -464,15 +491,20 @@
     obj = bytes_to_str(value=obj)
 
     if to_dict and has_to_dict(obj):
         obj = obj.to_dict()
 
     try:
         return json.dumps(
-            obj, indent=indent, sort_keys=sort_keys, cls=cls, fallback=fallback, **kwargs
+            obj,
+            indent=indent,
+            sort_keys=sort_keys,
+            cls=cls,
+            fallback=fallback,
+            **kwargs,
         )
     except Exception:  # pragma: no cover
         if error:
             raise
         return obj
 
 
@@ -580,18 +612,16 @@
         nexc = ToolsError(msgs)
         nexc.value = value
         nexc.kwargs = kwargs
         nexc.orig_exc = exc
         raise nexc
     finally:
         if close_fh and fh is not None:
-            try:
+            with contextlib.suppress(Exception):
                 fh.close()
-            except Exception:
-                pass
 
 
 def jsonl_loader(item: str, idx: int, error: bool = True, **kwargs) -> t.Any:
     """Pass."""
     try:
         return json.loads(item, **kwargs)
     except Exception as exc:
@@ -606,15 +636,18 @@
             nexc = ToolsError(msgs)
             nexc.item = item
             nexc.orig_exc = exc
             raise nexc
 
 
 def jsonl_load(
-    obj: t.Union[str, t.List[str], t.IO], error: bool = True, close_fh: bool = True, **kwargs
+    obj: t.Union[str, t.List[str], t.IO],
+    error: bool = True,
+    close_fh: bool = True,
+    **kwargs,
 ) -> t.List[t.Any]:
     """Deserialize a jsonl str into an object.
 
     Args:
         obj: str to deserialize into obj
         error: if json error happens, raise it
         **kwargs: passed to :func:`json.loads`
@@ -637,15 +670,18 @@
         fh = obj
         items = obj.readlines
     elif isinstance(obj, (tuple, list)):
         items = obj
     elif isinstance(obj, str):
         items = obj.splitlines
     else:
-        raise ToolsError(f"Unexpected type {tlens(obj)}, must be str, bytes, {t.IO}, or {PathLike}")
+        msg = f"Unexpected type {tlens(obj)}, must be str, bytes, {t.IO}, or {PathLike}"
+        raise ToolsError(
+            msg,
+        )
 
     ret = [
         jsonl_loader(item=item, idx=idx, error=error, **kwargs)
         for idx, item in enumerate(items() if callable(items) else items)
         if is_item(item)
     ]
     try:
@@ -664,15 +700,20 @@
     trim_msg: str = TRIM_MSG,
     **kwargs,
 ) -> str:  # pragma: no cover
     """Pass."""
     if obj is None and not error:
         obj = "null"
     return json_reload(
-        obj=obj, error=error, trim=trim, trim_lines=trim_lines, trim_msg=trim_msg, **kwargs
+        obj=obj,
+        error=error,
+        trim=trim,
+        trim_lines=trim_lines,
+        trim_msg=trim_msg,
+        **kwargs,
     )
 
 
 def json_reload(
     obj: t.Any,
     error: bool = False,
     trim: t.Optional[int] = None,
@@ -691,15 +732,16 @@
     if not isinstance(obj, str):
         obj = json_dump(obj=obj, error=error, **kwargs)
     obj = coerce_str(value=obj, trim=trim, trim_msg=trim_msg, trim_lines=trim_lines)
     return obj
 
 
 def text_load(
-    value: t.Union[str, t.List[str], t.IO], close_fh: bool = True
+    value: t.Union[str, t.List[str], t.IO],
+    close_fh: bool = True,
 ) -> t.Generator[str, None, None]:
     """Pass."""
     fh = None
     if is_existing_file(value):
         path = pathify(value)
         fh = path.open()
         lines = fh.readlines
@@ -707,36 +749,43 @@
         fh = value
         lines = value.readlines
     elif isinstance(value, str):
         lines = value.splitlines
     elif isinstance(value, (list, tuple)):
         lines = value
     else:
+        msg = f"Must supply str, list of str, {pathlib.Path}, or {t.IO}, supplied {tlens(value)}"
         raise ToolsError(
-            f"Must supply str, list of str, {pathlib.Path}, or {t.IO}, supplied {tlens(value)}"
+            msg,
         )
 
     try:
-        yield from [line for line in (lines() if callable(lines) else lines)]
+        yield from list(lines() if callable(lines) else lines)
     finally:
         try:
             if close_fh and fh is not None:
                 fh.close()
         except Exception:
             pass
 
 
 def dt_parse_uuid(
-    value: str, default_tz_utc: bool = False, allow_none=False, error: bool = False
+    value: str,
+    default_tz_utc: bool = False,
+    allow_none=False,
+    error: bool = False,
 ) -> t.Optional[datetime.datetime]:
     """Parse the date from an object UUID."""
     if allow_none and (value is None or str(value).lower().strip() in ["none", "null"]):
         return None
     try:
-        return dt_parse(obj=bson.ObjectId(value).generation_time, default_tz_utc=default_tz_utc)
+        return dt_parse(
+            obj=bson.ObjectId(value).generation_time,
+            default_tz_utc=default_tz_utc,
+        )
     except Exception:
         if error:
             raise
         return None
 
 
 def dt_parse(
@@ -752,18 +801,23 @@
         obj: object or list of objects to parse into datetime
         default_tz_utc: if no timezone is found, assume UTC
         allow_none: if obj is None or "none" or "null", return None
         as_none: if allow_none and obj is None, return this value
         as_tz: if not None, convert to this timezone
     """
     if isinstance(obj, list) and all(
-        [isinstance(x, (str, datetime.datetime, datetime.timedelta)) for x in obj]
+        isinstance(x, (str, datetime.datetime, datetime.timedelta)) for x in obj
     ):
         return [
-            dt_parse(obj=x, default_tz_utc=default_tz_utc, as_none=as_none, allow_none=allow_none)
+            dt_parse(
+                obj=x,
+                default_tz_utc=default_tz_utc,
+                as_none=as_none,
+                allow_none=allow_none,
+            )
             for x in obj
         ]
 
     if isinstance(obj, datetime.datetime):
         obj = str(obj)
 
     if isinstance(obj, datetime.timedelta):
@@ -779,15 +833,16 @@
             value = value.replace(tzinfo=as_tz)
         if isinstance(as_tz, datetime.tzinfo):
             value = value.astimezone(as_tz)
     return value
 
 
 def dt_parse_tmpl(
-    obj: t.Union[str, datetime.timedelta, datetime.datetime], tmpl: str = "%Y-%m-%d"
+    obj: t.Union[str, datetime.timedelta, datetime.datetime],
+    tmpl: str = "%Y-%m-%d",
 ) -> str:
     """Parse a string into the format used by the REST API.
 
     Args:
         obj: date time to parse using :meth:`dt_parse`
         tmpl: strftime template to convert obj into
     """
@@ -797,19 +852,17 @@
     ]
     try:
         dt = dt_parse(obj=obj)
         return dt.strftime(tmpl)
     except Exception:
         vtype = trype(obj)
         valid = "\n - " + "\n - ".join(valid_fmts)
+        msg = f"Could not parse date {obj!r} of type {vtype}, try a string in the format of:{valid}"
         raise ToolsError(
-            (
-                f"Could not parse date {obj!r} of type {vtype}"
-                f", try a string in the format of:{valid}"
-            )
+            (msg),
         )
 
 
 def dt_now(
     delta: t.Optional[datetime.timedelta] = None,
     tz: t.Optional[datetime.timezone] = datetime.timezone.utc,
 ) -> datetime:
@@ -826,15 +879,17 @@
 
 def dt_now_file(fmt: str = FILE_DATE_FMT, **kwargs):
     """Pass."""
     return dt_now(**kwargs).strftime(fmt)
 
 
 def dt_sec_ago(
-    obj: t.Union[str, datetime.timedelta, datetime.datetime], exact: bool = False, places: int = 2
+    obj: t.Union[str, datetime.timedelta, datetime.datetime],
+    exact: bool = False,
+    places: int = 2,
 ) -> int:
     """Get number of seconds ago a given datetime was.
 
     Args:
         obj: parsed by :meth:`dt_parse` into a datetime obj
         exact: if True, return exact seconds, otherwise round to places
         places: number of places to round to
@@ -875,15 +930,15 @@
     Args:
         obj: parsed by :meth:`dt_sec_ago` into seconds ago
     """
     return round(dt_sec_ago(obj=obj) / 60)
 
 
 def dt_days_left(
-    obj: t.Optional[t.Union[str, datetime.timedelta, datetime.datetime]]
+    obj: t.Optional[t.Union[str, datetime.timedelta, datetime.datetime]],
 ) -> t.Optional[int]:
     """Get number of days left until a given datetime.
 
     Args:
         obj: parsed by :meth:`dt_sec_ago` into days left
     """
     ret = None
@@ -917,15 +972,18 @@
     Args:
         obj: obj to convert into expanded and resolved absolute Path obj
     """
     return pathlib.Path(obj).expanduser().resolve()
 
 
 def path_read(
-    obj: PathLike, binary: bool = False, is_json: bool = False, **kwargs
+    obj: PathLike,
+    binary: bool = False,
+    is_json: bool = False,
+    **kwargs,
 ) -> t.Union[bytes, str]:
     """Read data from a file.
 
     Notes:
         * if path filename ends with ".json", data will be deserialized using
           :meth:`json_load`
 
@@ -937,20 +995,18 @@
 
     Raises:
         :exc:`ToolsError`: path does not exist as file
     """
     robj = get_path(obj=obj)
 
     if not robj.is_file():
-        raise ToolsError(f"Supplied path='{obj}' (resolved='{robj}') does not exist!")
+        msg = f"Supplied path='{obj}' (resolved='{robj}') does not exist!"
+        raise ToolsError(msg)
 
-    if binary:
-        data = robj.read_bytes()
-    else:
-        data = robj.read_text()
+    data = robj.read_bytes() if binary else robj.read_text()
 
     if is_json:
         data = json_load(obj=data, **kwargs)
 
     if robj.suffix == ".json" and isinstance(data, str):
         kwargs.setdefault("error", False)
         data = json_load(obj=data, **kwargs)
@@ -970,71 +1026,79 @@
     return path.parent / get_backup_filename(path=path)
 
 
 def check_path_is_not_dir(path: PathLike) -> pathlib.Path:
     """Pass."""
     path = get_path(obj=path)
     if path.is_dir():
-        raise ToolsError(f"'{path}' is a directory, not a file")
+        msg = f"'{path}' is a directory, not a file"
+        raise ToolsError(msg)
     return path
 
 
 def path_create_parent_dir(
-    path: PathLike, make_parent: bool = True, protect_parent=0o700
+    path: PathLike,
+    make_parent: bool = True,
+    protect_parent=0o700,
 ) -> pathlib.Path:
     """Pass."""
     path = get_path(obj=path)
 
     if not path.parent.is_dir():
         if make_parent:
             path.parent.mkdir(mode=protect_parent, parents=True, exist_ok=True)
         else:
+            msg = f"Parent directory '{path.parent}' does not exist and make_parent is False"
             raise ToolsError(
-                f"Parent directory '{path.parent}' does not exist and make_parent is False"
+                msg,
             )
     return path
 
 
 def path_backup_file(
     path: PathLike,
     backup_path: t.Optional[PathLike] = None,
     make_parent: bool = True,
     protect_parent=0o700,
     **kwargs,
 ) -> pathlib.Path:
     """Pass."""
     path = get_path(obj=path)
     if not path.is_file():
-        raise ToolsError(f"'{path}' does not exist as a file, can not backup")
+        msg = f"'{path}' does not exist as a file, can not backup"
+        raise ToolsError(msg)
 
-    if backup_path:
-        backup_path = get_path(obj=backup_path)
-    else:
-        backup_path = get_backup_path(path=path)
+    backup_path = (
+        get_path(obj=backup_path) if backup_path else get_backup_path(path=path)
+    )
 
     check_path_is_not_dir(path=backup_path)
 
     if backup_path.is_file():
         backup_path = get_backup_path(path=backup_path)
 
-    path_create_parent_dir(path=backup_path, make_parent=make_parent, protect_parent=protect_parent)
+    path_create_parent_dir(
+        path=backup_path,
+        make_parent=make_parent,
+        protect_parent=protect_parent,
+    )
     path.rename(backup_path)
     return backup_path
 
 
 def auto_suffix(
     path: PathLike,
     data: t.Union[bytes, str],
     error: bool = False,
     **kwargs,
 ) -> t.Union[bytes, str]:
     """Pass."""
     path = get_path(obj=path)
 
-    if path.suffix == ".json" and not (isinstance(data, str) or isinstance(data, bytes)):
+    if path.suffix == ".json" and not (isinstance(data, (str, bytes))):
         data = json_dump(obj=data, error=error, **kwargs)
     return data
 
 
 def path_write(
     obj: t.Optional[PathLike],
     data: t.Union[bytes, str],
@@ -1101,17 +1165,22 @@
             backup_path = path_backup_file(
                 path=obj,
                 backup_path=backup_path,
                 make_parent=make_parent,
                 protect_parent=protect_parent,
             )
         elif overwrite is False:
-            raise ToolsError(f"File '{obj}' already exists and overwrite is False")
+            msg = f"File '{obj}' already exists and overwrite is False"
+            raise ToolsError(msg)
     else:
-        path_create_parent_dir(path=obj, make_parent=make_parent, protect_parent=protect_parent)
+        path_create_parent_dir(
+            path=obj,
+            make_parent=make_parent,
+            protect_parent=protect_parent,
+        )
 
     obj.touch()
 
     if protect_file:
         obj.chmod(protect_file)
 
     bytes_written = method(data)
@@ -1159,15 +1228,16 @@
                 do_strip=do_strip,
                 lower=lower,
                 empty=empty,
             )
         ]
 
     if not isinstance(obj, str):
-        raise ToolsError(f"Unable to split non-str value {obj}")
+        msg = f"Unable to split non-str value {obj}"
+        raise ToolsError(msg)
 
     ret = []
     for x in obj.split(split):
         if lower:
             x = x.lower()
         if do_strip:
             x = x.strip(strip)
@@ -1213,15 +1283,19 @@
     kwargs.setdefault("style_args", WARN_ARGS)
     kwargs.setdefault("style_tmpl", WARN_TMPL)
     kwargs.setdefault("log_level", "warning")
     kwargs["do_echo"] = True
     return echo(msg=msg, **kwargs)
 
 
-def echo_error(msg: t.Optional[t.Union[str, t.List[str]]] = None, abort: bool = True, **kwargs):
+def echo_error(
+    msg: t.Optional[t.Union[str, t.List[str]]] = None,
+    abort: bool = True,
+    **kwargs,
+):
     """Echo an error message to console.
 
     Args:
         msg: message to echo
         abort: call sys.exit(1) after echoing message
         kwargs: passed to ``echo``
     """
@@ -1323,15 +1397,19 @@
             value = method()
 
         attr = attr.replace("_", " ").title()
         info[attr] = value
     return info
 
 
-def calc_percent(part: t.Union[int, float], whole: t.Union[int, float], places: int = 2) -> float:
+def calc_percent(
+    part: t.Union[int, float],
+    whole: t.Union[int, float],
+    places: int = 2,
+) -> float:
     """Calculate the percentage of part out of whole.
 
     Args:
         part: number to get percent of `whole`
         whole: number to calculate against `part`
         places: number of decimal places to return
     """
@@ -1355,28 +1433,31 @@
     """
     if isinstance(places, int):
         value = float(f"{value:.{places}f}")
     return value
 
 
 def join_kv(
-    obj: t.Union[t.List[dict], dict], listjoin: str = ", ", tmpl: str = "{k}: {v!r}"
+    obj: t.Union[t.List[dict], dict],
+    listjoin: str = ", ",
+    tmpl: str = "{k}: {v!r}",
 ) -> t.List[str]:
     """Join a dictionary into key value strings.
 
     Args:
         obj: dict or list of dicts to stringify
         listjoin: string to use for joining
         tmpl: template to format key value pairs of dict
     """
     if isinstance(obj, list):
         return [join_kv(obj=x, listjoin=listjoin, tmpl=tmpl) for x in obj]
 
     if not isinstance(obj, dict):
-        raise ToolsError(f"Object must be a dict, supplied {trype(obj)}")
+        msg = f"Object must be a dict, supplied {trype(obj)}"
+        raise ToolsError(msg)
 
     items = []
     for k, v in obj.items():
         if isinstance(v, (list, tuple)):
             v = listjoin.join([str(i) for i in v])
             items.append(tmpl.format(k=k, v=v))
             continue
@@ -1399,15 +1480,20 @@
     """
     if isinstance(obj, (list, tuple)):
         return " or ".join([x.__name__ for x in obj])
     else:
         return obj.__name__
 
 
-def check_type(value: t.Any, exp: t.Any, name: str = "", exp_items: t.Optional[t.Any] = None):
+def check_type(
+    value: t.Any,
+    exp: t.Any,
+    name: str = "",
+    exp_items: t.Optional[t.Any] = None,
+):
     """Check that a value is the appropriate type.
 
     Args:
         value: value to check type of
         exp: type(s) that value should be
         name: identifier of what value is for
         exp_items: if value is a list, type(s) that list items should be
@@ -1453,20 +1539,22 @@
         value: version to calculate
     """
     check_type(value=value, exp=str)
     converted = "0"
     version = value
     if ":" in value:
         if "." in value and value.index(":") > value.index("."):
-            raise ToolsError(f"Invalid version with ':' after '.' in {value!r}")
+            msg = f"Invalid version with ':' after '.' in {value!r}"
+            raise ToolsError(msg)
         converted, version = value.split(":", 1)
     octects = version.split(".")
     for octect in octects:
         if not octect.isdigit():
-            raise ToolsError(f"Invalid version with non-digit {octect!r} in {value!r}")
+            msg = f"Invalid version with non-digit {octect!r} in {value!r}"
+            raise ToolsError(msg)
         if len(octect) > 8:
             octect = octect[:8]
         converted += "".join(["0" for _ in range(8 - len(octect))]) + octect
     return converted
 
 
 def coerce_str_to_csv(
@@ -1481,52 +1569,59 @@
     """
     pre = f"{errmsg}\n" if errmsg else ""
 
     new_value = value
     if isinstance(value, str):
         new_value = [x.strip() for x in value.split(",") if x.strip()]
         if not new_value:
-            raise ToolsError(f"{pre}Empty value after parsing CSV: {value!r}")
+            msg = f"{pre}Empty value after parsing CSV: {value!r}"
+            raise ToolsError(msg)
 
     if not isinstance(new_value, (list, tuple)):
         if coerce_list:
             new_value = listify(obj=new_value)
         else:
-            raise ToolsError(f"{pre}Invalid type {trype(new_value)} supplied, must be a list")
+            msg = f"{pre}Invalid type {trype(new_value)} supplied, must be a list"
+            raise ToolsError(
+                msg,
+            )
 
     if not new_value:
-        raise ToolsError(f"{pre}Empty list supplied {value}")
+        msg = f"{pre}Empty list supplied {value}"
+        raise ToolsError(msg)
 
     return new_value
 
 
-def parse_ip_address(value: str) -> t.Union[ipaddress.IPv4Address, ipaddress.IPv6Address]:
+def parse_ip_address(
+    value: str,
+) -> t.Union[ipaddress.IPv4Address, ipaddress.IPv6Address]:
     """Parse a string into an IP address.
 
     Args:
         value: ip address
     """
     try:
         return ipaddress.ip_address(value)
     except Exception as exc:
         raise ToolsError(str(exc))
 
 
-def parse_ip_network(value: str) -> t.Union[ipaddress.IPv4Network, ipaddress.IPv6Network]:
+def parse_ip_network(
+    value: str,
+) -> t.Union[ipaddress.IPv4Network, ipaddress.IPv6Network]:
     """Parse a string into an IP network.
 
     Args:
         value: ip network
     """
     if "/" not in str(value):
+        msg = f"Supplied value {value!r} of type {trype(value)} is not a valid subnet - format must be <address>/<CIDR>."
         raise ToolsError(
-            (
-                f"Supplied value {value!r} of type {trype(value)} is not a valid subnet "
-                "- format must be <address>/<CIDR>."
-            )
+            (msg),
         )
     try:
         return ipaddress.ip_network(value)
     except Exception as exc:
         raise ToolsError(str(exc))
 
 
@@ -1535,15 +1630,19 @@
 
     Args:
         obj: dictionary to get string of
     """
     return "\n  " + "\n  ".join([f"{k}: {v}" for k, v in obj.items()])
 
 
-def bom_strip(content: t.Union[str, bytes], strip=True, bom: bytes = codecs.BOM_UTF8) -> str:
+def bom_strip(
+    content: t.Union[str, bytes],
+    strip=True,
+    bom: bytes = codecs.BOM_UTF8,
+) -> str:
     """Remove the UTF-8 BOM marker from the beginning of a string.
 
     Args:
         content: string to remove BOM marker from if found
         strip: remove whitespace before & after removing BOM marker
     """
     if isinstance(content, (str, bytes)):
@@ -1567,21 +1666,23 @@
 
     Args:
         stream: stdin or a file descriptor to read input from
     """
     stream_name = format(getattr(stream, "name", stream))
 
     if stream.isatty():
-        raise ToolsError(f"No input provided on {stream_name!r}")
+        msg = f"No input provided on {stream_name!r}"
+        raise ToolsError(msg)
 
     # its STDIN with input or a file
     content = stream.read().strip()
 
     if not content:
-        raise ToolsError(f"Empty content supplied to {stream_name!r}")
+        msg = f"Empty content supplied to {stream_name!r}"
+        raise ToolsError(msg)
 
     return content
 
 
 def check_gui_page_size(size: t.Optional[int] = None) -> int:
     """Check page size to see if it one of the valid GUI page sizes.
 
@@ -1592,15 +1693,18 @@
         :exc:`ApiError`: if size is not one of
             :data:`axonius_api_client.constants.api.GUI_PAGE_SIZES`
 
     """
     size = size or GUI_PAGE_SIZES[0]
     size = coerce_int(size)
     if size not in GUI_PAGE_SIZES:
-        raise ToolsError(f"gui_page_size of {size} is invalid, must be one of {GUI_PAGE_SIZES}")
+        msg = f"gui_page_size of {size} is invalid, must be one of {GUI_PAGE_SIZES}"
+        raise ToolsError(
+            msg,
+        )
     return size
 
 
 def calc_gb(value: t.Union[str, int], places: int = 2, is_kb: bool = True) -> float:
     """Convert bytes into GB.
 
     Args:
@@ -1686,19 +1790,22 @@
 
     ret.update(kwargs)
     return ret
 
 
 def is_url(value: str) -> bool:
     """Pass."""
-    return isinstance(value, str) and any([value.startswith(x) for x in URL_STARTS])
+    return isinstance(value, str) and any(value.startswith(x) for x in URL_STARTS)
 
 
 def bytes_to_str(
-    value: t.Any, encoding: str = "utf-8", ignore: bool = False, strict: bool = False
+    value: t.Any,
+    encoding: str = "utf-8",
+    ignore: bool = False,
+    strict: bool = False,
 ) -> t.Any:
     """Convert value to str if value is bytes.
 
     Args:
         value (t.Any): value to convert to str
         encoding (str, optional): encoding to use
         ignore (bool, optional): ignore errors instead of replacing them
@@ -1768,36 +1875,34 @@
         else:
             value_len = len(value)
             if value_len >= trim:
                 value = value[:trim]
                 trim_done = True
 
         if trim_done:
-            value += trim_msg.format(trim_type=trim_type, trim=trim, value_len=value_len)
+            value += trim_msg.format(
+                trim_type=trim_type,
+                trim=trim,
+                value_len=value_len,
+            )
     return value
 
 
 # def strim(value: str, limit: t.Optional[int] = None) -> str:
 #     """Pass."""
 #     if isinstance(limit, int) and limit > 0 and len(value) > limit:
-#         value = value[:limit] + f"... {len(value) - limit} more characters"
-#     return value
 
 
 # def ltrim(
 #     value: t.Union[str, t.List[str]], limit: t.Optional[int] = None, rejoin: bool = False
 # ) -> t.List[str]:
 #     """Pass."""
 #     if isinstance(value, str):
-#         value = value.splitlines()
-#     value = listify(value)
 
 #     if isinstance(limit, int) and limit > 0 and len(value) > limit:
-#         value = value[:limit] + [f"... {len(value) - limit} more lines"]
-#     return value
 
 
 def get_cls_path(value: t.Any) -> str:
     """Pass."""
     if inspect.isclass(value):
         cls = value
     elif hasattr(value, "__class__"):
@@ -1867,21 +1972,29 @@
 
     return value
 
 
 def safe_replace(obj: dict, value: str) -> str:
     """Pass."""
     for search, replace in obj.items():
-        if isinstance(search, str) and isinstance(replace, str) and search and search in value:
+        if (
+            isinstance(search, str)
+            and isinstance(replace, str)
+            and search
+            and search in value
+        ):
             value = value.replace(search, replace)
     return value
 
 
 def safe_format(
-    value: PathLike, mapping: t.Optional[t.Dict[str, str]] = None, as_path: bool = False, **kwargs
+    value: PathLike,
+    mapping: t.Optional[t.Dict[str, str]] = None,
+    as_path: bool = False,
+    **kwargs,
 ) -> PathLike:
     """Pass."""
     is_path = isinstance(value, pathlib.Path)
     to_update = str(value) if is_path else value
 
     if not isinstance(to_update, str):
         return value
@@ -1890,15 +2003,16 @@
         if isinstance(item, dict) and item:
             to_update = safe_replace(obj=item, value=to_update)
 
     return get_path(to_update) if is_path or as_path else to_update
 
 
 def get_paths_format(
-    *args, mapping: t.Optional[t.Dict[str, str]] = None
+    *args,
+    mapping: t.Optional[t.Dict[str, str]] = None,
 ) -> t.Optional[pathlib.Path]:
     """Pass."""
     ret = None
     for path in args:
         if isinstance(path, bytes):
             path = path.decode("utf-8")
 
@@ -1910,23 +2024,21 @@
                 path = safe_replace(obj=mapping, value=path)
 
             path = pathlib.Path(path)
 
         if isinstance(path, pathlib.Path):
             path = path.expanduser()
 
-            if ret:
-                ret = ret / path
-            else:
-                ret = path.resolve()
+            ret = ret / path if ret else path.resolve()
     return ret
 
 
 def int_days_map(
-    value: t.Union[str, t.List[t.Union[str, int]]], names: bool = False
+    value: t.Union[str, t.List[t.Union[str, int]]],
+    names: bool = False,
 ) -> t.List[str]:
     """Pass."""
     ret = []
     value = coerce_str_to_csv(value=value, coerce_list=True)
     valid = ", ".join([f"{v} ({k})" for k, v in DAYS_MAP.items()])
 
     for item in value:
@@ -1945,15 +2057,16 @@
                 )
                 if item == number:
                     ret.append(number)
                     found = True
 
         if not found:
             item = str(item)
-            raise ToolsError(f"Invalid day {item!r} supplied, valid: {valid}")
+            msg = f"Invalid day {item!r} supplied, valid: {valid}"
+            raise ToolsError(msg)
 
     if names:
         ret = [v for k, v in DAYS_MAP.items() if k in ret]
     else:
         ret = [str(k) for k, v in DAYS_MAP.items() if k in ret]
 
     return ret
@@ -1996,15 +2109,17 @@
         return io.BytesIO(value)
     return value
 
 
 def is_json_dict(value) -> bool:
     """Pass."""
     try:
-        check_obj = json.loads(value) if isinstance(value, (str, bytes)) else json.load(value)
+        check_obj = (
+            json.loads(value) if isinstance(value, (str, bytes)) else json.load(value)
+        )
     except Exception:
         pass
     else:
         if isinstance(check_obj, dict):
             return True
     return False
 
@@ -2071,20 +2186,21 @@
             f"Parsed JSON: {ret!r}",
         ]
         log_or_exc(**kwargs)
 
     return ret
 
 
-def is_callable(value: t.Any, attr: t.Optional[str] = None, default: t.Any = None) -> bool:
+def is_callable(
+    value: t.Any,
+    attr: t.Optional[str] = None,
+    default: t.Any = None,
+) -> bool:
     """Pass."""
-    if isinstance(attr, str):
-        check = getattr(value, attr, default)
-    else:
-        check = value
+    check = getattr(value, attr, default) if isinstance(attr, str) else value
     return callable(check)
 
 
 def extract_kvs_csv(
     value: t.Union[str, bytes, t.IO] = None,
     has_headers: bool = False,
     split_kv: str = "=",
@@ -2168,15 +2284,17 @@
     if is_str(value=value) and value.startswith(prefix):
         value = re.compile(value[prefix_len:], re.I)
 
     return value
 
 
 def human_size(
-    value: t.Union[int, str, bytes, float], decimals: int = 2, error: bool = True
+    value: t.Union[int, str, bytes, float],
+    decimals: int = 2,
+    error: bool = True,
 ) -> str:
     """Convert bytes to human-readable.
 
     Args:
         value (t.Union[int, str, bytes, float]): value to coerce into int/float
         decimals (int, optional): number of decimal places to include in str output
 
@@ -2212,23 +2330,28 @@
     except Exception:
         return False
 
 
 def check_tty(value: t.Any, errmsg: str = "unable to prompt"):
     """Pass."""
     if not is_tty(value):
-        raise ToolsError(f"{value!r} is not a TTY -- {errmsg}")
+        msg = f"{value!r} is not a TTY -- {errmsg}"
+        raise ToolsError(msg)
 
 
 def check_tty_stdin():
     """Pass."""
     check_tty(sys.stdin)
 
 
-def get_secho_args(kwargs: t.Optional[dict] = None, key: t.Optional[str] = None, **sargs):
+def get_secho_args(
+    kwargs: t.Optional[dict] = None,
+    key: t.Optional[str] = None,
+    **sargs,
+):
     """Pass."""
     kwargs = kwargs if isinstance(kwargs, dict) else {}
     ret = {}
     skey = f"style_{key}"
 
     for arg in SECHO_ARGS:
         checks = [arg]
@@ -2272,26 +2395,29 @@
         secho_msg = get_secho_args(key="msgs", kwargs=kwargs, **style_msgs)
         click.secho(message=join.join(use_msgs), **secho_msg)
     if is_str(text):
         secho_text = get_secho_args(key="text", kwargs=kwargs, **style_text)
         click.secho(message=text, **secho_text)
     text_confirm = click.style(text_confirm, bold=True)
     answer = click.confirm(
-        text=text_confirm, default=default, abort=abort, err=kwargs.get("stderr", True)
+        text=text_confirm,
+        default=default,
+        abort=abort,
+        err=kwargs.get("stderr", True),
     )
     return answer
 
 
 def coerce_prompt_confirm(value: t.Any = None, prompt: bool = False, **kwargs) -> bool:
     """Pass."""
     kwargs.setdefault("style_msgs", {"fg": "red", "bold": True})
     value: t.Any = coerce_bool(obj=value, error=False)
     if value is not True and prompt is True:
         value: bool = confirm(**kwargs)
-    return True if value is True else False
+    return value is True
 
 
 def check_confirm_prompt(
     reason: str,
     src: t.Any,
     msgs: t.List[str] = None,
     value: t.Any = None,
@@ -2304,15 +2430,18 @@
     msgs = listify(msgs)
     msgs.append(f"Do you really want to {reason}")
     value: bool = coerce_prompt_confirm(msgs=msgs, value=value, prompt=prompt, **kwargs)
     if value is not True:
         raise ConfirmNotTrue(confirm=value, prompt=prompt, reason=reason, src=src)
 
 
-def csv_able(value: t.Optional[t.Union[str, t.List[str]]], sep: str = ",") -> t.List[str]:
+def csv_able(
+    value: t.Optional[t.Union[str, t.List[str]]],
+    sep: str = ",",
+) -> t.List[str]:
     """Pass."""
     ret = []
     if isinstance(value, (list, tuple, set)):
         for item in value:
             ret += [x for x in csv_able(value=item, sep=sep) if x not in ret]
         return ret
 
@@ -2348,28 +2477,23 @@
     return f"{ksource}{source}"
 
 
 # def parse_int_bool(value: t.Any) -> t.Union[int, bool]:
 #     """Pass."""
 #     if isinstance(value, (str, bytes)):
 #         # if bytes, convert to str
-#         value = bytes_to_str(value=value)
 #         # try to coerce to int or float
-#         value = coerce_int_float(value=value, error=False, ret_value=True)
 #         # try to coerce to bool
-#         value = coerce_bool(obj=value, error=False)
-#     return value if isinstance(value, (int, float, bool)) else False
 
 
 # def appendit(values: t.List[t.Any], targets: t.List[list]):
 #     """Pass."""
 #     for target in listify(targets):
 #         for value in listify(values):
 #             if value not in target:
-#                 target.append(value)
 
 
 def parse_value_copy(
     default: str,
     value: t.Optional[str] = None,
     copy_prefix: str = FolderDefaults.copy_prefix,
     existing: t.Optional[t.List[str]] = None,
@@ -2382,17 +2506,14 @@
         value = f"{copy_prefix} {value}"
     return value
 
 
 # def get_hours_ago(value: t.Optional[datetime.datetime] = None, exact: bool = True) -> float:
 #     """Pass."""
 #     if isinstance(value, datetime.datetime):
-#         secs_ago: float = dt_sec_ago(obj=value, exact=exact)
-#         return trim_float(value=secs_ago / 60 / 60)
-#     return None
 
 
 def parse_refresh(
     value: t.Any = REFRESH,
     elapsed: bool = True,
     refresh_elapsed: t.Optional[t.Union[int, float]] = None,
 ) -> bool:
@@ -2443,45 +2564,52 @@
     stop: t.Optional[datetime.datetime] = None,
     places: t.Optional[int] = 5,
 ) -> t.Optional[float]:
     """Pass."""
     seconds: t.Optional[float] = None
     if start is not None:
         start: datetime.datetime = dt_parse(obj=start)
-        if stop is None:
-            stop = dt_now()
-        else:
-            stop = dt_parse(stop)
+        stop = dt_now() if stop is None else dt_parse(stop)
         delta: datetime.timedelta = stop - start
         seconds: float = delta.total_seconds()
         if isinstance(places, int):
             seconds: float = float(f"{seconds:.{places}f}")
     return seconds
 
 
-def score_prefix(value: str, prefix: t.Optional[t.List[str]] = None, join: str = "_") -> str:
+def score_prefix(
+    value: str,
+    prefix: t.Optional[t.List[str]] = None,
+    join: str = "_",
+) -> str:
     """Prefix a value."""
     prefix: t.List[str] = listify(prefix)
     use_prefix: str = f"{join.join(prefix)}{join}" if prefix else ""
-    return f"{use_prefix}{value}" if isinstance(prefix, (list, tuple)) and prefix else value
+    return (
+        f"{use_prefix}{value}"
+        if isinstance(prefix, (list, tuple)) and prefix
+        else value
+    )
 
 
 def get_mm_field(value: t.Any) -> t.Optional[marshmallow.fields.Field]:
     """Get the marshmallow field from a dataclasses field.
 
     Args:
         value: The field to check.
 
     Returns:
         marshmallow.fields.Field: The marshmallow field.
     """
     if isinstance(value, marshmallow.fields.Field):
         return value
     if isinstance(value, dataclasses.Field):
-        return getattr(value, "metadata", {}).get("dataclasses_json", {}).get("mm_field")
+        return (
+            getattr(value, "metadata", {}).get("dataclasses_json", {}).get("mm_field")
+        )
     return None
 
 
 def get_mm_description(value: dataclasses.Field) -> t.Optional[str]:
     """Get the marshmallow description from a dataclasses field.
 
     Args:
@@ -2501,15 +2629,17 @@
 
     Returns:
         bool: True if the field is a nested schema.
     """
     return isinstance(get_nested_schema(value=value), marshmallow.Schema)
 
 
-def get_nested_schema(value: marshmallow.fields.Field) -> t.Optional[marshmallow.Schema]:
+def get_nested_schema(
+    value: marshmallow.fields.Field,
+) -> t.Optional[marshmallow.Schema]:
     """Get the nested schema from a marshmallow field.
 
     Args:
         value: The field to check.
 
     Returns:
         marshmallow.Schema: The nested schema.
@@ -2524,19 +2654,23 @@
         value: If type hint, return the type.
 
     Returns:
         Any: The type if value is a type hint, else None.
     """
     if isinstance(value, type):
         return value
-    args: t.Tuple[t.Any] = t.get_args(value)
+    args: t.Tuple[t.Any] = te.get_args(value)
     return args[0] if len(args) == 1 else args
 
 
-def is_subclass(value: t.Any, expected_types: t.Any = None, as_none: bool = False) -> bool:
+def is_subclass(
+    value: t.Any,
+    expected_types: t.Any = None,
+    as_none: bool = False,
+) -> bool:
     """Determine if value is a subclass of the type for this field."""
     if expected_types is None:
         return as_none
     try:
         return issubclass(value, expected_types)
     except TypeError:
         return False
@@ -2565,15 +2699,17 @@
     try:
         return issubclass(value, expected_type)
     except TypeError:
         return False
 
 
 def trim_value_repr(
-    value: t.Any, max_length: t.Optional[int] = 30, trim_post: t.Optional[str] = TRIM_POST
+    value: t.Any,
+    max_length: t.Optional[int] = 30,
+    trim_post: t.Optional[str] = TRIM_POST,
 ) -> str:
     """Trim the value to a maximum length and appends info about the number of trimmed characters.
 
     Args:
         value: The input value to be trimmed.
         max_length: The maximum allowed length of the value repr.
         trim_post: The string to add
@@ -2609,15 +2745,16 @@
         return float(value)
 
     value = bytes_to_str(value)
     if isinstance(value, str) and value.strip():
         try:
             return float(value.strip())
         except ValueError:
-            raise ValueError(f"Invalid float/integer provided for seconds: {value!r}")
+            msg = f"Invalid float/integer provided for seconds: {value!r}"
+            raise ValueError(msg)
     return None
 
 
 def coerce_delta(value: t.Optional[TypeDelta] = None) -> t.Optional[datetime.timedelta]:
     """Coerce a value to a timedelta.
 
     Args:
```

## axonius_api_client/version.py

```diff
@@ -1,10 +1,10 @@
 # -*- coding: utf-8 -*-
 """Version information for this package."""
-__version__ = "5.0.3"
+__version__ = "5.0.4"
 VERSION: str = __version__
 """Version of package."""
 
 __url__ = "https://github.com/Axonius/axonius_api_client"
 URL: str = __url__
 """URL of package."""
```

## axonius_api_client/api/system/settings.py

```diff
@@ -239,15 +239,15 @@
         """Direct API method to update the system settings.
 
         Args:
             new_config: new system settings to update
         """
         api_endpoint = ApiEndpoints.system_settings.settings_update
         request_obj = api_endpoint.load_request(
-            config=new_config, configNmae=self.CONFIG_NAME, pluginId=self.PLUGIN_NAME
+            config=new_config, configName=self.CONFIG_NAME, pluginId=self.PLUGIN_NAME
         )
         return api_endpoint.perform_request(
             http=self.auth.http,
             request_obj=request_obj,
             plugin_name=self.PLUGIN_NAME,
             config_name=self.CONFIG_NAME,
         )
```

## axonius_api_client/constants/ctypes.py

```diff
@@ -1,34 +1,28 @@
-# -*- coding: utf-8 -*-
 """Custom types."""
 import datetime
 import pathlib
 import typing as t
 
-PathLike: t.TypeVar = t.TypeVar("PathLike", pathlib.Path, str, bytes)
-PatternLike: t.TypeVar = t.TypeVar("PatternLike", t.Pattern, str, bytes)
-PatternLikeListy: t.Type = t.Union[PatternLike, t.Iterable[PatternLike]]
+PathLike = t.TypeVar("PathLike", pathlib.Path, str, bytes)
+PatternLike = t.TypeVar("PatternLike", t.Pattern, str, bytes)
+PatternLikeListy = t.Union[PatternLike, t.Iterable[PatternLike]]
 ComplexLike: t.Tuple[t.Type, ...] = (dict, list, tuple)
 SimpleLike: t.Tuple[t.Type, ...] = (str, int, bool, float)
-Refreshables: t.Type = t.Optional[t.Union[str, bytes, int, float, bool]]
-TypeDate: t.TypeVar = t.TypeVar("TypeDate", str, bytes, datetime.datetime, datetime.timedelta)
-TypeDelta: t.TypeVar = t.TypeVar("TypeDelta", str, bytes, float, int, datetime.timedelta)
-TypeFloat: t.TypeVar = t.TypeVar("TypeFloat", float, int, str, bytes)
-TypeMatch: t.TypeVar = t.TypeVar(
+Refreshables = t.Optional[t.Union[str, bytes, int, float, bool]]
+TypeDate = t.TypeVar("TypeDate", str, bytes, datetime.datetime, datetime.timedelta)
+TypeDelta = t.TypeVar("TypeDelta", str, bytes, float, int, datetime.timedelta)
+TypeFloat = t.TypeVar("TypeFloat", float, int, str, bytes)
+TypeMatch = t.TypeVar(
     "TypeMatch",
     str,
     bytes,
     t.Pattern,
     t.List[t.Union[str, bytes, t.Pattern]],
     t.Tuple[t.Union[str, bytes, t.Pattern]],
 )
-TypeInt: t.TypeVar = t.TypeVar("TypeInt", int, str, bytes)
-TypeBool: t.TypeVar = t.TypeVar("TypeBool", bool, str, bytes, int, float)
+TypeInt = t.TypeVar("TypeInt", int, str, bytes)
+TypeBool = t.TypeVar("TypeBool", bool, str, bytes, int, float)
 
 
 class FolderBase:
     """baseclass for all folder types."""
-
-
-# STR_RE = t.Union[str, t.Pattern]
-# STR_RE_LISTY = t.Union[STR_RE, t.List[STR_RE]]
-# OPT_STR_RE_LISTY = t.Optional[STR_RE_LISTY]
```

## axonius_api_client/tests/tests_pkg/test_http.py

```diff
@@ -9,15 +9,20 @@
 
 from axonius_api_client.exceptions import HttpError
 from axonius_api_client.http import Http
 from axonius_api_client.projects.url_parser import UrlParser
 from axonius_api_client.projects import cert_human
 from axonius_api_client.version import __version__
 
-from ..meta import TEST_CLIENT_CERT, TEST_CLIENT_CERT_NAME, TEST_CLIENT_KEY, TEST_CLIENT_KEY_NAME
+from ..meta import (
+    TEST_CLIENT_CERT,
+    TEST_CLIENT_CERT_NAME,
+    TEST_CLIENT_KEY,
+    TEST_CLIENT_KEY_NAME,
+)
 from ..utils import (
     get_arg_url,
     log_check,
     get_http,
 )
 
 InsecureRequestWarning = urllib3.exceptions.InsecureRequestWarning
@@ -43,27 +48,27 @@
 
     def test_user_agent(self, request):
         """Test user_agent has version in it."""
         ax_url = get_arg_url(request)
         http = Http(url=ax_url)
         assert __version__ in http.user_agent
 
-    def test_certwarn_true(self, httpbin_secure):
-        url = httpbin_secure.url
-        http = Http(url=url, certwarn=True, save_history=True)
-        with pytest.warns(InsecureRequestWarning):
-            http()
-
-    def test_certwarn_false(self, httpbin_secure):
-        url = httpbin_secure.url
-        http = Http(url=url, certwarn=False)
-        with pytest.warns() as record:
-            response = http()
-        assert response
-        assert record
+    # def test_certwarn_true(self, httpbin_secure):
+    #     url = httpbin_secure.url
+    #     http = Http(url=url, certwarn=True, save_history=True)
+    #     with pytest.warns(InsecureRequestWarning):
+    #         http()
+
+    # def test_certwarn_false(self, httpbin_secure):
+    #     url = httpbin_secure.url
+    #     http = Http(url=url, certwarn=False)
+    #     with pytest.warns() as record:
+    #         response = http()
+    #     assert response
+    #     assert record
 
     def test_save_last_true(self, request):
         """Test last req/resp with save_last=True."""
         ax_url = get_arg_url(request)
         http = Http(url=ax_url, save_last=True, certwarn=False)
         with pytest.warns() as record:
             response = http()
@@ -136,15 +141,17 @@
             response = http()
         assert response
         assert record
 
     def test_log_req_attrs_true(self, request, caplog):
         """Test verbose logging of request attrs when log_request_attrs=True."""
         caplog.set_level(logging.DEBUG)
-        http = get_http(request, log_request_attrs=["url", "headers"], log_level="debug")
+        http = get_http(
+            request, log_request_attrs=["url", "headers"], log_level="debug"
+        )
         with pytest.warns() as record:
             response = http()
         assert response
         assert record
         entries = ["REQUEST ATTRS:.*{}.*headers".format(http.url)]
         log_check(caplog, entries)
 
@@ -158,15 +165,17 @@
         assert record
         entries = ["REQUEST ATTRS:"]
         log_check(caplog, entries, exists=False)
 
     def test_log_resp_attrs_true(self, request, caplog):
         """Test verbose logging of response attrs when log_response_attrs=True."""
         caplog.set_level(logging.DEBUG)
-        http = get_http(request, log_response_attrs=["url", "headers"], log_level="debug")
+        http = get_http(
+            request, log_response_attrs=["url", "headers"], log_level="debug"
+        )
         with pytest.warns() as record:
             response = http()
         assert response
         assert record
         entries = ["RESPONSE ATTRS:.*url.*headers"]
         log_check(caplog, entries)
 
@@ -177,15 +186,17 @@
         assert isinstance(cert, cert_human.Cert)
 
     def test_get_cert_chain(self, request):
         """Test get_cert_chain."""
         http = get_http(request)
         chain = http.get_cert_chain()
         assert (
-            isinstance(chain, list) and chain and all(isinstance(c, cert_human.Cert) for c in chain)
+            isinstance(chain, list)
+            and chain
+            and all(isinstance(c, cert_human.Cert) for c in chain)
         )
 
     def test_safe_request(self, request):
         """Test safe request."""
         http = get_http(request)
         data = http.safe_request(path="/force_error", method="POST")
         assert isinstance(data, requests.Response) or data is None
```

## Comparing `axonius_api_client-5.0.3.dist-info/LICENSE` & `axonius_api_client-5.0.4.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `axonius_api_client-5.0.3.dist-info/METADATA` & `axonius_api_client-5.0.4.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: axonius-api-client
-Version: 5.0.3
+Version: 5.0.4
 Summary: Axonius API client for Python
 Home-page: https://github.com/Axonius/axonius_api_client
 Author: Axonius
 Author-email: support@axonius.com
 License: MIT
 Keywords: Axonius,API Library
 Classifier: Development Status :: 5 - Production/Stable
```

## Comparing `axonius_api_client-5.0.3.dist-info/RECORD` & `axonius_api_client-5.0.4.dist-info/RECORD`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 axonius_api_client/__init__.py,sha256=dEYcOBOzi19UogZ5J8lH8LZke1Tbslk71_hcGKvBfjc,3139
-axonius_api_client/connect.py,sha256=HyGmfJqcKK14NEhjDUHoblpN4Wsz0-DUHF2jNWjmYJ4,34635
+axonius_api_client/connect.py,sha256=j5DmJyw2Mor-CC0AZGWAL_Nalsu7kTNG7R6M2pm9N6M,35191
 axonius_api_client/data.py,sha256=H1RleG9w98ks7z-GR69V4Q-lIhQa6h-A_IteDmXT5yg,4025
-axonius_api_client/exceptions.py,sha256=5H3st4FfZupKTHj-xkrUzWUiUoVzUq6q2iTuUBOMrQ0,15429
+axonius_api_client/exceptions.py,sha256=8kWgpVkA6xXRmWlteIDRsmWwonXlKSgA7-OvRVsOpbM,15664
 axonius_api_client/features.py,sha256=QCpHgAkbfDxELQvE4CWiksR8RvGEPI51_Dm6xNl7DPQ,5153
-axonius_api_client/http.py,sha256=bF3RT3no7mqb7AAWnyG_ihAWfNL_9YdC_fvrmR0u7sw,31439
+axonius_api_client/http.py,sha256=1TiKKKwqg8cenjj6oIKk2a26HO2UKcW37JZMfpvkseg,32317
 axonius_api_client/logs.py,sha256=fy-5p_MI6OH47InlzIxh2e8DjEqV3P9V9qT3h50kt4A,12568
 axonius_api_client/setup_env.py,sha256=eX9pkRR7wrlptopBgBKVCvM-OqPFaVJUTuXhlwcMLQ8,23869
-axonius_api_client/tools.py,sha256=RG2RKZDaTD086CtwD1DZIRBgWMys97knVTPcD9VPgdA,76766
-axonius_api_client/version.py,sha256=8uUKdY43nIjn_M1gPe2MDxwejmcaiheN5B0xFnOUWvQ,1021
+axonius_api_client/tools.py,sha256=WJoCGLMCmtvp212SdlNpZs5yo503UP6w642uPgdmAOE,77381
+axonius_api_client/version.py,sha256=ylkoKXmDUs8qi3hSNPS_tDNB_Q-Jv63qFsMttTyaL4Q,1021
 axonius_api_client/api/__init__.py,sha256=yRStW-3A0p-HZpvZf7HevljPmT5vmSCJv95wycx6i94,1368
 axonius_api_client/api/api_endpoint.py,sha256=T2ybS4lWAIHm_TpfbDuDF9MWMpAd44291sEbiHLdPYg,19821
 axonius_api_client/api/api_endpoints.py,sha256=heDb5XvCOWFoqx4lo-hBrVQhVMMTroTh0xNGB95acm0,54346
 axonius_api_client/api/mixins.py,sha256=Syvx-KCgdLBouth1XU_EetP2k3BDaGlkSrS9AHnyntQ,3284
 axonius_api_client/api/adapters/__init__.py,sha256=_cKJH5Ymo596vGRaQ5M-0CPZkvMbfUkixp1vRq1_lk8,161
 axonius_api_client/api/adapters/adapters.py,sha256=v0ypvrFXme-VL14FjzM_w2KXu0zSD3Oj6kNKRlFuJnM,25244
 axonius_api_client/api/adapters/cnx.py,sha256=DQMNRi2NnfDlltx6RnR2kxJ0RajyyZDm446Kv0QgjCQ,46857
@@ -127,15 +127,15 @@
 axonius_api_client/api/system/activity_logs.py,sha256=Wo1zGiPmK3YDS-CLxVaJT-Ap3U3xTcnkIYXe65iEf0I,3987
 axonius_api_client/api/system/dashboard.py,sha256=MxlL33bSNf7brQz5aMRUdAHh58vNCsaGbgTth4k73-k,11606
 axonius_api_client/api/system/dashboard_spaces.py,sha256=EnJThN8DFCprMg70d-Qq5ewAujbxe0B9BRm_Ocx975I,14794
 axonius_api_client/api/system/data_scopes.py,sha256=cR89OI8h2hwd8A6toRaCerIHLEVPHYLCR-QOBQepbZs,12622
 axonius_api_client/api/system/instances.py,sha256=OhYEiwA0H-mY80hiUzkCGJEJ9LLdN41mqkqV0_-wPVc,28157
 axonius_api_client/api/system/meta.py,sha256=WzA5b9XnurQ-X6MSqvWXOvFfCsvw5BHAzbrS9WuwH-Q,3778
 axonius_api_client/api/system/remote_support.py,sha256=grXFFzo61wQzoV3v7Cw6Z4sihKlVzcNy1OVA1ugvxMY,3966
-axonius_api_client/api/system/settings.py,sha256=355FTg0Emdb4NuLrol5ayoKi5HbvibsoYemtqncWRf0,21550
+axonius_api_client/api/system/settings.py,sha256=9QLTAfsoP_LAlh7x1KGiq7mkBNurfoF_TjZ6O-v6xtE,21550
 axonius_api_client/api/system/signup.py,sha256=5wiPledEMNrnVecF4OaKUfg5I3bCwCDqaQwDl1Juu7c,6590
 axonius_api_client/api/system/system_roles.py,sha256=DOmM1m6Sbtzu68px2qbWDett8615l_lYwq14fDTiCio,19278
 axonius_api_client/api/system/system_users.py,sha256=U-eQYjB_CJsVnKmxVHZquBNByjS3114y7hAQ6paRCZ0,19313
 axonius_api_client/api/wizards/__init__.py,sha256=pj-lzzzKi6Xvq7txit3WsKvFGbSSty_98hzSHqhlO58,236
 axonius_api_client/api/wizards/wizard.py,sha256=acXbd7QrzVF-uVOms5pLh1sdZVaQCOg8fBI1x5gqoDA,22147
 axonius_api_client/api/wizards/wizard_csv.py,sha256=JJEt0kKnKtITqjhKDDIcTxZxXeYVdOZIYehAwn_L4TY,12635
 axonius_api_client/api/wizards/wizard_text.py,sha256=g-Y9Lbkh7eaXFrRmMZAFf0Z5v3jhQnaXAW9jMRnNax4,4997
@@ -355,15 +355,15 @@
 axonius_api_client/cli/grp_tools/cmd_write_config.py,sha256=NbljLN-TpaoMAHb5mH-rlGv4PC0By3RfZf28jAN8tsM,677
 axonius_api_client/cli/grp_tools/grp_common.py,sha256=dF4vIW4jtTjmLcW0-hW-1wY61HR6euF2MTkJTS78yfU,2101
 axonius_api_client/cli/grp_tools/grp_options.py,sha256=N6EAywbXkaslCE5Gqhu3Op0tECDv1srZNgaG2Xsi6Ho,554
 axonius_api_client/constants/__init__.py,sha256=hIMu5lK5c_MM2bzsTRpr8KhWbq26TeSxQvvSgZ2gTiI,334
 axonius_api_client/constants/adapters.py,sha256=gIe9bVsVOCWxU1dGqRE8FdSkBcXSLHLyvf7lyVll8sU,2973
 axonius_api_client/constants/api.py,sha256=97lpzVqYs8RtPUVhCzFNd19lwyQV2ImhEI0VwL6VYT0,2868
 axonius_api_client/constants/asset_helpers.py,sha256=SvJAyKXW3bdQ3ql8SWJ6JOtsJ2kPH9QTG-IWe9sJtG8,18484
-axonius_api_client/constants/ctypes.py,sha256=FiVVkUk7SgQjGoju6cUdBoNHMDozntaICso72Qq5PPA,1258
+axonius_api_client/constants/ctypes.py,sha256=4Smk3ugUHV3BxED789emaa5RbOEaZn9Kfc2XSn_0cXA,998
 axonius_api_client/constants/enforcements.py,sha256=9o5TQ1mVjYrKkZTWbKuwEwgCipd5vT2TZwQBqe6PF1w,5056
 axonius_api_client/constants/fields.py,sha256=_nP7PQsC1qD2_d0mzTLsMLu-n_3JOPkfT9Uw4A6OBjA,38018
 axonius_api_client/constants/general.py,sha256=yYDgkT9bcjdR2zAiTdgFLNWfmr6_PAINmiK6SCvy-pI,2669
 axonius_api_client/constants/logs.py,sha256=203BzqlLYA-ZPEKwOtpzKTH0nDFAJxnreMg9idv-Rz0,4180
 axonius_api_client/constants/tables.py,sha256=iFDcIz7gt6mHgF88L2X2ZEvnEYwc8QfBtv6NhGWSmXg,1151
 axonius_api_client/constants/wizards.py,sha256=wEqxuDoWZSSp5v3b5TIJc0tCHUwBYVy7bLPo3VJPtdc,15197
 axonius_api_client/examples/__init__.py,sha256=J2HXxzf9cqBgfqeF3DarsDA98Jzoq3e17ks5NWjknXk,119
@@ -588,18 +588,18 @@
 axonius_api_client/tests/tests_cli/tests_grp_tools/__init__.py,sha256=EeC6RMJKsW54bbcwIfBnxDnLkBUDbq0DJ1_Ey_fiFgI,42
 axonius_api_client/tests/tests_cli/tests_grp_tools/test_cmd_shell.py,sha256=XgPAKfZjt3WxnvBUgKGFWUkk3xUR27UzKNfX02yFM0E,5082
 axonius_api_client/tests/tests_cli/tests_grp_tools/test_cmd_sysinfo.py,sha256=aHh_pVp70BKk5nTlUETP0y51weW540DQLBvEyq0PD68,995
 axonius_api_client/tests/tests_cli/tests_grp_tools/test_cmd_write_config.py,sha256=jgGDiUD-tbXOwl3yUicYUX5QE6tZXN1vUiWN7tT76a4,1271
 axonius_api_client/tests/tests_pkg/__init__.py,sha256=EeC6RMJKsW54bbcwIfBnxDnLkBUDbq0DJ1_Ey_fiFgI,42
 axonius_api_client/tests/tests_pkg/test_connect.py,sha256=pfHWyoP7-XvEjGKQSzCFKLQME5d5Q79YSFpxLPfY0ko,6783
 axonius_api_client/tests/tests_pkg/test_data.py,sha256=k3iL7D1Q-Dd3R0_3XXXXbg3KKWCJtglu4TZhGb4cJCg,2481
-axonius_api_client/tests/tests_pkg/test_http.py,sha256=RvVf3vqgv7WZ7Rd1pUE_kCqC0SxERF7YJgL_2a9nG4o,9914
+axonius_api_client/tests/tests_pkg/test_http.py,sha256=25r0oo1VNp73znnZ83PPfUi55sSh-LXvSf39GVzIWiI,10027
 axonius_api_client/tests/tests_pkg/test_logs.py,sha256=bqIx4r3om-nEe_8Lg_T40jhbaYyOabH8DSyQYfXgZm0,4045
 axonius_api_client/tests/tests_pkg/test_setup_env.py,sha256=5GgAYAqehKAW-F_4rGebtDe4Ji9nUXVekaxorJM5UCs,8318
 axonius_api_client/tests/tests_pkg/test_tools.py,sha256=AydEs5mijbeFn0BCC7L2xBJcGy6dyYznWZvndQ20g4o,42244
 axonius_api_client/tests/tests_pkg/test_url_parser.py,sha256=YdQ5sE7x8UyXcl1UzjGx6FYbOYuRGTktF7boxNt-Iqo,3189
-axonius_api_client-5.0.3.dist-info/LICENSE,sha256=D2xtlW7XSDr0U5FMGUUkBNZGOP7jeWjnmmHdBuE5SpE,1064
-axonius_api_client-5.0.3.dist-info/METADATA,sha256=bPMqGx4KJ61XjM4R7OrtmAorWI2rkL0htC5HQSIZCAw,2767
-axonius_api_client-5.0.3.dist-info/WHEEL,sha256=a-zpFRIJzOq5QfuhBzbhiA1eHTzNCJn8OdRvhdNX0Rk,110
-axonius_api_client-5.0.3.dist-info/entry_points.txt,sha256=m7s3YZRnG6lOa94ExOVHS35-ys79ncmsiyuGaU0q5NQ,57
-axonius_api_client-5.0.3.dist-info/top_level.txt,sha256=PujMecHFuFDWI-PaRPMS52vnGmVv-4pSOxud44wiO30,19
-axonius_api_client-5.0.3.dist-info/RECORD,,
+axonius_api_client-5.0.4.dist-info/LICENSE,sha256=D2xtlW7XSDr0U5FMGUUkBNZGOP7jeWjnmmHdBuE5SpE,1064
+axonius_api_client-5.0.4.dist-info/METADATA,sha256=VRuzz2UdUdmRXb6h4JtaReN5OZ7KQ55eb4IFk9rs1z4,2767
+axonius_api_client-5.0.4.dist-info/WHEEL,sha256=a-zpFRIJzOq5QfuhBzbhiA1eHTzNCJn8OdRvhdNX0Rk,110
+axonius_api_client-5.0.4.dist-info/entry_points.txt,sha256=m7s3YZRnG6lOa94ExOVHS35-ys79ncmsiyuGaU0q5NQ,57
+axonius_api_client-5.0.4.dist-info/top_level.txt,sha256=PujMecHFuFDWI-PaRPMS52vnGmVv-4pSOxud44wiO30,19
+axonius_api_client-5.0.4.dist-info/RECORD,,
```

