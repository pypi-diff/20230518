# Comparing `tmp/datarobot_mlops-9.1.1b1-py3-none-any.whl.zip` & `tmp/datarobot_mlops-9.1.1rc1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,40 +1,40 @@
-Zip file size: 88918 bytes, number of entries: 38
--rw-r--r--  2.0 unx      597 b- defN 23-Mar-27 23:33 datarobot/mlops/__init__.py
--rw-r--r--  2.0 unx    21276 b- defN 23-Mar-27 23:33 datarobot/mlops/agent.py
--rw-r--r--  2.0 unx     1023 b- defN 23-Mar-27 23:33 datarobot/mlops/constants.py
--rw-r--r--  2.0 unx     4241 b- defN 23-Mar-27 23:33 datarobot/mlops/event.py
--rw-r--r--  2.0 unx     3068 b- defN 23-Mar-27 23:33 datarobot/mlops/json_shim.py
--rw-r--r--  2.0 unx    30722 b- defN 23-Mar-27 23:33 datarobot/mlops/metric.py
--rw-r--r--  2.0 unx    39436 b- defN 23-Mar-27 23:33 datarobot/mlops/mlops.py
--rw-r--r--  2.0 unx    43371 b- defN 23-Mar-27 23:33 datarobot/mlops/model.py
--rw-r--r--  2.0 unx      532 b- defN 23-Mar-27 23:33 datarobot/mlops/channel/__init__.py
--rw-r--r--  2.0 unx    19171 b- defN 23-Mar-27 23:33 datarobot/mlops/channel/output_channel_queue.py
--rw-r--r--  2.0 unx    13375 b- defN 23-Mar-27 23:33 datarobot/mlops/channel/record.py
--rw-r--r--  2.0 unx      532 b- defN 23-Mar-27 23:33 datarobot/mlops/common/__init__.py
--rw-r--r--  2.0 unx     8149 b- defN 23-Mar-27 23:33 datarobot/mlops/common/aggregation_util.py
--rw-r--r--  2.0 unx    16970 b- defN 23-Mar-27 23:33 datarobot/mlops/common/config.py
--rw-r--r--  2.0 unx     2409 b- defN 23-Mar-27 23:33 datarobot/mlops/common/enums.py
--rw-r--r--  2.0 unx     1081 b- defN 23-Mar-27 23:33 datarobot/mlops/common/exception.py
--rw-r--r--  2.0 unx     2182 b- defN 23-Mar-27 23:33 datarobot/mlops/common/prediction_util.py
--rw-r--r--  2.0 unx      861 b- defN 23-Mar-27 23:33 datarobot/mlops/common/singleton.py
--rw-r--r--  2.0 unx      919 b- defN 23-Mar-27 23:33 datarobot/mlops/common/stringutil.py
--rw-r--r--  2.0 unx     3872 b- defN 23-Mar-27 23:33 datarobot/mlops/common/version_util.py
--rw-r--r--  2.0 unx      532 b- defN 23-Mar-27 23:33 datarobot/mlops/spooler/__init__.py
--rw-r--r--  2.0 unx     7227 b- defN 23-Mar-27 23:33 datarobot/mlops/spooler/async_memory_spooler.py
--rw-r--r--  2.0 unx    34711 b- defN 23-Mar-27 23:33 datarobot/mlops/spooler/filesystem_spooler.py
--rw-r--r--  2.0 unx    21987 b- defN 23-Mar-27 23:33 datarobot/mlops/spooler/kafka_spooler.py
--rw-r--r--  2.0 unx     6972 b- defN 23-Mar-27 23:33 datarobot/mlops/spooler/memory_spooler.py
--rw-r--r--  2.0 unx    12434 b- defN 23-Mar-27 23:33 datarobot/mlops/spooler/pubsub_spooler.py
--rw-r--r--  2.0 unx    10100 b- defN 23-Mar-27 23:33 datarobot/mlops/spooler/rabbitmq_spooler.py
--rw-r--r--  2.0 unx     4413 b- defN 23-Mar-27 23:33 datarobot/mlops/spooler/record_spooler.py
--rw-r--r--  2.0 unx     4466 b- defN 23-Mar-27 23:33 datarobot/mlops/spooler/record_spooler_factory.py
--rw-r--r--  2.0 unx     4454 b- defN 23-Mar-27 23:33 datarobot/mlops/spooler/spooler_offset_manager.py
--rw-r--r--  2.0 unx    10369 b- defN 23-Mar-27 23:33 datarobot/mlops/spooler/sqs_spool.py
--rw-r--r--  2.0 unx     2212 b- defN 23-Mar-27 23:33 datarobot/mlops/spooler/stdout_spooler.py
--rw-r--r--  2.0 unx     2570 b- defN 23-Mar-27 23:38 datarobot_mlops-9.1.1b1.data/data/share/mlops/agent.yaml
--rw-r--r--  2.0 unx     1395 b- defN 23-Mar-27 23:38 datarobot_mlops-9.1.1b1.data/data/share/mlops/mlops.log4j2.properties
--rw-r--r--  2.0 unx     3107 b- defN 23-Mar-27 23:38 datarobot_mlops-9.1.1b1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Mar-27 23:38 datarobot_mlops-9.1.1b1.dist-info/WHEEL
--rw-r--r--  2.0 unx       10 b- defN 23-Mar-27 23:38 datarobot_mlops-9.1.1b1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     3558 b- defN 23-Mar-27 23:38 datarobot_mlops-9.1.1b1.dist-info/RECORD
-38 files, 344396 bytes uncompressed, 83120 bytes compressed:  75.9%
+Zip file size: 88953 bytes, number of entries: 38
+-rw-r--r--  2.0 unx      597 b- defN 23-May-18 21:10 datarobot/mlops/__init__.py
+-rw-r--r--  2.0 unx    21276 b- defN 23-May-18 21:10 datarobot/mlops/agent.py
+-rw-r--r--  2.0 unx     1021 b- defN 23-May-18 21:10 datarobot/mlops/constants.py
+-rw-r--r--  2.0 unx     4241 b- defN 23-May-18 21:10 datarobot/mlops/event.py
+-rw-r--r--  2.0 unx     3068 b- defN 23-May-18 21:10 datarobot/mlops/json_shim.py
+-rw-r--r--  2.0 unx    30588 b- defN 23-May-18 21:10 datarobot/mlops/metric.py
+-rw-r--r--  2.0 unx    39285 b- defN 23-May-18 21:10 datarobot/mlops/mlops.py
+-rw-r--r--  2.0 unx    43371 b- defN 23-May-18 21:10 datarobot/mlops/model.py
+-rw-r--r--  2.0 unx      532 b- defN 23-May-18 21:10 datarobot/mlops/channel/__init__.py
+-rw-r--r--  2.0 unx    19054 b- defN 23-May-18 21:10 datarobot/mlops/channel/output_channel_queue.py
+-rw-r--r--  2.0 unx    13375 b- defN 23-May-18 21:10 datarobot/mlops/channel/record.py
+-rw-r--r--  2.0 unx      532 b- defN 23-May-18 21:10 datarobot/mlops/common/__init__.py
+-rw-r--r--  2.0 unx     8149 b- defN 23-May-18 21:10 datarobot/mlops/common/aggregation_util.py
+-rw-r--r--  2.0 unx    17052 b- defN 23-May-18 21:10 datarobot/mlops/common/config.py
+-rw-r--r--  2.0 unx     2409 b- defN 23-May-18 21:10 datarobot/mlops/common/enums.py
+-rw-r--r--  2.0 unx     1081 b- defN 23-May-18 21:10 datarobot/mlops/common/exception.py
+-rw-r--r--  2.0 unx     2182 b- defN 23-May-18 21:10 datarobot/mlops/common/prediction_util.py
+-rw-r--r--  2.0 unx      861 b- defN 23-May-18 21:10 datarobot/mlops/common/singleton.py
+-rw-r--r--  2.0 unx      919 b- defN 23-May-18 21:10 datarobot/mlops/common/stringutil.py
+-rw-r--r--  2.0 unx     3872 b- defN 23-May-18 21:10 datarobot/mlops/common/version_util.py
+-rw-r--r--  2.0 unx      532 b- defN 23-May-18 21:10 datarobot/mlops/spooler/__init__.py
+-rw-r--r--  2.0 unx     7227 b- defN 23-May-18 21:10 datarobot/mlops/spooler/async_memory_spooler.py
+-rw-r--r--  2.0 unx    34711 b- defN 23-May-18 21:10 datarobot/mlops/spooler/filesystem_spooler.py
+-rw-r--r--  2.0 unx    22027 b- defN 23-May-18 21:10 datarobot/mlops/spooler/kafka_spooler.py
+-rw-r--r--  2.0 unx     6972 b- defN 23-May-18 21:10 datarobot/mlops/spooler/memory_spooler.py
+-rw-r--r--  2.0 unx    12434 b- defN 23-May-18 21:10 datarobot/mlops/spooler/pubsub_spooler.py
+-rw-r--r--  2.0 unx    10337 b- defN 23-May-18 21:10 datarobot/mlops/spooler/rabbitmq_spooler.py
+-rw-r--r--  2.0 unx     4666 b- defN 23-May-18 21:10 datarobot/mlops/spooler/record_spooler.py
+-rw-r--r--  2.0 unx     4466 b- defN 23-May-18 21:10 datarobot/mlops/spooler/record_spooler_factory.py
+-rw-r--r--  2.0 unx     4454 b- defN 23-May-18 21:10 datarobot/mlops/spooler/spooler_offset_manager.py
+-rw-r--r--  2.0 unx    10369 b- defN 23-May-18 21:10 datarobot/mlops/spooler/sqs_spool.py
+-rw-r--r--  2.0 unx     2212 b- defN 23-May-18 21:10 datarobot/mlops/spooler/stdout_spooler.py
+-rw-r--r--  2.0 unx     2570 b- defN 23-May-18 21:15 datarobot_mlops-9.1.1rc1.data/data/share/mlops/agent.yaml
+-rw-r--r--  2.0 unx     1395 b- defN 23-May-18 21:15 datarobot_mlops-9.1.1rc1.data/data/share/mlops/mlops.log4j2.properties
+-rw-r--r--  2.0 unx     3102 b- defN 23-May-18 21:15 datarobot_mlops-9.1.1rc1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-18 21:15 datarobot_mlops-9.1.1rc1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       10 b- defN 23-May-18 21:15 datarobot_mlops-9.1.1rc1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     3564 b- defN 23-May-18 21:15 datarobot_mlops-9.1.1rc1.dist-info/RECORD
+38 files, 344605 bytes uncompressed, 83143 bytes compressed:  75.9%
```

## zipnote {}

```diff
@@ -90,26 +90,26 @@
 
 Filename: datarobot/mlops/spooler/sqs_spool.py
 Comment: 
 
 Filename: datarobot/mlops/spooler/stdout_spooler.py
 Comment: 
 
-Filename: datarobot_mlops-9.1.1b1.data/data/share/mlops/agent.yaml
+Filename: datarobot_mlops-9.1.1rc1.data/data/share/mlops/agent.yaml
 Comment: 
 
-Filename: datarobot_mlops-9.1.1b1.data/data/share/mlops/mlops.log4j2.properties
+Filename: datarobot_mlops-9.1.1rc1.data/data/share/mlops/mlops.log4j2.properties
 Comment: 
 
-Filename: datarobot_mlops-9.1.1b1.dist-info/METADATA
+Filename: datarobot_mlops-9.1.1rc1.dist-info/METADATA
 Comment: 
 
-Filename: datarobot_mlops-9.1.1b1.dist-info/WHEEL
+Filename: datarobot_mlops-9.1.1rc1.dist-info/WHEEL
 Comment: 
 
-Filename: datarobot_mlops-9.1.1b1.dist-info/top_level.txt
+Filename: datarobot_mlops-9.1.1rc1.dist-info/top_level.txt
 Comment: 
 
-Filename: datarobot_mlops-9.1.1b1.dist-info/RECORD
+Filename: datarobot_mlops-9.1.1rc1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## datarobot/mlops/constants.py

```diff
@@ -15,15 +15,15 @@
 
 class Constants:
     """
     Various constants related to MLOps
     """
 
     OFFICIAL_NAME = "datarobot-mlops"
-    MLOPS_VERSION = "9.1.1-beta.1"
+    MLOPS_VERSION = "9.1.1-rc.1"
 
     # Constants used to upload actuals
     ACTUALS_ASSOCIATION_ID_KEY = "associationId"
     ACTUALS_WAS_ACTED_ON_KEY = "wasActedOn"
     ACTUALS_TIMESTAMP_KEY = "timestamp"
     ACTUALS_VALUE_KEY = "actualValue"
```

## datarobot/mlops/metric.py

```diff
@@ -65,15 +65,14 @@
     class DeploymentStatsConstants:
         NUM_PREDICTIONS_FIELD_NAME = "numPredictions"
         EXECUTION_TIME_FIELD_NAME = "executionTime"
 
     class CustomMetricStatsConstants:
         BUCKETS_FIELD_NAME = "buckets"
         METRIC_ID_FIELD_NAME = "customMetricId"
-        MODEL_PACKAGE_ID_FIELD_NAME = "modelPackageId"
         METRIC_VALUE_FIELD_NAME = "value"
 
     class PredictionsStatsConstants:
         PREDICTIONS_FIELD_NAME = "predictions"
         ASSOCIATION_IDS_FIELD_NAME = "associationIds"
         RESULTS_FIELD_NAME = "results"
         CLASS_NAMES_FIELD_NAME = "classNames"
@@ -414,17 +413,14 @@
 
 
 class CustomMetricContainer(StatsContainer):
     """
     Custom Metric data formatter.
     """
 
-    MODEL_PACKAGE_ID_FIELD_NAME = (
-        SerializationConstants.CustomMetricStatsConstants.MODEL_PACKAGE_ID_FIELD_NAME
-    )
     METRIC_ID_FIELD_NAME = SerializationConstants.CustomMetricStatsConstants.METRIC_ID_FIELD_NAME
     METRIC_VALUE_FIELD_NAME = (
         SerializationConstants.CustomMetricStatsConstants.METRIC_VALUE_FIELD_NAME
     )
     TIMESTAMP_FIELD_NAME = SerializationConstants.GeneralConstants.TIMESTAMP_FIELD_NAME
     BUCKETS_FIELD_NAME = SerializationConstants.CustomMetricStatsConstants.BUCKETS_FIELD_NAME
 
@@ -472,15 +468,17 @@
             "buckets": [
                 {"timestamp": "2016-12-13T11:12:13.141516Z", "value": 10.0},
                 {"timestamp": "2016-12-13T11:12:14.565122Z", "value": 20.0},
             ],
         }
         """
         ret = dict()
-        ret[self.MODEL_PACKAGE_ID_FIELD_NAME] = self._general_stats.get_model_id()
+        ret[
+            SerializationConstants.GeneralConstants.MODEL_ID_FIELD_NAME
+        ] = self._general_stats.get_model_id()
         ret[self.METRIC_ID_FIELD_NAME] = self._custom_metric.get_metric_id()
 
         buckets = []
         for value, timestamp in zip(
             self._custom_metric.get_values(), self._custom_metric.get_timestamps()
         ):
             buckets.append(
```

## datarobot/mlops/mlops.py

```diff
@@ -869,58 +869,60 @@
         :param deployment_id: the deployment for these metrics
         :type deployment_id: str, optional
         """
         self._validate()
         _deployment_id = self._get_id(deployment_id, ConfigConstants.DEPLOYMENT_ID)
         self._model.report_event(_deployment_id, None, event)
 
-    # Reporting custom metrics is not complete for 9.0. Removing the interface.
-    # def report_deployment_metric(self, metric_id, value, timestamp=None, deployment_id=None):
-    #     """
-    #     Report a custom deployment metric back to DataRobot MLOps.
-    #     The metric must be created prior to reporting.
-    #     This method reports a deployment metric.
-    #
-    #     :param metric_id: Metric ID to report
-    #     :type metric_id: str
-    #     :param value: The numeric value to report for the metric
-    #     :type value: float
-    #     :param timestamp: Timestamp to use for reporting the metric
-    #     :type timestamp: str, optional
-    #     :param deployment_id: Deployment to report metric for
-    #     :type deployment_id: str, optional
-    #     """
-    #     self._validate()
-    #     _deployment_id = self._get_id(deployment_id, ConfigConstants.DEPLOYMENT_ID)
-    #     self._model.report_custom_metric(_deployment_id, None, metric_id, value, timestamp)
-
-    # def report_model_metric(self, metric_id, value, timestamp=None, deployment_id=None,
-    #                         model_id=None):
-    #     """
-    #     Report a custom model metric back to DataRobot MLOps.
-    #     The metric must be created prior to reporting.
-    #     This method reports a model metric, so both deployment and model IDs are required to be
-    #     available.
-    #
-    #     :param metric_id:
-    #     :type metric_id: str
-    #     :param value: The numeric value to report for the metric
-    #     :type value: float
-    #     :param timestamp:
-    #     :param deployment_id: Deployment Id to use for reporting the metric - if None, then taking
-    #                 from environment or using the default deployment if set.
-    #     :type deployment_id: str, optional
-    #     :param model_id: Model ID to use for reporting the metric - if None, then taking from
-    #                 configuration.
-    #     :type model_id: str, optional
-    #     """
-    #     self._validate()
-    #     _deployment_id = self._get_id(deployment_id, ConfigConstants.DEPLOYMENT_ID)
-    #     _model_id = self._get_id(model_id, ConfigConstants.MODEL_ID)
-    #     self._model.report_custom_metric(_deployment_id, _model_id, metric_id, value, timestamp)
+    def report_deployment_metric(
+        self, metric_id, value, timestamp=None, deployment_id=None, model_id=None
+    ):
+        """
+        Report a custom deployment metric back to DataRobot MLOps.
+        The metric must be created prior to reporting.
+        This method reports a deployment metric.
+
+        :param metric_id: Metric ID to report
+        :type metric_id: str
+        :param value: The numeric value to report for the metric
+        :type value: float
+        :param timestamp: Timestamp to use for reporting the metric
+        :type timestamp: str, optional
+        :param deployment_id: Deployment to report metric for
+        :type deployment_id: str, optional
+        """
+        self._validate()
+        _deployment_id = self._get_id(deployment_id, ConfigConstants.DEPLOYMENT_ID)
+        self._model.report_custom_metric(_deployment_id, model_id, metric_id, value, timestamp)
+
+    def report_model_metric(
+        self, metric_id, value, timestamp=None, deployment_id=None, model_id=None
+    ):
+        """
+        Report a custom model metric back to DataRobot MLOps.
+        The metric must be created prior to reporting.
+        This method reports a model metric, so both deployment and model IDs are required to be
+        available.
+
+        :param metric_id:
+        :type metric_id: str
+        :param value: The numeric value to report for the metric
+        :type value: float
+        :param timestamp:
+        :param deployment_id: Deployment Id to use for reporting the metric - if None, then taking
+                    from environment or using the default deployment if set.
+        :type deployment_id: str, optional
+        :param model_id: Model ID to use for reporting the metric - if None, then taking from
+                    configuration.
+        :type model_id: str, optional
+        """
+        self._validate()
+        _deployment_id = self._get_id(deployment_id, ConfigConstants.DEPLOYMENT_ID)
+        _model_id = self._get_id(model_id, ConfigConstants.MODEL_ID)
+        self._model.report_custom_metric(_deployment_id, _model_id, metric_id, value, timestamp)
 
     # ------------------------------------------------------
     #  PICKLING MLOPS
     # ------------------------------------------------------
 
     def __getstate__(self):
         """
```

## datarobot/mlops/channel/output_channel_queue.py

```diff
@@ -40,15 +40,14 @@
     MODEL_ID = SerializationConstants.GeneralConstants.MODEL_ID_FIELD_NAME
     FEATURES = SerializationConstants.PredictionsDataConstants.FEATURES_FIELD_NAME
     PREDICTIONS = SerializationConstants.PredictionsDataConstants.PREDICTIONS_FIELD_NAME
     ASSOCIATION_IDS = SerializationConstants.PredictionsDataConstants.ASSOCIATION_IDS_FIELD_NAME
     CLASS_NAMES = SerializationConstants.PredictionsDataConstants.CLASS_NAMES_FIELD_NAME
 
     METRIC_ID = SerializationConstants.CustomMetricStatsConstants.METRIC_ID_FIELD_NAME
-    MODEL_PACKAGE_ID = SerializationConstants.CustomMetricStatsConstants.MODEL_PACKAGE_ID_FIELD_NAME
     BUCKETS = SerializationConstants.CustomMetricStatsConstants.BUCKETS_FIELD_NAME
     VALUE = SerializationConstants.CustomMetricStatsConstants.METRIC_VALUE_FIELD_NAME
 
     def shutdown(self, timeout_sec=0, final_shutdown=True):
         if self._output_channel is not None:
             self._output_channel.close()
         self._output_channel = None
@@ -157,15 +156,15 @@
         :param custom_metric: dictionary containing all custom metric data
         :param start_index: start of subset to extract
         :param end_index: end of subset to extract
         :return: a dictionary in same format as input
         """
         return {
             self.METRIC_ID: custom_metric[self.METRIC_ID],
-            self.MODEL_PACKAGE_ID: custom_metric[self.MODEL_PACKAGE_ID],
+            self.MODEL_ID: custom_metric[self.MODEL_ID],
             self.BUCKETS: custom_metric[self.BUCKETS][start_index:end_index],
         }
 
     def split_custom_metric_and_create_records(
         self, output_channel, deployment_id, stats_serializer, data_format
     ):
         """
```

## datarobot/mlops/common/config.py

```diff
@@ -343,14 +343,15 @@
     KAFKA_TOPIC_NAME = ConfigKey("MLOPS_KAFKA_TOPIC_NAME", str)
     KAFKA_BOOTSTRAP_SERVERS = ConfigKey("MLOPS_KAFKA_BOOTSTRAP_SERVERS", str)
     KAFKA_MAX_FLUSH_MS = ConfigKey("MLOPS_KAFKA_MAX_FLUSH_MS", int)
     KAFKA_BUFFER_MAX_KB = ConfigKey("MLOPS_KAFKA_BUFFER_MAX_KB", int)
     KAFKA_CONSUMER_GROUP_ID = ConfigKey("MLOPS_KAFKA_CONSUMER_GROUP_ID", str)
     KAFKA_CONSUMER_POLL_TIMEOUT_MS = ConfigKey("MLOPS_KAFKA_CONSUMER_POLL_TIMEOUT_MS", int)
     KAFKA_CONSUMER_MAX_NUM_MESSAGES = ConfigKey("MLOPS_KAFKA_CONSUMER_MAX_NUM_MESSAGES", int)
+    KAFKA_AUTO_RELEASE_OFFSET = ConfigKey("MLOPS_KAFKA_AUTO_RELEASE_OFFSET", str)
     KAFKA_MESSAGE_BYTE_SIZE_LIMIT = ConfigKey("MLOPS_KAFKA_MESSAGE_BYTE_SIZE_LIMIT", int)
     KAFKA_ACK_DEADLINE_STR = ConfigKey("MLOPS_KAFKA_ACK_DEADLINE", int)
     KAFKA_REQUEST_TIMEOUT_MS = ConfigKey("MLOPS_KAFKA_REQUEST_TIMEOUT_MS", int)
     KAFKA_SESSION_TIMEOUT_MS = ConfigKey("MLOPS_KAFKA_SESSION_TIMEOUT_MS", int)
     KAFKA_DELIVERY_TIMEOUT_MS = ConfigKey("MLOPS_KAFKA_DELIVERY_TIMEOUT_MS", int)
     KAFKA_SOCKET_TIMEOUT_MS = ConfigKey("MLOPS_KAFKA_SOCKET_TIMEOUT_MS", int)
     KAFKA_METADATA_MAX_AGE_MS = ConfigKey("MLOPS_KAFKA_METADATA_MAX_AGE_MS", int)
```

## datarobot/mlops/spooler/kafka_spooler.py

```diff
@@ -158,15 +158,17 @@
 
         # NOTE: following consumer configuration is only used for testing
         if self._dequeue_enabled:
             with suppress(DRConfigKeyNotFound):
                 consumer_group_id = config.get_config(ConfigConstants.KAFKA_CONSUMER_GROUP_ID)
                 self._kafka_consumer_config = self._kafka_producer_config.copy()
                 self._kafka_consumer_config[KafkaConf.GROUP_ID] = consumer_group_id
-                self._kafka_consumer_config[KafkaConf.AUTO_OFFSET_RESET] = "earliest"
+                self._kafka_consumer_config[
+                    KafkaConf.AUTO_OFFSET_RESET
+                ] = config.get_config_default(ConfigConstants.KAFKA_AUTO_RELEASE_OFFSET, "earliest")
                 self._kafka_consumer_config[
                     KafkaConf.ENABLE_AUTO_COMMIT
                 ] = not self.enable_dequeue_ack_record
 
     def _gen_kafka_client_config(self):
         _config = {}
         self._bootstrap_servers = config.get_config(ConfigConstants.KAFKA_BOOTSTRAP_SERVERS)
@@ -422,20 +424,15 @@
             ):
                 record_list.append(record)
                 if self.enable_dequeue_ack_record:
                     self._add_pending_record(record.get_id(), msg)
                     self._spooler_offset_manager.track_offset_record(
                         msg.offset(), record.get_id(), msg.partition()
                     )
-
-        if len(record_list) == 0:
-            self._empty_count += 1
-        else:
-            self._empty_count = 0
-
+        self._update_empty_count(len(record_list))
         return record_list
 
     def _read_single_message(self, msg):
 
         if msg is None:
             self._logger.debug("Consumer assigned to topics: %s", self._consumer.assignment())
             return None
```

## datarobot/mlops/spooler/rabbitmq_spooler.py

```diff
@@ -1,14 +1,17 @@
 import ssl
 import sys
 from time import sleep
 from time import time
 
 import pika
+from pika.connection import SSLOptions
 from pika.exceptions import AMQPConnectionError
+from pika.exceptions import NackError
+from pika.exceptions import UnroutableError
 
 from datarobot.mlops.channel.record import Record
 from datarobot.mlops.common import config
 from datarobot.mlops.common.config import ConfigConstants
 from datarobot.mlops.common.enums import MLOpsSpoolAction
 from datarobot.mlops.common.enums import SpoolerType
 from datarobot.mlops.common.exception import DRSpoolerException
@@ -97,43 +100,45 @@
             self._ssl_ca_certificate_path and self._ssl_certificate_path and self._ssl_key_path
         )
 
         self._validate_url(self._queue_url)
         self.rabbitmq_params = pika.URLParameters(self._queue_url)
 
         if self._enable_ssl:
-            self.rabbitmq_params.ssl_options = {
-                "ca_certs": self._ssl_ca_certificate_path,
-                "certfile": self._ssl_certificate_path,
-                "keyfile": self._ssl_key_path,
-            }
-            if self._tls_version:
-                self.rabbitmq_params.ssl_options["ssl_version"] = self._tls_version
+            ssl_context = ssl.create_default_context(
+                ssl.Purpose.CLIENT_AUTH, capath=self._ssl_ca_certificate_path
+            )
+            ssl_context.load_cert_chain(
+                certfile=self._ssl_certificate_path,
+                keyfile=self._ssl_key_path,
+            )
+            self.rabbitmq_params.ssl_options = SSLOptions(context=ssl_context)
 
     def open(self, action=MLOpsSpoolAction.ENQUEUE):
         self.set_config()
         try:
             self._connection = pika.BlockingConnection(self.rabbitmq_params)
             self._channel = self._connection.channel()
             self._channel.confirm_delivery()
             self._channel.queue_declare(queue=self._queue_name, durable=True)
             self._logger.debug(
                 "Successfully connected to {}, using queue: {}".format(
                     self._queue_url, self._queue_name
                 )
             )
             self.initialized = True
-        except AMQPConnectionError as ex:
+        except (AMQPConnectionError, ssl.SSLCertVerificationError) as ex:
             msg = f"Fail to establish connection to RabbitMQ: {ex}"
             self._logger.error(msg)
             raise DRSpoolerException(msg)
 
     def close(self):
         if self._channel and not self._channel.is_closed:
             self._channel.close()
+            self._channel = None
 
         if self._connection and not self._connection.is_closed:
             self._connection.close()
 
     def reconnect(self):
         self.close()
         self.open()
@@ -179,23 +184,23 @@
                     self._logger.warning(
                         f"Reconnection error when publishing a message to RabbitMQ - {ex}"
                     )
                     reason = "reconnection error"
                     continue
 
             try:
-                if self._channel.basic_publish(
+                self._channel.basic_publish(
                     exchange="",
                     routing_key=self._queue_name,
                     body=message,
                     properties=pika.BasicProperties(delivery_mode=2),
-                ):
-                    return
-                else:
-                    raise DRSpoolerException("RabbitMQ: Delivery confirmation not received")
+                )
+                return
+            except (UnroutableError, NackError):
+                raise DRSpoolerException("RabbitMQ: Delivery confirmation not received")
             except pika.exceptions.AMQPConnectionError:
                 self._logger.debug("Connection error when publishing a message to RabbitMQ")
                 reason = "connection error"
             except pika.exceptions.ChannelClosed:
                 self._logger.info("Channel closed when publishing a message to RabbitMQ")
                 reason = "channel close"
             except Exception as ex:
@@ -232,15 +237,15 @@
         if not self.initialized:
             raise DRSpoolerException("Spooler must be opened before using.")
 
         record_list = []
         try:
             for _ in range(self.RABBITMQ_MAX_RECORDS_TO_DEQUEUE):
                 method, _, body = self._channel.basic_get(
-                    self._queue_name, no_ack=(not self.enable_dequeue_ack_record)
+                    self._queue_name, auto_ack=(not self.enable_dequeue_ack_record)
                 )
                 if body is None:
                     break
 
                 record = Record.from_json(body)
                 record_list.append(record)
                 self._add_pending_record(record.get_id(), method)
```

## datarobot/mlops/spooler/record_spooler.py

```diff
@@ -1,11 +1,13 @@
 import logging
 from abc import ABCMeta
 from abc import abstractmethod
+from typing import List
 
+from datarobot.mlops.channel.record import Record
 from datarobot.mlops.common import config
 from datarobot.mlops.common.config import ConfigConstants
 from datarobot.mlops.common.enums import DataFormat
 from datarobot.mlops.common.enums import MLOpsSpoolAction
 from datarobot.mlops.common.exception import DRCommonException
 
 #  Copyright (c) 2020 DataRobot, Inc. and its affiliates. All rights reserved.
@@ -122,13 +124,17 @@
         if not self.enable_dequeue_ack_record:
             return
 
         for record_id in records_id_list:
             self._records_pending_ack.pop(record_id, None)
 
     @abstractmethod
-    def dequeue(self):
+    def dequeue(self) -> List[Record]:
         raise NotImplementedError(
-            "Dequeue operation is not yet implemented for the {} spooler".format(
-                str(self.get_type())
-            )
+            f"Dequeue operation is not yet implemented for the {self.get_type()} spooler"
+        )
+
+    @abstractmethod
+    def enqueue(self, record_list: List[Record]):
+        raise NotImplementedError(
+            f"Enqueue operation is not yet implemented for the {self.get_type()} spooler"
         )
```

## Comparing `datarobot_mlops-9.1.1b1.data/data/share/mlops/agent.yaml` & `datarobot_mlops-9.1.1rc1.data/data/share/mlops/agent.yaml`

 * *Files identical despite different names*

## Comparing `datarobot_mlops-9.1.1b1.data/data/share/mlops/mlops.log4j2.properties` & `datarobot_mlops-9.1.1rc1.data/data/share/mlops/mlops.log4j2.properties`

 * *Files identical despite different names*

## Comparing `datarobot_mlops-9.1.1b1.dist-info/METADATA` & `datarobot_mlops-9.1.1rc1.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: datarobot-mlops
-Version: 9.1.1b1
+Version: 9.1.1rc1
 Summary: datarobot-mlops library to read and report MLOps statistics
 Home-page: http://datarobot.com
 Author: DataRobot
 Author-email: support@datarobot.com
 Maintainer: DataRobot
 Maintainer-email: info@datarobot.com
 License: DataRobot Tool and Utility Agreement
@@ -35,15 +35,15 @@
 Requires-Dist: azure-identity (>=1.0) ; extra == 'azure'
 Provides-Extra: google
 Requires-Dist: google-cloud-pubsub (<3,>=2) ; extra == 'google'
 Provides-Extra: kafka
 Requires-Dist: confluent-kafka (<2,>=1.5.0) ; extra == 'kafka'
 Requires-Dist: certifi ; extra == 'kafka'
 Provides-Extra: rabbitmq
-Requires-Dist: pika (<1,>=0.13.1) ; extra == 'rabbitmq'
+Requires-Dist: pika (>=1.0) ; extra == 'rabbitmq'
 
 # DataRobot MLOps metrics reporting library
 
 This is the Python version of the DataRobot MLOps reporting SDK.
 This library enables remote reporting of MLOps metrics back to DataRobot for
 monitoring.
```

## Comparing `datarobot_mlops-9.1.1b1.dist-info/RECORD` & `datarobot_mlops-9.1.1rc1.dist-info/RECORD`

 * *Files 11% similar despite different names*

```diff
@@ -1,38 +1,38 @@
 datarobot/mlops/__init__.py,sha256=AKjMKTNwSwhUBVbzAe95rrPT428dkII5aszufDWlEYw,597
 datarobot/mlops/agent.py,sha256=zbt31wzbURHLQMmMXkQTPIVNGiiitIYsJRptzS4EGrA,21276
-datarobot/mlops/constants.py,sha256=fTAcqXJLKcSGMhadAc5DpZbdfGKGEC2pMXN5RkmL878,1023
+datarobot/mlops/constants.py,sha256=-KJGSbKS7vjeCGYBbY9cu5QeNk3byL8A61_aqB0wIZ4,1021
 datarobot/mlops/event.py,sha256=3XYENd0P8qa1itpjAfyqvmZnN6uSaVAo1ZnxVE4SeKw,4241
 datarobot/mlops/json_shim.py,sha256=ju_DRuaaGLOqmPBJTMCJHoLkHbf_qXhsQo5dUyLHdGk,3068
-datarobot/mlops/metric.py,sha256=EestF5vM360DFJA1kkOGAPl6BSTV8YpD0rgAP0m-I1Y,30722
-datarobot/mlops/mlops.py,sha256=E04HBkaBDB2gbWKZr679EFs1yrwDaNVse8CZNiUpdxI,39436
+datarobot/mlops/metric.py,sha256=sLnY9fOCBu9kA93l3mss0lWWaaLMP6zKc3TNocPwy7s,30588
+datarobot/mlops/mlops.py,sha256=KsMiCKXwGHKKASU0E3t0lOQORh0v1e7zrQEQhIqdHuE,39285
 datarobot/mlops/model.py,sha256=uTPyonl_QD7jCD_Xmt7PXE9VNyTsmO1WFVzTrop19mE,43371
 datarobot/mlops/channel/__init__.py,sha256=tjNa8K5lXmMIeAgvdxrcwqKXqunstSuvbqL0xklSess,532
-datarobot/mlops/channel/output_channel_queue.py,sha256=obtmtv45toCKVccqO6TrY8v6dtHFmsxx4wmiNgj54OI,19171
+datarobot/mlops/channel/output_channel_queue.py,sha256=1KfWZnJ4AnRLPdHHEtCO0pw-Az2HdYgEB7L2KXRdHvc,19054
 datarobot/mlops/channel/record.py,sha256=MGIqPnXxdnVOe9rmWODJzzkVlPEW2CxkEgl9S-WJssg,13375
 datarobot/mlops/common/__init__.py,sha256=tjNa8K5lXmMIeAgvdxrcwqKXqunstSuvbqL0xklSess,532
 datarobot/mlops/common/aggregation_util.py,sha256=efVhOrgQV0ILq55_xs7ve0kHifQ7JhyHc0oh4YErGOI,8149
-datarobot/mlops/common/config.py,sha256=8QQ6GU96A3EMWRWQv7ctq7CDq4AiOudm2WZK0DoXa4c,16970
+datarobot/mlops/common/config.py,sha256=mPcIOa28caRuGyv3PlPl083cRHvc3lU13C-KK7O50P8,17052
 datarobot/mlops/common/enums.py,sha256=oqMURq6mYtBVlOet9fkCLdSuYcqSfZnbZyp5HhwECvU,2409
 datarobot/mlops/common/exception.py,sha256=6eJCd4mI1IxZpTWPSFmLqXKcmIHiNXXQu2PMXr-KdKM,1081
 datarobot/mlops/common/prediction_util.py,sha256=j8u8HyTN4yqdAJDdBaXeJvszP3D95mxPCIZE_6T_NvA,2182
 datarobot/mlops/common/singleton.py,sha256=d3Vx_rUgnWh-8qpJ6PtCBxQfSd46yjPwOQi7TUuzD2k,861
 datarobot/mlops/common/stringutil.py,sha256=mzQ3fN3-pWiQR5BCf-VF3GrqbpmXDZuRUhX_ZcJk4as,919
 datarobot/mlops/common/version_util.py,sha256=p4bPqjtPVdSzJYavXoT9nGMVt-RqR3RGIEwbhWyBVYw,3872
 datarobot/mlops/spooler/__init__.py,sha256=tjNa8K5lXmMIeAgvdxrcwqKXqunstSuvbqL0xklSess,532
 datarobot/mlops/spooler/async_memory_spooler.py,sha256=LXv0tJBC6yqJg1qcvtVH3RjFplP-XQH2zQ_MukrvwMg,7227
 datarobot/mlops/spooler/filesystem_spooler.py,sha256=WKXMeZK_r99CV246xu05kVa2GgYNewSyzSMunUG3FiI,34711
-datarobot/mlops/spooler/kafka_spooler.py,sha256=2eZFCEQVOvBLtbMuUM2BEWZakkcEA2RukjloW0IcgFk,21987
+datarobot/mlops/spooler/kafka_spooler.py,sha256=NifiP1vagLreXdpvQocRumsvNHxEHtkbWfw-RjSZudM,22027
 datarobot/mlops/spooler/memory_spooler.py,sha256=lEzDbG6kqPzdzLW-p2WOzTWHRB1DQRrXygw2NU3Qq4s,6972
 datarobot/mlops/spooler/pubsub_spooler.py,sha256=I5g7EEjdXXERMU2GOusLOg1-WGgWTsZ7yL86fxoO6g4,12434
-datarobot/mlops/spooler/rabbitmq_spooler.py,sha256=ptyPQNQSnuICUxZrAJrg-vIYUvfoXXdSHzTN2Shk2sw,10100
-datarobot/mlops/spooler/record_spooler.py,sha256=i4HZnwHwQnHpCYZ_zyHUg9bFUbUonS619K8TdLPWwu0,4413
+datarobot/mlops/spooler/rabbitmq_spooler.py,sha256=3AnXmY-2EhNUqdBwhJif-phaKbgmHmD1cDrCzA2UFq0,10337
+datarobot/mlops/spooler/record_spooler.py,sha256=RuG8JUAoqe8QfvdRpqWLlnJr9CnKqog2j4Dp_OjlMkg,4666
 datarobot/mlops/spooler/record_spooler_factory.py,sha256=9QG-uoqVM02ZOmVKn4xqy4tNNfr2oEWEFm1XzpsHbJw,4466
 datarobot/mlops/spooler/spooler_offset_manager.py,sha256=ty-a0bCQ7fd7wF680e1MSNjc9rX2fJzH4Si7FBeLFXM,4454
 datarobot/mlops/spooler/sqs_spool.py,sha256=UgLz98R7T7hRWnzjYB2PqhDvvqkCCvFKCbGs1PYGR2k,10369
 datarobot/mlops/spooler/stdout_spooler.py,sha256=JugaGLxvTzAiCZTbs5ee8i--9X1yXxAT2jZ6G-d5Vcw,2212
-datarobot_mlops-9.1.1b1.data/data/share/mlops/agent.yaml,sha256=gCkDlb3EA1bzfE6Bf5S8XMBA10xZ4OoSXWDJeDXzDrw,2570
-datarobot_mlops-9.1.1b1.data/data/share/mlops/mlops.log4j2.properties,sha256=HEofKe-I_176Wd4r30Z9BEnQtkHbxOek-4Xzim54gaQ,1395
-datarobot_mlops-9.1.1b1.dist-info/METADATA,sha256=BRrbdCwBhAV08HDuzxodaHW5GSrEz7XpTe-8JZ5cj_c,3107
-datarobot_mlops-9.1.1b1.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-datarobot_mlops-9.1.1b1.dist-info/top_level.txt,sha256=RTK5ZHErXe7mZUlXWQRjQpqFdWw3qmpF95Lz7ViL2Lc,10
-datarobot_mlops-9.1.1b1.dist-info/RECORD,,
+datarobot_mlops-9.1.1rc1.data/data/share/mlops/agent.yaml,sha256=gCkDlb3EA1bzfE6Bf5S8XMBA10xZ4OoSXWDJeDXzDrw,2570
+datarobot_mlops-9.1.1rc1.data/data/share/mlops/mlops.log4j2.properties,sha256=HEofKe-I_176Wd4r30Z9BEnQtkHbxOek-4Xzim54gaQ,1395
+datarobot_mlops-9.1.1rc1.dist-info/METADATA,sha256=Og-Jmlp_xzvM9ryt11EaTOgR29PyAVz4JN4uLDon6to,3102
+datarobot_mlops-9.1.1rc1.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+datarobot_mlops-9.1.1rc1.dist-info/top_level.txt,sha256=RTK5ZHErXe7mZUlXWQRjQpqFdWw3qmpF95Lz7ViL2Lc,10
+datarobot_mlops-9.1.1rc1.dist-info/RECORD,,
```

