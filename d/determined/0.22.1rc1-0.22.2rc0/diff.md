# Comparing `tmp/determined-0.22.1rc1-py3-none-any.whl.zip` & `tmp/determined-0.22.2rc0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,251 +1,251 @@
-Zip file size: 566777 bytes, number of entries: 249
--rw-r--r--  2.0 unx     1131 b- defN 23-May-17 18:35 determined/__init__.py
--rw-r--r--  2.0 unx       27 b- defN 23-May-17 18:35 determined/__version__.py
--rw-r--r--  2.0 unx     1664 b- defN 23-May-17 18:35 determined/_env_context.py
--rw-r--r--  2.0 unx     8804 b- defN 23-May-17 18:35 determined/_execution.py
--rw-r--r--  2.0 unx     2779 b- defN 23-May-17 18:35 determined/_experiment_config.py
--rw-r--r--  2.0 unx     4781 b- defN 23-May-17 18:35 determined/_import.py
--rw-r--r--  2.0 unx    14901 b- defN 23-May-17 18:35 determined/_info.py
--rw-r--r--  2.0 unx     1272 b- defN 23-May-17 18:35 determined/_tf_rng.py
--rw-r--r--  2.0 unx     1214 b- defN 23-May-17 18:35 determined/_trial.py
--rw-r--r--  2.0 unx     4726 b- defN 23-May-17 18:35 determined/_trial_context.py
--rw-r--r--  2.0 unx     3356 b- defN 23-May-17 18:35 determined/_trial_controller.py
--rw-r--r--  2.0 unx     2417 b- defN 23-May-17 18:35 determined/constants.py
--rw-r--r--  2.0 unx     2734 b- defN 23-May-17 18:35 determined/errors.py
--rw-r--r--  2.0 unx     5431 b- defN 23-May-17 18:35 determined/gpu.py
--rw-r--r--  2.0 unx     6182 b- defN 23-May-17 18:35 determined/horovod.py
--rw-r--r--  2.0 unx    19382 b- defN 23-May-17 18:35 determined/ipc.py
--rw-r--r--  2.0 unx     3065 b- defN 23-May-17 18:35 determined/load.py
--rw-r--r--  2.0 unx      737 b- defN 23-May-17 18:35 determined/monkey_patch.py
--rw-r--r--  2.0 unx    39670 b- defN 23-May-17 18:35 determined/profiler.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-17 18:35 determined/py.typed
--rw-r--r--  2.0 unx    15909 b- defN 23-May-17 18:35 determined/util.py
--rw-r--r--  2.0 unx     6578 b- defN 23-May-17 18:35 determined/workload.py
--rw-r--r--  2.0 unx      476 b- defN 23-May-17 18:35 determined/cli/__init__.py
--rw-r--r--  2.0 unx       75 b- defN 23-May-17 18:35 determined/cli/__main__.py
--rw-r--r--  2.0 unx     3423 b- defN 23-May-17 18:35 determined/cli/_util.py
--rw-r--r--  2.0 unx     9810 b- defN 23-May-17 18:35 determined/cli/agent.py
--rw-r--r--  2.0 unx     6409 b- defN 23-May-17 18:35 determined/cli/checkpoint.py
--rw-r--r--  2.0 unx    12433 b- defN 23-May-17 18:35 determined/cli/cli.py
--rw-r--r--  2.0 unx    13480 b- defN 23-May-17 18:35 determined/cli/command.py
--rw-r--r--  2.0 unx     2138 b- defN 23-May-17 18:35 determined/cli/dev.py
--rw-r--r--  2.0 unx      739 b- defN 23-May-17 18:35 determined/cli/errors.py
--rw-r--r--  2.0 unx    50046 b- defN 23-May-17 18:35 determined/cli/experiment.py
--rw-r--r--  2.0 unx     8291 b- defN 23-May-17 18:35 determined/cli/job.py
--rw-r--r--  2.0 unx     2137 b- defN 23-May-17 18:35 determined/cli/master.py
--rw-r--r--  2.0 unx     8747 b- defN 23-May-17 18:35 determined/cli/model.py
--rw-r--r--  2.0 unx     5635 b- defN 23-May-17 18:35 determined/cli/notebook.py
--rw-r--r--  2.0 unx     1761 b- defN 23-May-17 18:35 determined/cli/oauth.py
--rw-r--r--  2.0 unx    12190 b- defN 23-May-17 18:35 determined/cli/project.py
--rw-r--r--  2.0 unx    10219 b- defN 23-May-17 18:35 determined/cli/proxy.py
--rw-r--r--  2.0 unx    18787 b- defN 23-May-17 18:35 determined/cli/rbac.py
--rw-r--r--  2.0 unx     3783 b- defN 23-May-17 18:35 determined/cli/remote.py
--rw-r--r--  2.0 unx     4847 b- defN 23-May-17 18:35 determined/cli/render.py
--rw-r--r--  2.0 unx     2386 b- defN 23-May-17 18:35 determined/cli/resources.py
--rw-r--r--  2.0 unx     9718 b- defN 23-May-17 18:35 determined/cli/shell.py
--rw-r--r--  2.0 unx     5193 b- defN 23-May-17 18:35 determined/cli/sso.py
--rw-r--r--  2.0 unx     6381 b- defN 23-May-17 18:35 determined/cli/task.py
--rw-r--r--  2.0 unx     2868 b- defN 23-May-17 18:35 determined/cli/template.py
--rw-r--r--  2.0 unx     6718 b- defN 23-May-17 18:35 determined/cli/tensorboard.py
--rw-r--r--  2.0 unx      135 b- defN 23-May-17 18:35 determined/cli/top_arg_descriptions.py
--rw-r--r--  2.0 unx    15095 b- defN 23-May-17 18:35 determined/cli/trial.py
--rw-r--r--  2.0 unx     1448 b- defN 23-May-17 18:35 determined/cli/tunnel.py
--rw-r--r--  2.0 unx     6560 b- defN 23-May-17 18:35 determined/cli/user.py
--rw-r--r--  2.0 unx     9754 b- defN 23-May-17 18:35 determined/cli/user_groups.py
--rw-r--r--  2.0 unx     2557 b- defN 23-May-17 18:35 determined/cli/version.py
--rw-r--r--  2.0 unx    15179 b- defN 23-May-17 18:35 determined/cli/workspace.py
--rw-r--r--  2.0 unx      352 b- defN 23-May-17 18:35 determined/common/__init__.py
--rw-r--r--  2.0 unx      498 b- defN 23-May-17 18:35 determined/common/_logging.py
--rw-r--r--  2.0 unx     8593 b- defN 23-May-17 18:35 determined/common/check.py
--rw-r--r--  2.0 unx     2255 b- defN 23-May-17 18:35 determined/common/constants.py
--rw-r--r--  2.0 unx     8222 b- defN 23-May-17 18:35 determined/common/context.py
--rw-r--r--  2.0 unx     7359 b- defN 23-May-17 18:35 determined/common/declarative_argparse.py
--rw-r--r--  2.0 unx     1662 b- defN 23-May-17 18:35 determined/common/requests.py
--rw-r--r--  2.0 unx     6349 b- defN 23-May-17 18:35 determined/common/util.py
--rw-r--r--  2.0 unx      778 b- defN 23-May-17 18:35 determined/common/api/__init__.py
--rw-r--r--  2.0 unx     3383 b- defN 23-May-17 18:35 determined/common/api/_session.py
--rw-r--r--  2.0 unx     2840 b- defN 23-May-17 18:35 determined/common/api/_util.py
--rw-r--r--  2.0 unx     1450 b- defN 23-May-17 18:35 determined/common/api/analytics.py
--rw-r--r--  2.0 unx    15676 b- defN 23-May-17 18:35 determined/common/api/authentication.py
--rw-r--r--  2.0 unx   611974 b- defN 23-May-17 18:35 determined/common/api/bindings.py
--rw-r--r--  2.0 unx     7415 b- defN 23-May-17 18:35 determined/common/api/certs.py
--rw-r--r--  2.0 unx     2555 b- defN 23-May-17 18:35 determined/common/api/errors.py
--rw-r--r--  2.0 unx     3235 b- defN 23-May-17 18:35 determined/common/api/logs.py
--rw-r--r--  2.0 unx      247 b- defN 23-May-17 18:35 determined/common/api/metric.py
--rw-r--r--  2.0 unx     3147 b- defN 23-May-17 18:35 determined/common/api/profiler.py
--rw-r--r--  2.0 unx    10411 b- defN 23-May-17 18:35 determined/common/api/request.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-17 18:35 determined/common/api/checkpoint/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-17 18:35 determined/common/api/checkpoint/torch_load.py
--rw-r--r--  2.0 unx      502 b- defN 23-May-17 18:35 determined/common/experimental/__init__.py
--rw-r--r--  2.0 unx    15864 b- defN 23-May-17 18:35 determined/common/experimental/determined.py
--rw-r--r--  2.0 unx    11398 b- defN 23-May-17 18:35 determined/common/experimental/experiment.py
--rw-r--r--  2.0 unx    12639 b- defN 23-May-17 18:35 determined/common/experimental/model.py
--rw-r--r--  2.0 unx      306 b- defN 23-May-17 18:35 determined/common/experimental/oauth2_scim_client.py
--rw-r--r--  2.0 unx      466 b- defN 23-May-17 18:35 determined/common/experimental/session.py
--rw-r--r--  2.0 unx    15743 b- defN 23-May-17 18:35 determined/common/experimental/trial.py
--rw-r--r--  2.0 unx     3503 b- defN 23-May-17 18:35 determined/common/experimental/user.py
--rw-r--r--  2.0 unx      125 b- defN 23-May-17 18:35 determined/common/experimental/checkpoint/__init__.py
--rw-r--r--  2.0 unx    13827 b- defN 23-May-17 18:35 determined/common/experimental/checkpoint/_checkpoint.py
--rw-r--r--  2.0 unx     3868 b- defN 23-May-17 18:35 determined/common/storage/__init__.py
--rw-r--r--  2.0 unx     3822 b- defN 23-May-17 18:35 determined/common/storage/azure.py
--rw-r--r--  2.0 unx     3514 b- defN 23-May-17 18:35 determined/common/storage/azure_client.py
--rw-r--r--  2.0 unx     7152 b- defN 23-May-17 18:35 determined/common/storage/base.py
--rw-r--r--  2.0 unx     4447 b- defN 23-May-17 18:35 determined/common/storage/boto3_credential_manager.py
--rw-r--r--  2.0 unx     1014 b- defN 23-May-17 18:35 determined/common/storage/cloud.py
--rw-r--r--  2.0 unx     5789 b- defN 23-May-17 18:35 determined/common/storage/gcs.py
--rw-r--r--  2.0 unx     2070 b- defN 23-May-17 18:35 determined/common/storage/hdfs.py
--rw-r--r--  2.0 unx     6195 b- defN 23-May-17 18:35 determined/common/storage/s3.py
--rw-r--r--  2.0 unx     7816 b- defN 23-May-17 18:35 determined/common/storage/shared.py
--rw-r--r--  2.0 unx      747 b- defN 23-May-17 18:35 determined/core/__init__.py
--rw-r--r--  2.0 unx    29468 b- defN 23-May-17 18:35 determined/core/_checkpoint.py
--rw-r--r--  2.0 unx    10984 b- defN 23-May-17 18:35 determined/core/_context.py
--rw-r--r--  2.0 unx    16194 b- defN 23-May-17 18:35 determined/core/_distributed.py
--rw-r--r--  2.0 unx    12738 b- defN 23-May-17 18:35 determined/core/_preempt.py
--rw-r--r--  2.0 unx    15041 b- defN 23-May-17 18:35 determined/core/_searcher.py
--rw-r--r--  2.0 unx      932 b- defN 23-May-17 18:35 determined/core/_tensorboard_mode.py
--rw-r--r--  2.0 unx    10462 b- defN 23-May-17 18:35 determined/core/_train.py
--rw-r--r--  2.0 unx       40 b- defN 23-May-17 18:35 determined/deploy/__init__.py
--rw-r--r--  2.0 unx     1057 b- defN 23-May-17 18:35 determined/deploy/cli.py
--rw-r--r--  2.0 unx       94 b- defN 23-May-17 18:35 determined/deploy/errors.py
--rw-r--r--  2.0 unx     1472 b- defN 23-May-17 18:35 determined/deploy/healthcheck.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-17 18:35 determined/deploy/aws/__init__.py
--rw-r--r--  2.0 unx    19015 b- defN 23-May-17 18:35 determined/deploy/aws/aws.py
--rw-r--r--  2.0 unx    24035 b- defN 23-May-17 18:35 determined/deploy/aws/cli.py
--rw-r--r--  2.0 unx     2998 b- defN 23-May-17 18:35 determined/deploy/aws/constants.py
--rw-r--r--  2.0 unx     1420 b- defN 23-May-17 18:35 determined/deploy/aws/gen_vcpu_mapping.py
--rw-r--r--  2.0 unx     2201 b- defN 23-May-17 18:35 determined/deploy/aws/master_config_inject.py
--rw-r--r--  2.0 unx     4911 b- defN 23-May-17 18:35 determined/deploy/aws/preflight.py
--rw-r--r--  2.0 unx    17324 b- defN 23-May-17 18:35 determined/deploy/aws/vcpu_mapping.yaml
--rw-r--r--  2.0 unx        0 b- defN 23-May-17 18:35 determined/deploy/aws/deployment_types/__init__.py
--rw-r--r--  2.0 unx     5624 b- defN 23-May-17 18:35 determined/deploy/aws/deployment_types/base.py
--rw-r--r--  2.0 unx     1593 b- defN 23-May-17 18:35 determined/deploy/aws/deployment_types/govcloud.py
--rw-r--r--  2.0 unx     3094 b- defN 23-May-17 18:35 determined/deploy/aws/deployment_types/secure.py
--rw-r--r--  2.0 unx     1349 b- defN 23-May-17 18:35 determined/deploy/aws/deployment_types/simple.py
--rw-r--r--  2.0 unx     1400 b- defN 23-May-17 18:35 determined/deploy/aws/deployment_types/vpc.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-17 18:35 determined/deploy/aws/templates/__init__.py
--rw-r--r--  2.0 unx    29259 b- defN 23-May-17 18:35 determined/deploy/aws/templates/efs.yaml
--rw-r--r--  2.0 unx    29969 b- defN 23-May-17 18:35 determined/deploy/aws/templates/fsx.yaml
--rw-r--r--  2.0 unx    23518 b- defN 23-May-17 18:35 determined/deploy/aws/templates/govcloud.yaml
--rw-r--r--  2.0 unx    29153 b- defN 23-May-17 18:35 determined/deploy/aws/templates/secure.yaml
--rw-r--r--  2.0 unx    24926 b- defN 23-May-17 18:35 determined/deploy/aws/templates/simple.yaml
--rw-r--r--  2.0 unx        0 b- defN 23-May-17 18:35 determined/deploy/gcp/__init__.py
--rw-r--r--  2.0 unx    19015 b- defN 23-May-17 18:35 determined/deploy/gcp/cli.py
--rw-r--r--  2.0 unx      772 b- defN 23-May-17 18:35 determined/deploy/gcp/constants.py
--rw-r--r--  2.0 unx    12420 b- defN 23-May-17 18:35 determined/deploy/gcp/gcp.py
--rw-r--r--  2.0 unx     2380 b- defN 23-May-17 18:35 determined/deploy/gcp/preflight.py
--rw-r--r--  2.0 unx     5376 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/main.tf
--rw-r--r--  2.0 unx     1569 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/master.yaml.tmpl
--rw-r--r--  2.0 unx     1487 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/outputs.tf
--rw-r--r--  2.0 unx     3767 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/variables.tf
--rw-r--r--  2.0 unx     6105 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/compute/main.tf
--rw-r--r--  2.0 unx      424 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/compute/outputs.tf
--rw-r--r--  2.0 unx     1574 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/compute/variables.tf
--rw-r--r--  2.0 unx     1222 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/database/main.tf
--rw-r--r--  2.0 unx      283 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/database/outputs.tf
--rw-r--r--  2.0 unx      320 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/database/variables.tf
--rw-r--r--  2.0 unx      522 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/filestore/main.tf
--rw-r--r--  2.0 unx      184 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/filestore/outputs.tf
--rw-r--r--  2.0 unx      125 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/filestore/variables.tf
--rw-r--r--  2.0 unx     1026 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/firewall/main.tf
--rw-r--r--  2.0 unx      195 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/firewall/outputs.tf
--rw-r--r--  2.0 unx       75 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/firewall/variables.tf
--rw-r--r--  2.0 unx      637 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/gcs/main.tf
--rw-r--r--  2.0 unx       51 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/gcs/outputs.tf
--rw-r--r--  2.0 unx      161 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/gcs/variables.tf
--rw-r--r--  2.0 unx      161 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/ip/main.tf
--rw-r--r--  2.0 unx      122 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/ip/outputs.tf
--rw-r--r--  2.0 unx       88 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/ip/variables.tf
--rw-r--r--  2.0 unx     1112 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/network/main.tf
--rw-r--r--  2.0 unx      275 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/network/outputs.tf
--rw-r--r--  2.0 unx      207 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/network/variables.tf
--rw-r--r--  2.0 unx      962 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/service_account/main.tf
--rw-r--r--  2.0 unx       73 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/service_account/outputs.tf
--rw-r--r--  2.0 unx      138 b- defN 23-May-17 18:35 determined/deploy/gcp/terraform/modules/service_account/variables.tf
--rw-r--r--  2.0 unx        0 b- defN 23-May-17 18:35 determined/deploy/gke/__init__.py
--rw-r--r--  2.0 unx    19568 b- defN 23-May-17 18:35 determined/deploy/gke/cli.py
--rw-r--r--  2.0 unx      408 b- defN 23-May-17 18:35 determined/deploy/gke/constants.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-17 18:35 determined/deploy/local/__init__.py
--rw-r--r--  2.0 unx    12829 b- defN 23-May-17 18:35 determined/deploy/local/cli.py
--rw-r--r--  2.0 unx    16913 b- defN 23-May-17 18:35 determined/deploy/local/cluster_utils.py
--rw-r--r--  2.0 unx     1134 b- defN 23-May-17 18:35 determined/deploy/local/preflight.py
--rw-r--r--  2.0 unx      697 b- defN 23-May-17 18:35 determined/estimator/__init__.py
--rw-r--r--  2.0 unx     1288 b- defN 23-May-17 18:35 determined/estimator/_callback.py
--rw-r--r--  2.0 unx     7375 b- defN 23-May-17 18:35 determined/estimator/_estimator_context.py
--rw-r--r--  2.0 unx    40175 b- defN 23-May-17 18:35 determined/estimator/_estimator_trial.py
--rw-r--r--  2.0 unx     3086 b- defN 23-May-17 18:35 determined/estimator/_load.py
--rw-r--r--  2.0 unx    13742 b- defN 23-May-17 18:35 determined/estimator/_reducer.py
--rw-r--r--  2.0 unx     9600 b- defN 23-May-17 18:35 determined/estimator/_util.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-17 18:35 determined/exec/__init__.py
--rw-r--r--  2.0 unx     3836 b- defN 23-May-17 18:35 determined/exec/gc_checkpoints.py
--rw-r--r--  2.0 unx     8857 b- defN 23-May-17 18:35 determined/exec/harness.py
--rw-r--r--  2.0 unx     4233 b- defN 23-May-17 18:35 determined/exec/launch.py
--rw-r--r--  2.0 unx      389 b- defN 23-May-17 18:35 determined/exec/pid_client.py
--rw-r--r--  2.0 unx     1476 b- defN 23-May-17 18:35 determined/exec/pid_server.py
--rw-r--r--  2.0 unx    13479 b- defN 23-May-17 18:35 determined/exec/prep_container.py
--rw-r--r--  2.0 unx    10994 b- defN 23-May-17 18:35 determined/exec/tensorboard.py
--rw-r--r--  2.0 unx      264 b- defN 23-May-17 18:35 determined/experimental/__init__.py
--rw-r--r--  2.0 unx     3473 b- defN 23-May-17 18:35 determined/experimental/_native.py
--rw-r--r--  2.0 unx    15160 b- defN 23-May-17 18:35 determined/experimental/client.py
--rw-r--r--  2.0 unx      744 b- defN 23-May-17 18:35 determined/keras/__init__.py
--rw-r--r--  2.0 unx     7579 b- defN 23-May-17 18:35 determined/keras/_data.py
--rw-r--r--  2.0 unx    11491 b- defN 23-May-17 18:35 determined/keras/_enqueuer.py
--rw-r--r--  2.0 unx     4020 b- defN 23-May-17 18:35 determined/keras/_load.py
--rw-r--r--  2.0 unx      486 b- defN 23-May-17 18:35 determined/keras/_tensorboard_callback.py
--rw-r--r--  2.0 unx    19042 b- defN 23-May-17 18:35 determined/keras/_tf_keras_context.py
--rw-r--r--  2.0 unx     1204 b- defN 23-May-17 18:35 determined/keras/_tf_keras_multi_gpu.py
--rw-r--r--  2.0 unx    48040 b- defN 23-May-17 18:35 determined/keras/_tf_keras_trial.py
--rw-r--r--  2.0 unx    28556 b- defN 23-May-17 18:35 determined/keras/callbacks.py
--rw-r--r--  2.0 unx        0 b- defN 23-May-17 18:35 determined/launch/__init__.py
--rw-r--r--  2.0 unx    13720 b- defN 23-May-17 18:35 determined/launch/deepspeed.py
--rw-r--r--  2.0 unx    10813 b- defN 23-May-17 18:35 determined/launch/horovod.py
--rw-r--r--  2.0 unx     4574 b- defN 23-May-17 18:35 determined/launch/torch_distributed.py
--rw-r--r--  2.0 unx     4502 b- defN 23-May-17 18:35 determined/launch/wrap_rank.py
--rw-r--r--  2.0 unx       98 b- defN 23-May-17 18:35 determined/layers/__init__.py
--rw-r--r--  2.0 unx    19401 b- defN 23-May-17 18:35 determined/layers/_workload_sequencer.py
--rw-r--r--  2.0 unx     1134 b- defN 23-May-17 18:35 determined/pytorch/__init__.py
--rw-r--r--  2.0 unx     5459 b- defN 23-May-17 18:35 determined/pytorch/_callback.py
--rw-r--r--  2.0 unx    16294 b- defN 23-May-17 18:35 determined/pytorch/_data.py
--rw-r--r--  2.0 unx     3670 b- defN 23-May-17 18:35 determined/pytorch/_experimental.py
--rw-r--r--  2.0 unx    12510 b- defN 23-May-17 18:35 determined/pytorch/_load.py
--rw-r--r--  2.0 unx     3286 b- defN 23-May-17 18:35 determined/pytorch/_lr_scheduler.py
--rw-r--r--  2.0 unx     8275 b- defN 23-May-17 18:35 determined/pytorch/_metric_utils.py
--rw-r--r--  2.0 unx    45136 b- defN 23-May-17 18:35 determined/pytorch/_pytorch_context.py
--rw-r--r--  2.0 unx    67819 b- defN 23-May-17 18:35 determined/pytorch/_pytorch_trial.py
--rw-r--r--  2.0 unx    21406 b- defN 23-May-17 18:35 determined/pytorch/_reducer.py
--rw-r--r--  2.0 unx    13510 b- defN 23-May-17 18:35 determined/pytorch/_trainer.py
--rw-r--r--  2.0 unx     9561 b- defN 23-May-17 18:35 determined/pytorch/samplers.py
--rw-r--r--  2.0 unx      347 b- defN 23-May-17 18:35 determined/pytorch/deepspeed/__init__.py
--rw-r--r--  2.0 unx    17524 b- defN 23-May-17 18:35 determined/pytorch/deepspeed/_deepspeed_context.py
--rw-r--r--  2.0 unx    42777 b- defN 23-May-17 18:35 determined/pytorch/deepspeed/_deepspeed_trial.py
--rw-r--r--  2.0 unx     1987 b- defN 23-May-17 18:35 determined/pytorch/deepspeed/_mpu.py
--rw-r--r--  2.0 unx       67 b- defN 23-May-17 18:35 determined/pytorch/lightning/__init__.py
--rw-r--r--  2.0 unx    18157 b- defN 23-May-17 18:35 determined/pytorch/lightning/_adapter.py
--rw-r--r--  2.0 unx      343 b- defN 23-May-17 18:35 determined/searcher/__init__.py
--rw-r--r--  2.0 unx     3563 b- defN 23-May-17 18:35 determined/searcher/_remote_search_runner.py
--rw-r--r--  2.0 unx    10081 b- defN 23-May-17 18:35 determined/searcher/_search_method.py
--rw-r--r--  2.0 unx    14053 b- defN 23-May-17 18:35 determined/searcher/_search_runner.py
--rw-r--r--  2.0 unx      512 b- defN 23-May-17 18:35 determined/tensorboard/__init__.py
--rw-r--r--  2.0 unx     1573 b- defN 23-May-17 18:35 determined/tensorboard/azure.py
--rw-r--r--  2.0 unx     5884 b- defN 23-May-17 18:35 determined/tensorboard/base.py
--rw-r--r--  2.0 unx     4534 b- defN 23-May-17 18:35 determined/tensorboard/build.py
--rw-r--r--  2.0 unx     2305 b- defN 23-May-17 18:35 determined/tensorboard/gcs.py
--rw-r--r--  2.0 unx     1333 b- defN 23-May-17 18:35 determined/tensorboard/hdfs.py
--rw-r--r--  2.0 unx     1892 b- defN 23-May-17 18:35 determined/tensorboard/s3.py
--rw-r--r--  2.0 unx     1747 b- defN 23-May-17 18:35 determined/tensorboard/shared.py
--rw-r--r--  2.0 unx     3734 b- defN 23-May-17 18:35 determined/tensorboard/util.py
--rw-r--r--  2.0 unx      780 b- defN 23-May-17 18:35 determined/tensorboard/fetchers/__init__.py
--rw-r--r--  2.0 unx     2534 b- defN 23-May-17 18:35 determined/tensorboard/fetchers/azure.py
--rw-r--r--  2.0 unx     1670 b- defN 23-May-17 18:35 determined/tensorboard/fetchers/base.py
--rw-r--r--  2.0 unx     1733 b- defN 23-May-17 18:35 determined/tensorboard/fetchers/gcs.py
--rw-r--r--  2.0 unx     2476 b- defN 23-May-17 18:35 determined/tensorboard/fetchers/s3.py
--rw-r--r--  2.0 unx     1634 b- defN 23-May-17 18:35 determined/tensorboard/fetchers/shared.py
--rw-r--r--  2.0 unx       91 b- defN 23-May-17 18:35 determined/tensorboard/metric_writers/__init__.py
--rw-r--r--  2.0 unx     2113 b- defN 23-May-17 18:35 determined/tensorboard/metric_writers/callback.py
--rw-r--r--  2.0 unx     2936 b- defN 23-May-17 18:35 determined/tensorboard/metric_writers/pytorch.py
--rw-r--r--  2.0 unx     4385 b- defN 23-May-17 18:35 determined/tensorboard/metric_writers/tensorflow.py
--rw-r--r--  2.0 unx     1262 b- defN 23-May-17 18:35 determined-0.22.1rc1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-17 18:35 determined-0.22.1rc1.dist-info/WHEEL
--rw-r--r--  2.0 unx       53 b- defN 23-May-17 18:35 determined-0.22.1rc1.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       11 b- defN 23-May-17 18:35 determined-0.22.1rc1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    22843 b- defN 23-May-17 18:35 determined-0.22.1rc1.dist-info/RECORD
-249 files, 2356817 bytes uncompressed, 530347 bytes compressed:  77.5%
+Zip file size: 569186 bytes, number of entries: 249
+-rw-r--r--  2.0 unx     1131 b- defN 23-May-17 23:33 determined/__init__.py
+-rw-r--r--  2.0 unx       27 b- defN 23-May-17 23:33 determined/__version__.py
+-rw-r--r--  2.0 unx     1664 b- defN 23-May-17 23:33 determined/_env_context.py
+-rw-r--r--  2.0 unx     8804 b- defN 23-May-17 23:33 determined/_execution.py
+-rw-r--r--  2.0 unx     2779 b- defN 23-May-17 23:33 determined/_experiment_config.py
+-rw-r--r--  2.0 unx     4781 b- defN 23-May-17 23:33 determined/_import.py
+-rw-r--r--  2.0 unx    14901 b- defN 23-May-17 23:33 determined/_info.py
+-rw-r--r--  2.0 unx     1272 b- defN 23-May-17 23:33 determined/_tf_rng.py
+-rw-r--r--  2.0 unx     1214 b- defN 23-May-17 23:33 determined/_trial.py
+-rw-r--r--  2.0 unx     4726 b- defN 23-May-17 23:33 determined/_trial_context.py
+-rw-r--r--  2.0 unx     3356 b- defN 23-May-17 23:33 determined/_trial_controller.py
+-rw-r--r--  2.0 unx     2417 b- defN 23-May-17 23:33 determined/constants.py
+-rw-r--r--  2.0 unx     2734 b- defN 23-May-17 23:33 determined/errors.py
+-rw-r--r--  2.0 unx     5431 b- defN 23-May-17 23:33 determined/gpu.py
+-rw-r--r--  2.0 unx     6182 b- defN 23-May-17 23:33 determined/horovod.py
+-rw-r--r--  2.0 unx    19382 b- defN 23-May-17 23:33 determined/ipc.py
+-rw-r--r--  2.0 unx     3065 b- defN 23-May-17 23:33 determined/load.py
+-rw-r--r--  2.0 unx      737 b- defN 23-May-17 23:33 determined/monkey_patch.py
+-rw-r--r--  2.0 unx    39670 b- defN 23-May-17 23:33 determined/profiler.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-17 23:33 determined/py.typed
+-rw-r--r--  2.0 unx    15909 b- defN 23-May-17 23:33 determined/util.py
+-rw-r--r--  2.0 unx     6578 b- defN 23-May-17 23:33 determined/workload.py
+-rw-r--r--  2.0 unx      476 b- defN 23-May-17 23:33 determined/cli/__init__.py
+-rw-r--r--  2.0 unx       75 b- defN 23-May-17 23:33 determined/cli/__main__.py
+-rw-r--r--  2.0 unx     3423 b- defN 23-May-17 23:33 determined/cli/_util.py
+-rw-r--r--  2.0 unx     9810 b- defN 23-May-17 23:33 determined/cli/agent.py
+-rw-r--r--  2.0 unx     6409 b- defN 23-May-17 23:33 determined/cli/checkpoint.py
+-rw-r--r--  2.0 unx    12530 b- defN 23-May-17 23:33 determined/cli/cli.py
+-rw-r--r--  2.0 unx    14081 b- defN 23-May-17 23:33 determined/cli/command.py
+-rw-r--r--  2.0 unx     2138 b- defN 23-May-17 23:33 determined/cli/dev.py
+-rw-r--r--  2.0 unx      739 b- defN 23-May-17 23:33 determined/cli/errors.py
+-rw-r--r--  2.0 unx    50931 b- defN 23-May-17 23:33 determined/cli/experiment.py
+-rw-r--r--  2.0 unx     8291 b- defN 23-May-17 23:33 determined/cli/job.py
+-rw-r--r--  2.0 unx     2137 b- defN 23-May-17 23:33 determined/cli/master.py
+-rw-r--r--  2.0 unx     8747 b- defN 23-May-17 23:33 determined/cli/model.py
+-rw-r--r--  2.0 unx     5641 b- defN 23-May-17 23:33 determined/cli/notebook.py
+-rw-r--r--  2.0 unx     1761 b- defN 23-May-17 23:33 determined/cli/oauth.py
+-rw-r--r--  2.0 unx    12190 b- defN 23-May-17 23:33 determined/cli/project.py
+-rw-r--r--  2.0 unx    10219 b- defN 23-May-17 23:33 determined/cli/proxy.py
+-rw-r--r--  2.0 unx    18787 b- defN 23-May-17 23:33 determined/cli/rbac.py
+-rw-r--r--  2.0 unx     3783 b- defN 23-May-17 23:33 determined/cli/remote.py
+-rw-r--r--  2.0 unx     4847 b- defN 23-May-17 23:33 determined/cli/render.py
+-rw-r--r--  2.0 unx     2372 b- defN 23-May-17 23:33 determined/cli/resources.py
+-rw-r--r--  2.0 unx     9718 b- defN 23-May-17 23:33 determined/cli/shell.py
+-rw-r--r--  2.0 unx     5240 b- defN 23-May-17 23:33 determined/cli/sso.py
+-rw-r--r--  2.0 unx     6381 b- defN 23-May-17 23:33 determined/cli/task.py
+-rw-r--r--  2.0 unx     5354 b- defN 23-May-17 23:33 determined/cli/template.py
+-rw-r--r--  2.0 unx     8240 b- defN 23-May-17 23:33 determined/cli/tensorboard.py
+-rw-r--r--  2.0 unx      135 b- defN 23-May-17 23:33 determined/cli/top_arg_descriptions.py
+-rw-r--r--  2.0 unx    15112 b- defN 23-May-17 23:33 determined/cli/trial.py
+-rw-r--r--  2.0 unx     1448 b- defN 23-May-17 23:33 determined/cli/tunnel.py
+-rw-r--r--  2.0 unx     6875 b- defN 23-May-17 23:33 determined/cli/user.py
+-rw-r--r--  2.0 unx     9754 b- defN 23-May-17 23:33 determined/cli/user_groups.py
+-rw-r--r--  2.0 unx     2557 b- defN 23-May-17 23:33 determined/cli/version.py
+-rw-r--r--  2.0 unx    15179 b- defN 23-May-17 23:33 determined/cli/workspace.py
+-rw-r--r--  2.0 unx      352 b- defN 23-May-17 23:33 determined/common/__init__.py
+-rw-r--r--  2.0 unx      498 b- defN 23-May-17 23:33 determined/common/_logging.py
+-rw-r--r--  2.0 unx     8593 b- defN 23-May-17 23:33 determined/common/check.py
+-rw-r--r--  2.0 unx     2255 b- defN 23-May-17 23:33 determined/common/constants.py
+-rw-r--r--  2.0 unx     8222 b- defN 23-May-17 23:33 determined/common/context.py
+-rw-r--r--  2.0 unx     8612 b- defN 23-May-17 23:33 determined/common/declarative_argparse.py
+-rw-r--r--  2.0 unx     1662 b- defN 23-May-17 23:33 determined/common/requests.py
+-rw-r--r--  2.0 unx     6349 b- defN 23-May-17 23:33 determined/common/util.py
+-rw-r--r--  2.0 unx      778 b- defN 23-May-17 23:33 determined/common/api/__init__.py
+-rw-r--r--  2.0 unx     3383 b- defN 23-May-17 23:33 determined/common/api/_session.py
+-rw-r--r--  2.0 unx     2840 b- defN 23-May-17 23:33 determined/common/api/_util.py
+-rw-r--r--  2.0 unx     1450 b- defN 23-May-17 23:33 determined/common/api/analytics.py
+-rw-r--r--  2.0 unx    16070 b- defN 23-May-17 23:33 determined/common/api/authentication.py
+-rw-r--r--  2.0 unx   619513 b- defN 23-May-17 23:33 determined/common/api/bindings.py
+-rw-r--r--  2.0 unx     7415 b- defN 23-May-17 23:33 determined/common/api/certs.py
+-rw-r--r--  2.0 unx     2555 b- defN 23-May-17 23:33 determined/common/api/errors.py
+-rw-r--r--  2.0 unx     3235 b- defN 23-May-17 23:33 determined/common/api/logs.py
+-rw-r--r--  2.0 unx      247 b- defN 23-May-17 23:33 determined/common/api/metric.py
+-rw-r--r--  2.0 unx     3147 b- defN 23-May-17 23:33 determined/common/api/profiler.py
+-rw-r--r--  2.0 unx    10416 b- defN 23-May-17 23:33 determined/common/api/request.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-17 23:33 determined/common/api/checkpoint/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-17 23:33 determined/common/api/checkpoint/torch_load.py
+-rw-r--r--  2.0 unx      502 b- defN 23-May-17 23:33 determined/common/experimental/__init__.py
+-rw-r--r--  2.0 unx    15864 b- defN 23-May-17 23:33 determined/common/experimental/determined.py
+-rw-r--r--  2.0 unx    11398 b- defN 23-May-17 23:33 determined/common/experimental/experiment.py
+-rw-r--r--  2.0 unx    12639 b- defN 23-May-17 23:33 determined/common/experimental/model.py
+-rw-r--r--  2.0 unx      306 b- defN 23-May-17 23:33 determined/common/experimental/oauth2_scim_client.py
+-rw-r--r--  2.0 unx      466 b- defN 23-May-17 23:33 determined/common/experimental/session.py
+-rw-r--r--  2.0 unx    15743 b- defN 23-May-17 23:33 determined/common/experimental/trial.py
+-rw-r--r--  2.0 unx     3503 b- defN 23-May-17 23:33 determined/common/experimental/user.py
+-rw-r--r--  2.0 unx      125 b- defN 23-May-17 23:33 determined/common/experimental/checkpoint/__init__.py
+-rw-r--r--  2.0 unx    13827 b- defN 23-May-17 23:33 determined/common/experimental/checkpoint/_checkpoint.py
+-rw-r--r--  2.0 unx     3868 b- defN 23-May-17 23:33 determined/common/storage/__init__.py
+-rw-r--r--  2.0 unx     3822 b- defN 23-May-17 23:33 determined/common/storage/azure.py
+-rw-r--r--  2.0 unx     3514 b- defN 23-May-17 23:33 determined/common/storage/azure_client.py
+-rw-r--r--  2.0 unx     7152 b- defN 23-May-17 23:33 determined/common/storage/base.py
+-rw-r--r--  2.0 unx     4447 b- defN 23-May-17 23:33 determined/common/storage/boto3_credential_manager.py
+-rw-r--r--  2.0 unx     1014 b- defN 23-May-17 23:33 determined/common/storage/cloud.py
+-rw-r--r--  2.0 unx     5789 b- defN 23-May-17 23:33 determined/common/storage/gcs.py
+-rw-r--r--  2.0 unx     2070 b- defN 23-May-17 23:33 determined/common/storage/hdfs.py
+-rw-r--r--  2.0 unx     6195 b- defN 23-May-17 23:33 determined/common/storage/s3.py
+-rw-r--r--  2.0 unx     7816 b- defN 23-May-17 23:33 determined/common/storage/shared.py
+-rw-r--r--  2.0 unx      747 b- defN 23-May-17 23:33 determined/core/__init__.py
+-rw-r--r--  2.0 unx    29691 b- defN 23-May-17 23:33 determined/core/_checkpoint.py
+-rw-r--r--  2.0 unx    10984 b- defN 23-May-17 23:33 determined/core/_context.py
+-rw-r--r--  2.0 unx    16194 b- defN 23-May-17 23:33 determined/core/_distributed.py
+-rw-r--r--  2.0 unx    12738 b- defN 23-May-17 23:33 determined/core/_preempt.py
+-rw-r--r--  2.0 unx    15041 b- defN 23-May-17 23:33 determined/core/_searcher.py
+-rw-r--r--  2.0 unx      932 b- defN 23-May-17 23:33 determined/core/_tensorboard_mode.py
+-rw-r--r--  2.0 unx    10462 b- defN 23-May-17 23:33 determined/core/_train.py
+-rw-r--r--  2.0 unx       40 b- defN 23-May-17 23:33 determined/deploy/__init__.py
+-rw-r--r--  2.0 unx     1031 b- defN 23-May-17 23:33 determined/deploy/cli.py
+-rw-r--r--  2.0 unx       94 b- defN 23-May-17 23:33 determined/deploy/errors.py
+-rw-r--r--  2.0 unx     1472 b- defN 23-May-17 23:33 determined/deploy/healthcheck.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-17 23:33 determined/deploy/aws/__init__.py
+-rw-r--r--  2.0 unx    19597 b- defN 23-May-17 23:33 determined/deploy/aws/aws.py
+-rw-r--r--  2.0 unx    24035 b- defN 23-May-17 23:33 determined/deploy/aws/cli.py
+-rw-r--r--  2.0 unx     2998 b- defN 23-May-17 23:33 determined/deploy/aws/constants.py
+-rw-r--r--  2.0 unx     1420 b- defN 23-May-17 23:33 determined/deploy/aws/gen_vcpu_mapping.py
+-rw-r--r--  2.0 unx     2201 b- defN 23-May-17 23:33 determined/deploy/aws/master_config_inject.py
+-rw-r--r--  2.0 unx     4911 b- defN 23-May-17 23:33 determined/deploy/aws/preflight.py
+-rw-r--r--  2.0 unx    17324 b- defN 23-May-17 23:33 determined/deploy/aws/vcpu_mapping.yaml
+-rw-r--r--  2.0 unx        0 b- defN 23-May-17 23:33 determined/deploy/aws/deployment_types/__init__.py
+-rw-r--r--  2.0 unx     5624 b- defN 23-May-17 23:33 determined/deploy/aws/deployment_types/base.py
+-rw-r--r--  2.0 unx     1593 b- defN 23-May-17 23:33 determined/deploy/aws/deployment_types/govcloud.py
+-rw-r--r--  2.0 unx     3094 b- defN 23-May-17 23:33 determined/deploy/aws/deployment_types/secure.py
+-rw-r--r--  2.0 unx     1349 b- defN 23-May-17 23:33 determined/deploy/aws/deployment_types/simple.py
+-rw-r--r--  2.0 unx     1400 b- defN 23-May-17 23:33 determined/deploy/aws/deployment_types/vpc.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-17 23:33 determined/deploy/aws/templates/__init__.py
+-rw-r--r--  2.0 unx    29259 b- defN 23-May-17 23:33 determined/deploy/aws/templates/efs.yaml
+-rw-r--r--  2.0 unx    29969 b- defN 23-May-17 23:33 determined/deploy/aws/templates/fsx.yaml
+-rw-r--r--  2.0 unx    23518 b- defN 23-May-17 23:33 determined/deploy/aws/templates/govcloud.yaml
+-rw-r--r--  2.0 unx    29153 b- defN 23-May-17 23:33 determined/deploy/aws/templates/secure.yaml
+-rw-r--r--  2.0 unx    24926 b- defN 23-May-17 23:33 determined/deploy/aws/templates/simple.yaml
+-rw-r--r--  2.0 unx        0 b- defN 23-May-17 23:33 determined/deploy/gcp/__init__.py
+-rw-r--r--  2.0 unx    19015 b- defN 23-May-17 23:33 determined/deploy/gcp/cli.py
+-rw-r--r--  2.0 unx      772 b- defN 23-May-17 23:33 determined/deploy/gcp/constants.py
+-rw-r--r--  2.0 unx    12420 b- defN 23-May-17 23:33 determined/deploy/gcp/gcp.py
+-rw-r--r--  2.0 unx     2380 b- defN 23-May-17 23:33 determined/deploy/gcp/preflight.py
+-rw-r--r--  2.0 unx     5376 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/main.tf
+-rw-r--r--  2.0 unx     1569 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/master.yaml.tmpl
+-rw-r--r--  2.0 unx     1487 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/outputs.tf
+-rw-r--r--  2.0 unx     3767 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/variables.tf
+-rw-r--r--  2.0 unx     6122 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/compute/main.tf
+-rw-r--r--  2.0 unx      424 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/compute/outputs.tf
+-rw-r--r--  2.0 unx     1574 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/compute/variables.tf
+-rw-r--r--  2.0 unx     1222 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/database/main.tf
+-rw-r--r--  2.0 unx      283 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/database/outputs.tf
+-rw-r--r--  2.0 unx      320 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/database/variables.tf
+-rw-r--r--  2.0 unx      522 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/filestore/main.tf
+-rw-r--r--  2.0 unx      184 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/filestore/outputs.tf
+-rw-r--r--  2.0 unx      125 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/filestore/variables.tf
+-rw-r--r--  2.0 unx     1026 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/firewall/main.tf
+-rw-r--r--  2.0 unx      195 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/firewall/outputs.tf
+-rw-r--r--  2.0 unx       75 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/firewall/variables.tf
+-rw-r--r--  2.0 unx      637 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/gcs/main.tf
+-rw-r--r--  2.0 unx       51 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/gcs/outputs.tf
+-rw-r--r--  2.0 unx      161 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/gcs/variables.tf
+-rw-r--r--  2.0 unx      161 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/ip/main.tf
+-rw-r--r--  2.0 unx      122 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/ip/outputs.tf
+-rw-r--r--  2.0 unx       88 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/ip/variables.tf
+-rw-r--r--  2.0 unx     1112 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/network/main.tf
+-rw-r--r--  2.0 unx      275 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/network/outputs.tf
+-rw-r--r--  2.0 unx      207 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/network/variables.tf
+-rw-r--r--  2.0 unx      962 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/service_account/main.tf
+-rw-r--r--  2.0 unx       73 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/service_account/outputs.tf
+-rw-r--r--  2.0 unx      138 b- defN 23-May-17 23:33 determined/deploy/gcp/terraform/modules/service_account/variables.tf
+-rw-r--r--  2.0 unx        0 b- defN 23-May-17 23:33 determined/deploy/gke/__init__.py
+-rw-r--r--  2.0 unx    19568 b- defN 23-May-17 23:33 determined/deploy/gke/cli.py
+-rw-r--r--  2.0 unx      408 b- defN 23-May-17 23:33 determined/deploy/gke/constants.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-17 23:33 determined/deploy/local/__init__.py
+-rw-r--r--  2.0 unx    12829 b- defN 23-May-17 23:33 determined/deploy/local/cli.py
+-rw-r--r--  2.0 unx    16913 b- defN 23-May-17 23:33 determined/deploy/local/cluster_utils.py
+-rw-r--r--  2.0 unx     1134 b- defN 23-May-17 23:33 determined/deploy/local/preflight.py
+-rw-r--r--  2.0 unx      697 b- defN 23-May-17 23:33 determined/estimator/__init__.py
+-rw-r--r--  2.0 unx     1288 b- defN 23-May-17 23:33 determined/estimator/_callback.py
+-rw-r--r--  2.0 unx     7375 b- defN 23-May-17 23:33 determined/estimator/_estimator_context.py
+-rw-r--r--  2.0 unx    40175 b- defN 23-May-17 23:33 determined/estimator/_estimator_trial.py
+-rw-r--r--  2.0 unx     3086 b- defN 23-May-17 23:33 determined/estimator/_load.py
+-rw-r--r--  2.0 unx    13742 b- defN 23-May-17 23:33 determined/estimator/_reducer.py
+-rw-r--r--  2.0 unx     9600 b- defN 23-May-17 23:33 determined/estimator/_util.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-17 23:33 determined/exec/__init__.py
+-rw-r--r--  2.0 unx     3836 b- defN 23-May-17 23:33 determined/exec/gc_checkpoints.py
+-rw-r--r--  2.0 unx     8857 b- defN 23-May-17 23:33 determined/exec/harness.py
+-rw-r--r--  2.0 unx     4233 b- defN 23-May-17 23:33 determined/exec/launch.py
+-rw-r--r--  2.0 unx      389 b- defN 23-May-17 23:33 determined/exec/pid_client.py
+-rw-r--r--  2.0 unx     1476 b- defN 23-May-17 23:33 determined/exec/pid_server.py
+-rw-r--r--  2.0 unx    13479 b- defN 23-May-17 23:33 determined/exec/prep_container.py
+-rw-r--r--  2.0 unx    10994 b- defN 23-May-17 23:33 determined/exec/tensorboard.py
+-rw-r--r--  2.0 unx      264 b- defN 23-May-17 23:33 determined/experimental/__init__.py
+-rw-r--r--  2.0 unx     3473 b- defN 23-May-17 23:33 determined/experimental/_native.py
+-rw-r--r--  2.0 unx    15160 b- defN 23-May-17 23:33 determined/experimental/client.py
+-rw-r--r--  2.0 unx      744 b- defN 23-May-17 23:33 determined/keras/__init__.py
+-rw-r--r--  2.0 unx     7579 b- defN 23-May-17 23:33 determined/keras/_data.py
+-rw-r--r--  2.0 unx    11491 b- defN 23-May-17 23:33 determined/keras/_enqueuer.py
+-rw-r--r--  2.0 unx     4020 b- defN 23-May-17 23:33 determined/keras/_load.py
+-rw-r--r--  2.0 unx      486 b- defN 23-May-17 23:33 determined/keras/_tensorboard_callback.py
+-rw-r--r--  2.0 unx    19042 b- defN 23-May-17 23:33 determined/keras/_tf_keras_context.py
+-rw-r--r--  2.0 unx     1204 b- defN 23-May-17 23:33 determined/keras/_tf_keras_multi_gpu.py
+-rw-r--r--  2.0 unx    48040 b- defN 23-May-17 23:33 determined/keras/_tf_keras_trial.py
+-rw-r--r--  2.0 unx    28556 b- defN 23-May-17 23:33 determined/keras/callbacks.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-17 23:33 determined/launch/__init__.py
+-rw-r--r--  2.0 unx    13720 b- defN 23-May-17 23:33 determined/launch/deepspeed.py
+-rw-r--r--  2.0 unx    10813 b- defN 23-May-17 23:33 determined/launch/horovod.py
+-rw-r--r--  2.0 unx     4574 b- defN 23-May-17 23:33 determined/launch/torch_distributed.py
+-rw-r--r--  2.0 unx     4502 b- defN 23-May-17 23:33 determined/launch/wrap_rank.py
+-rw-r--r--  2.0 unx       98 b- defN 23-May-17 23:33 determined/layers/__init__.py
+-rw-r--r--  2.0 unx    19401 b- defN 23-May-17 23:33 determined/layers/_workload_sequencer.py
+-rw-r--r--  2.0 unx     1151 b- defN 23-May-17 23:33 determined/pytorch/__init__.py
+-rw-r--r--  2.0 unx     5459 b- defN 23-May-17 23:33 determined/pytorch/_callback.py
+-rw-r--r--  2.0 unx    16294 b- defN 23-May-17 23:33 determined/pytorch/_data.py
+-rw-r--r--  2.0 unx     3670 b- defN 23-May-17 23:33 determined/pytorch/_experimental.py
+-rw-r--r--  2.0 unx    12510 b- defN 23-May-17 23:33 determined/pytorch/_load.py
+-rw-r--r--  2.0 unx     3286 b- defN 23-May-17 23:33 determined/pytorch/_lr_scheduler.py
+-rw-r--r--  2.0 unx     8275 b- defN 23-May-17 23:33 determined/pytorch/_metric_utils.py
+-rw-r--r--  2.0 unx    45136 b- defN 23-May-17 23:33 determined/pytorch/_pytorch_context.py
+-rw-r--r--  2.0 unx    68474 b- defN 23-May-17 23:33 determined/pytorch/_pytorch_trial.py
+-rw-r--r--  2.0 unx    21406 b- defN 23-May-17 23:33 determined/pytorch/_reducer.py
+-rw-r--r--  2.0 unx    13510 b- defN 23-May-17 23:33 determined/pytorch/_trainer.py
+-rw-r--r--  2.0 unx     9561 b- defN 23-May-17 23:33 determined/pytorch/samplers.py
+-rw-r--r--  2.0 unx      347 b- defN 23-May-17 23:33 determined/pytorch/deepspeed/__init__.py
+-rw-r--r--  2.0 unx    17524 b- defN 23-May-17 23:33 determined/pytorch/deepspeed/_deepspeed_context.py
+-rw-r--r--  2.0 unx    42777 b- defN 23-May-17 23:33 determined/pytorch/deepspeed/_deepspeed_trial.py
+-rw-r--r--  2.0 unx     1987 b- defN 23-May-17 23:33 determined/pytorch/deepspeed/_mpu.py
+-rw-r--r--  2.0 unx       67 b- defN 23-May-17 23:33 determined/pytorch/lightning/__init__.py
+-rw-r--r--  2.0 unx    18157 b- defN 23-May-17 23:33 determined/pytorch/lightning/_adapter.py
+-rw-r--r--  2.0 unx      343 b- defN 23-May-17 23:33 determined/searcher/__init__.py
+-rw-r--r--  2.0 unx     3563 b- defN 23-May-17 23:33 determined/searcher/_remote_search_runner.py
+-rw-r--r--  2.0 unx    10081 b- defN 23-May-17 23:33 determined/searcher/_search_method.py
+-rw-r--r--  2.0 unx    14053 b- defN 23-May-17 23:33 determined/searcher/_search_runner.py
+-rw-r--r--  2.0 unx      512 b- defN 23-May-17 23:33 determined/tensorboard/__init__.py
+-rw-r--r--  2.0 unx     1573 b- defN 23-May-17 23:33 determined/tensorboard/azure.py
+-rw-r--r--  2.0 unx     5884 b- defN 23-May-17 23:33 determined/tensorboard/base.py
+-rw-r--r--  2.0 unx     4534 b- defN 23-May-17 23:33 determined/tensorboard/build.py
+-rw-r--r--  2.0 unx     2305 b- defN 23-May-17 23:33 determined/tensorboard/gcs.py
+-rw-r--r--  2.0 unx     1333 b- defN 23-May-17 23:33 determined/tensorboard/hdfs.py
+-rw-r--r--  2.0 unx     1892 b- defN 23-May-17 23:33 determined/tensorboard/s3.py
+-rw-r--r--  2.0 unx     1747 b- defN 23-May-17 23:33 determined/tensorboard/shared.py
+-rw-r--r--  2.0 unx     3734 b- defN 23-May-17 23:33 determined/tensorboard/util.py
+-rw-r--r--  2.0 unx      780 b- defN 23-May-17 23:33 determined/tensorboard/fetchers/__init__.py
+-rw-r--r--  2.0 unx     2534 b- defN 23-May-17 23:33 determined/tensorboard/fetchers/azure.py
+-rw-r--r--  2.0 unx     1670 b- defN 23-May-17 23:33 determined/tensorboard/fetchers/base.py
+-rw-r--r--  2.0 unx     1733 b- defN 23-May-17 23:33 determined/tensorboard/fetchers/gcs.py
+-rw-r--r--  2.0 unx     2476 b- defN 23-May-17 23:33 determined/tensorboard/fetchers/s3.py
+-rw-r--r--  2.0 unx     1634 b- defN 23-May-17 23:33 determined/tensorboard/fetchers/shared.py
+-rw-r--r--  2.0 unx       91 b- defN 23-May-17 23:33 determined/tensorboard/metric_writers/__init__.py
+-rw-r--r--  2.0 unx     2113 b- defN 23-May-17 23:33 determined/tensorboard/metric_writers/callback.py
+-rw-r--r--  2.0 unx     2936 b- defN 23-May-17 23:33 determined/tensorboard/metric_writers/pytorch.py
+-rw-r--r--  2.0 unx     4385 b- defN 23-May-17 23:33 determined/tensorboard/metric_writers/tensorflow.py
+-rw-r--r--  2.0 unx     1262 b- defN 23-May-17 23:33 determined-0.22.2rc0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-17 23:33 determined-0.22.2rc0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       53 b- defN 23-May-17 23:33 determined-0.22.2rc0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       11 b- defN 23-May-17 23:33 determined-0.22.2rc0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    22843 b- defN 23-May-17 23:33 determined-0.22.2rc0.dist-info/RECORD
+249 files, 2373438 bytes uncompressed, 532756 bytes compressed:  77.6%
```

## zipnote {}

```diff
@@ -726,23 +726,23 @@
 
 Filename: determined/tensorboard/metric_writers/pytorch.py
 Comment: 
 
 Filename: determined/tensorboard/metric_writers/tensorflow.py
 Comment: 
 
-Filename: determined-0.22.1rc1.dist-info/METADATA
+Filename: determined-0.22.2rc0.dist-info/METADATA
 Comment: 
 
-Filename: determined-0.22.1rc1.dist-info/WHEEL
+Filename: determined-0.22.2rc0.dist-info/WHEEL
 Comment: 
 
-Filename: determined-0.22.1rc1.dist-info/entry_points.txt
+Filename: determined-0.22.2rc0.dist-info/entry_points.txt
 Comment: 
 
-Filename: determined-0.22.1rc1.dist-info/top_level.txt
+Filename: determined-0.22.2rc0.dist-info/top_level.txt
 Comment: 
 
-Filename: determined-0.22.1rc1.dist-info/RECORD
+Filename: determined-0.22.2rc0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## determined/__version__.py

```diff
@@ -1 +1 @@
-__version__ = "0.22.1-rc1"
+__version__ = "0.22.2-rc0"
```

## determined/cli/cli.py

```diff
@@ -46,15 +46,21 @@
 from determined.cli.user_groups import args_description as user_groups_args_description
 from determined.cli.version import args_description as version_args_description
 from determined.cli.version import check_version
 from determined.cli.workspace import args_description as workspace_args_description
 from determined.common import api, yaml
 from determined.common.api import authentication, bindings, certs
 from determined.common.check import check_not_none
-from determined.common.declarative_argparse import Arg, Cmd, add_args, generate_aliases
+from determined.common.declarative_argparse import (
+    Arg,
+    ArgsDescription,
+    Cmd,
+    add_args,
+    generate_aliases,
+)
 from determined.common.util import (
     chunks,
     debug_mode,
     get_default_master_address,
     safe_load_yaml_with_exceptions,
 )
 from determined.errors import EnterpriseOnlyError
@@ -116,37 +122,40 @@
     yml.indent(mapping=2, sequence=4, offset=2)
     yml.dump(experiment_config["searcher"], sys.stdout)
     print()
     print("This search will create a total of {} trial(s).".format(sum(j["results"].values())))
     print(tabulate.tabulate(values, headers, tablefmt="presto"), flush=False)
 
 
-# fmt: off
-
 args_description = [
-    Arg("-u", "--user",
-        help="run as the given user", metavar="username",
-        default=None),
-    Arg("-m", "--master",
-        help="master address", metavar="address",
-        default=get_default_master_address()),
-    Arg("-v", "--version",
-        action="version", help="print CLI version and exit",
-        version="%(prog)s {}".format(determined.__version__)),
-
-    Cmd("preview-search", preview_search, "preview search", [
-        Arg("config_file", type=FileType("r"),
-            help="experiment config file (.yaml)")
-    ]),
+    Arg("-u", "--user", help="run as the given user", metavar="username", default=None),
+    Arg(
+        "-m",
+        "--master",
+        help="master address",
+        metavar="address",
+        default=get_default_master_address(),
+    ),
+    Arg(
+        "-v",
+        "--version",
+        action="version",
+        help="print CLI version and exit",
+        version="%(prog)s {}".format(determined.__version__),
+    ),
+    Cmd(
+        "preview-search",
+        preview_search,
+        "preview search",
+        [Arg("config_file", type=FileType("r"), help="experiment config file (.yaml)")],
+    ),
     deploy_cmd,
-]  # type: List[object]
-
-# fmt: on
+]  # type: ArgsDescription
 
-all_args_description = (
+all_args_description: ArgsDescription = (
     args_description
     + experiment_args_description
     + checkpoint_args_description
     + master_args_description
     + model_args_description
     + agent_args_description
     + notebook_args_description
```

## determined/cli/command.py

```diff
@@ -17,15 +17,17 @@
 yaml = yaml.YAML(typ="safe", pure=True)  # type: ignore
 
 
 CONFIG_DESC = """
 Additional configuration arguments for setting up a command.
 Arguments should be specified as `key=value`. Nested configuration
 keys can be specified by dot notation, e.g., `resources.slots=4`.
-List values can be specified by comma-separated values.
+List values can be specified by comma-separated values. More
+complex configuration values can be specified using JSON, e.g.,
+`bind_mounts=[{host_path: "/tmp", container_path: "/tmp"}]`.
 """
 
 CONTEXT_DESC = """
 A directory whose contents should be copied into the task container.
 Unlike --include, the directory itself will not appear in the task
 container, only its contents.  The total bytes copied into the container
 must not exceed 96 MB.  By default, no files are copied.  See also:
@@ -294,21 +296,28 @@
             raise ValueError(
                 "Could not read configuration option '{}'\n\n"
                 "Expecting:\n{}".format(config_arg, CONFIG_DESC)
             )
 
         key, value = config_arg.split("=", maxsplit=1)  # type: Tuple[str, Any]
 
+        # Complex objects may contain commas but are not intended to be split
+        # on commas and have their parts parsed separately.
+        if value.startswith(("[", "{")):
+            value = yaml.load(value)
+            # Certain configurations keys are expected to have list values.
+            # Convert a single value to a singleton list if needed.
+            if key in _CONFIG_PATHS_COERCE_TO_LIST and value.startswith("{"):
+                value = [value]
         # Separate values if a comma exists. Use yaml.load() to cast
         # the value(s) to the type YAML would use, e.g., "4" -> 4.
-        if "," in value:
+        elif "," in value:
             value = [yaml.load(v) for v in value.split(",")]
         else:
             value = yaml.load(value)
-
             # Certain configurations keys are expected to have list values.
             # Convert a single value to a singleton list if needed.
             if key in _CONFIG_PATHS_COERCE_TO_LIST:
                 value = [value]
 
         # TODO(#2703): Consider using full JSONPath spec instead of dot
         # notation.
```

## determined/cli/experiment.py

```diff
@@ -31,20 +31,14 @@
 from .trial import logs_args_description
 
 # Avoid reporting BrokenPipeError when piping `tabulate` output through
 # a filter like `head`.
 FLUSH = False
 
 
-def patch_experiment(args: Namespace, patch_doc: Dict[str, Any]) -> None:
-    path = f"experiments/{args.experiment_id}"
-    headers = {"Content-Type": "application/merge-patch+json"}
-    cli.setup_session(args).patch(path, json=patch_doc, headers=headers)
-
-
 @authentication.required
 def activate(args: Namespace) -> None:
     bindings.post_ActivateExperiment(cli.setup_session(args), id=args.experiment_id)
     print(f"Activated experiment {args.experiment_id}")
 
 
 @authentication.required
@@ -646,14 +640,15 @@
 def download_model_def(args: Namespace) -> None:
     resp = bindings.get_GetModelDef(cli.setup_session(args), experimentId=args.experiment_id)
     dst = f"experiment_{args.experiment_id}_model_def.tgz"
     with args.output_dir.joinpath(dst).open("wb") as f:
         f.write(base64.b64decode(resp.b64Tgz))
 
 
+@authentication.required
 def download(args: Namespace) -> None:
     exp = client.ExperimentReference(args.experiment_id, cli.setup_session(args))
     checkpoints = exp.top_n_checkpoints(
         args.top_n, sort_by=args.sort_by, smaller_is_better=args.smaller_is_better
     )
 
     top_level = pathlib.Path(args.output_dir)
@@ -685,15 +680,15 @@
 def list_experiments(args: Namespace) -> None:
     session = cli.setup_session(args)
 
     def get_with_offset(offset: int) -> bindings.v1GetExperimentsResponse:
         return bindings.get_GetExperiments(
             session,
             offset=offset,
-            archived=False if args.all else None,
+            archived=None if args.all else False,
             limit=args.limit,
             users=None if args.all else [authentication.must_cli_auth().get_session_user()],
         )
 
     resps = api.read_paginated(get_with_offset, offset=args.offset, pages=args.pages)
     all_experiments = [e for r in resps for e in r.experiments]
 
@@ -852,39 +847,53 @@
         exp_patch.labels = [label for label in exp_patch.labels if label != args.label]
         bindings.patch_PatchExperiment(session, body=exp_patch, experiment_id=args.experiment_id)
     print(f"Removed label '{args.label}' from experiment {args.experiment_id}")
 
 
 @authentication.required
 def set_max_slots(args: Namespace) -> None:
-    patch_experiment(args, {"resources": {"max_slots": args.max_slots}})
+    session = cli.setup_session(args)
+    exp_patch = bindings.v1PatchExperiment(
+        id=args.experiment_id,
+        resources=bindings.PatchExperimentPatchResources(maxSlots=args.max_slots),
+    )
+    bindings.patch_PatchExperiment(session, body=exp_patch, experiment_id=args.experiment_id)
     print(f"Set `max_slots` of experiment {args.experiment_id} to {args.max_slots}")
 
 
 @authentication.required
 def set_weight(args: Namespace) -> None:
-    patch_experiment(args, {"resources": {"weight": args.weight}})
+    session = cli.setup_session(args)
+    exp_patch = bindings.v1PatchExperiment(
+        id=args.experiment_id, resources=bindings.PatchExperimentPatchResources(weight=args.weight)
+    )
+    bindings.patch_PatchExperiment(session, body=exp_patch, experiment_id=args.experiment_id)
     print(f"Set `weight` of experiment {args.experiment_id} to {args.weight}")
 
 
 @authentication.required
 def set_priority(args: Namespace) -> None:
-    patch_experiment(args, {"resources": {"priority": args.priority}})
+    session = cli.setup_session(args)
+    exp_patch = bindings.v1PatchExperiment(
+        id=args.experiment_id,
+        resources=bindings.PatchExperimentPatchResources(priority=args.priority),
+    )
+    bindings.patch_PatchExperiment(session, body=exp_patch, experiment_id=args.experiment_id)
     print(f"Set `priority` of experiment {args.experiment_id} to {args.priority}")
 
 
 @authentication.required
 def set_gc_policy(args: Namespace) -> None:
-    policy = {
-        "save_experiment_best": args.save_experiment_best,
-        "save_trial_best": args.save_trial_best,
-        "save_trial_latest": args.save_trial_latest,
-    }
-
     if not args.yes:
+        policy = {
+            "save_experiment_best": args.save_experiment_best,
+            "save_trial_best": args.save_trial_best,
+            "save_trial_latest": args.save_trial_latest,
+        }
+
         r = api.get(args.master, f"experiments/{args.experiment_id}/preview_gc", params=policy)
         response = r.json()
         checkpoints = response["checkpoints"]
         metric_name = response["metric_name"]
 
         headers = [
             "Trial ID",
@@ -922,15 +931,24 @@
 
     if args.yes or render.yes_or_no(
         "Changing the checkpoint garbage collection policy of an "
         "experiment may result\n"
         "in the unrecoverable deletion of checkpoints.  Do you wish to "
         "proceed?"
     ):
-        patch_experiment(args, {"checkpoint_storage": policy})
+        session = cli.setup_session(args)
+        exp_patch = bindings.v1PatchExperiment(
+            id=args.experiment_id,
+            checkpointStorage=bindings.PatchExperimentPatchCheckpointStorage(
+                saveExperimentBest=args.save_experiment_best,
+                saveTrialBest=args.save_trial_best,
+                saveTrialLatest=args.save_trial_latest,
+            ),
+        )
+        bindings.patch_PatchExperiment(session, body=exp_patch, experiment_id=args.experiment_id)
         print(f"Set GC policy of experiment {args.experiment_id} to\n{pformat(policy)}")
     else:
         print("Aborting operations.")
 
 
 @authentication.required
 def unarchive(args: Namespace) -> None:
@@ -1005,16 +1023,16 @@
         Cmd(
             "logs",
             experiment_logs,
             "fetch logs of the first trial of an experiment",
             [
                 experiment_id_arg("experiment ID"),
                 cli.output_format_args["json"],
-            ]
-            + logs_args_description,
+                *logs_args_description,
+            ],
         ),
         Cmd(
             "download-model-def",
             download_model_def,
             "download model definition",
             [
                 experiment_id_arg("experiment ID"),
```

## determined/cli/notebook.py

```diff
@@ -52,15 +52,15 @@
                 url = api.browser_open(
                     args.master,
                     request.make_interactive_task_url(
                         task_id=nb.id,
                         service_address=nb.serviceAddress,
                         description=nb.description,
                         resource_pool=nb.resourcePool,
-                        task_type="notebook",
+                        task_type="jupyter-lab",
                         currentSlotsExceeded=currentSlotsExceeded,
                     ),
                 )
                 print(colored("Jupyter Notebook is running at: {}".format(url), "green"))
             command.render_event_stream(msg)
 
 
@@ -73,15 +73,15 @@
     api.browser_open(
         args.master,
         request.make_interactive_task_url(
             task_id=resp["id"],
             service_address=resp["serviceAddress"],
             description=resp["description"],
             resource_pool=resp["resourcePool"],
-            task_type="notebook",
+            task_type="jupyter-lab",
             currentSlotsExceeded=False,
         ),
     )
 
 
 # fmt: off
```

## determined/cli/resources.py

```diff
@@ -1,16 +1,15 @@
 import sys
 from argparse import Namespace
-from typing import Any, List
 
 import requests
 
 from determined.common import api
 from determined.common.api import authentication
-from determined.common.declarative_argparse import Arg, Cmd
+from determined.common.declarative_argparse import Arg, ArgsDescription, Cmd
 
 
 # Print the body of a response in chunks so we don't have to buffer the whole thing.
 def print_response(r: requests.Response) -> None:
     for chunk in r.iter_content(chunk_size=4096):
         sys.stdout.buffer.write(chunk)
 
@@ -33,15 +32,15 @@
     }
     path = (
         "api/v1/resources/allocation/aggregated" if args.json else "resources/allocation/aggregated"
     )
     print_response(api.get(args.master, path, params=params))
 
 
-args_description = [
+args_description: ArgsDescription = [
     Cmd(
         "res|ources",
         None,
         "query historical resource allocation",
         [
             Cmd(
                 "raw",
@@ -66,8 +65,8 @@
                         action="store_true",
                         help="aggregate by month rather than by day",
                     ),
                 ],
             ),
         ],
     )
-]  # type: List[Any]
+]
```

## determined/cli/sso.py

```diff
@@ -1,10 +1,11 @@
 import sys
 import webbrowser
 from argparse import Namespace
+from getpass import getpass
 from http.server import BaseHTTPRequestHandler, HTTPServer
 from typing import Any, Callable, List
 from urllib.parse import parse_qs, urlparse
 
 from determined.common import api
 from determined.common.api import authentication
 from determined.common.declarative_argparse import Arg, Cmd
@@ -97,20 +98,20 @@
     print(
         f"Please open this URL in your browser: '{sso_url}'\n"
         "After authenticating, copy/paste the localhost URL "
         f"from your browser into the prompt.\n{example_url}"
     )
     token = None
     while not token:
-        user_input_url = input("\nlocalhost URL? ")
+        user_input_url = getpass(prompt="\n(hidden) localhost URL? ")
         try:
             token = parse_qs(urlparse(user_input_url).query)["token"][0]
             handle_token(parsed_args.master, token)
         except (KeyError, IndexError):
-            print("Could not extract token from localhost URL. {example_url}")
+            print(f"Could not extract token from localhost URL. {example_url}")
 
 
 def list_providers(parsed_args: Namespace) -> None:
     master_info = api.get(parsed_args.master, "info", authenticated=False).json()
 
     try:
         sso_providers = master_info["sso_providers"]
```

## determined/cli/template.py

```diff
@@ -1,34 +1,38 @@
-from argparse import FileType, Namespace
+from argparse import ArgumentError, FileType, Namespace
 from collections import namedtuple
 from typing import Any, Dict, List
 
 from termcolor import colored
 
 from determined import cli
-from determined.common import util, yaml
+from determined.cli.workspace import get_workspace_id_from_args, workspace_arg
+from determined.common import api, util, yaml
 from determined.common.api import authentication, bindings
 from determined.common.declarative_argparse import Arg, Cmd
 
 from . import render
 
-TemplateClean = namedtuple("TemplateClean", ["name"])
-TemplateAll = namedtuple("TemplateAll", ["name", "config"])
+TemplateClean = namedtuple("TemplateClean", ["name", "workspace"])
+TemplateAll = namedtuple("TemplateAll", ["name", "workspace", "config"])
 
 
 def _parse_config(data: Dict[str, Any]) -> Any:
     # Pretty print the config field.
     return yaml.safe_dump(data, default_flow_style=False)
 
 
 @authentication.required
 def list_template(args: Namespace) -> None:
     templates: List[TemplateAll] = []
+    w_names = cli.workspace.get_workspace_names(cli.setup_session(args))
+
     for tpl in bindings.get_GetTemplates(cli.setup_session(args)).templates:
-        templates.append(TemplateAll(tpl.name, _parse_config(tpl.config)))
+        w_name = w_names.get(tpl.workspaceId, "missing workspace")
+        templates.append(TemplateAll(tpl.name, w_name, _parse_config(tpl.config)))
     if args.details:
         render.render_objects(TemplateAll, templates, table_fmt="grid")
     else:
         render.render_objects(TemplateClean, templates)
 
 
 @authentication.required
@@ -38,44 +42,90 @@
     ).template
     print(_parse_config(tpl.config))
 
 
 @authentication.required
 def set_template(args: Namespace) -> None:
     with args.template_file:
+        """
+        WARN: this downgrades the atomic behavior of upsert but it's
+        an acceptable tradeoff for now until we can remove this command.
+        """
+        session = cli.setup_session(args)
         body = util.safe_load_yaml_with_exceptions(args.template_file)
-        v1_template = bindings.v1Template(name=args.template_name, config=body)
-        bindings.put_PutTemplate(
-            cli.setup_session(args), template_name=args.template_name, body=v1_template
-        )
+        try:
+            bindings.get_GetTemplate(session, templateName=args.template_name).template
+            bindings.patch_PatchTemplateConfig(session, templateName=args.template_name, body=body)
+        except api.errors.NotFoundException:
+            v1_template = bindings.v1Template(name=args.template_name, config=body, workspaceId=0)
+            bindings.post_PostTemplate(session, template_name=args.template_name, body=v1_template)
         print(colored("Set template {}".format(args.template_name), "green"))
 
 
 @authentication.required
+def create_template(args: Namespace) -> None:
+    if not args.template_file:
+        raise ArgumentError(None, "template_file is required for set command")
+    body = util.safe_load_yaml_with_exceptions(args.template_file)
+    workspace_id = get_workspace_id_from_args(args) or 0
+    v1_template = bindings.v1Template(
+        name=args.template_name, config=body, workspaceId=workspace_id
+    )
+    bindings.post_PostTemplate(
+        cli.setup_session(args), template_name=args.template_name, body=v1_template
+    )
+    print(colored("Created template {}".format(args.template_name), "green"))
+
+
+@authentication.required
+def patch_template_config(args: Namespace) -> None:
+    if not args.template_file:
+        raise ArgumentError(None, "template_file is required for set command")
+    body = util.safe_load_yaml_with_exceptions(args.template_file)
+    bindings.patch_PatchTemplateConfig(
+        cli.setup_session(args), templateName=args.template_name, body=body
+    )
+    print(colored("Updated template {}".format(args.template_name), "green"))
+
+
+@authentication.required
 def remove_templates(args: Namespace) -> None:
     bindings.delete_DeleteTemplate(cli.setup_session(args), templateName=args.template_name)
     print(colored("Removed template {}".format(args.template_name), "green"))
 
 
 # fmt: off
 
 args_description = [
     Cmd("template tpl", None, "manage config templates", [
         Cmd("list ls", list_template, "list config templates", [
             Arg("-d", "--details", action="store_true",
                 help="show the configs of the templates"),
         ], is_default=True),
+        Cmd("set", set_template, "set config template", [
+            Arg("template_name", help="template name"),
+            Arg("template_file", type=FileType("r"),
+                help="config template file (.yaml)"),
+        ], deprecation_message="use the following options `det template create|set-value`."),
+        Cmd("set-value", None, "set template attributes", [
+            Cmd("config", patch_template_config, "update config template", [
+                Arg("template_name", help="template name"),
+                Arg("template_file", type=FileType("r"),
+                    help="config template file (.yaml)"),
+            ]),
+        ]),
         Cmd("describe", describe_template,
             "describe config template", [
                 Arg("template_name", type=str, help="template name"),
             ]),
-        Cmd("set", set_template, "set config template", [
+        Cmd("create", create_template, "create config template", [
             Arg("template_name", help="template name"),
             Arg("template_file", type=FileType("r"),
-                help="config template file (.yaml)")
+                help="config template file (.yaml)"),
+            workspace_arg,
         ]),
         Cmd("remove rm", remove_templates,
             "remove config template", [
                 Arg("template_name", help="template name")
             ]),
     ])
 ]  # type: List[Any]
```

## determined/cli/tensorboard.py

```diff
@@ -1,20 +1,19 @@
 from argparse import ONE_OR_MORE, ArgumentError, FileType, Namespace
 from functools import partial
 from pathlib import Path
-from typing import Any, List
 
 from termcolor import colored
 
 from determined import cli
 from determined.cli import command, task
 from determined.common import api, context
 from determined.common.api import authentication, bindings, request
 from determined.common.check import check_eq
-from determined.common.declarative_argparse import Arg, Cmd, Group
+from determined.common.declarative_argparse import Arg, ArgsDescription, Cmd, Group
 
 
 @authentication.required
 def start_tensorboard(args: Namespace) -> None:
     if not (args.trial_ids or args.experiment_ids):
         raise ArgumentError(None, "Either experiment_ids or trial_ids must be specified.")
 
@@ -88,73 +87,131 @@
             description=resp["description"],
             task_type="tensorboard",
             currentSlotsExceeded=False,
         ),
     )
 
 
-# fmt: off
-
-args_description = [
-    Cmd("tensorboard", None, "manage TensorBoard instances", [
-        Cmd("list ls", partial(command.list_tasks), "list TensorBoard instances", [
-            Arg("-q", "--quiet", action="store_true",
-                help="only display the IDs"),
-            Arg("--all", "-a", action="store_true",
-                help="show all TensorBoards (including other users')"),
-            cli.workspace.workspace_arg,
-            Group(cli.output_format_args["json"], cli.output_format_args["csv"]),
-        ], is_default=True),
-        Cmd("start", start_tensorboard, "start new TensorBoard instance", [
-            Arg("experiment_ids", type=int, nargs="*",
-                help="experiment IDs to load into TensorBoard. At most 100 trials from "
-                     "the specified experiment will be loaded into TensorBoard. If the "
-                     "experiment has more trials, the 100 best-performing trials will "
-                     "be used."),
-            Arg("-t", "--trial-ids", nargs=ONE_OR_MORE, type=int,
-                help="trial IDs to load into TensorBoard; at most 100 trials are "
-                     "allowed per TensorBoard instance"),
-            cli.workspace.workspace_arg,
-            Arg("--config-file", default=None, type=FileType("r"),
-                help="command config file (.yaml)"),
-            Arg("-c", "--context", default=None, type=Path, help=command.CONTEXT_DESC),
-            Arg(
-                "-i",
-                "--include",
-                default=[],
-                action="append",
-                type=Path,
-                help=command.INCLUDE_DESC
-            ),
-            Arg("--config", action="append", default=[], help=command.CONFIG_DESC),
-            Arg("--no-browser", action="store_true",
-                help="don't open TensorBoard in a browser after startup"),
-            Arg("-d", "--detach", action="store_true",
-                help="run in the background and print the ID")
-        ]),
-        Cmd("config", partial(command.config),
-            "display TensorBoard config", [
-                Arg("tensorboard_id", type=str, help="TensorBoard ID")
-        ]),
-        Cmd("open", open_tensorboard,
-            "open existing TensorBoard instance", [
-                Arg("tensorboard_id", help="TensorBoard ID")
-            ]),
-        Cmd("logs", partial(task.logs),
-            "fetch TensorBoard instance logs", [
-            Arg("task_id", help="TensorBoard ID", metavar="tensorboard_id"),
-            *task.common_log_options,
-        ]),
-        Cmd("kill", partial(command.kill), "kill TensorBoard instance", [
-            Arg("tensorboard_id", help="TensorBoard ID", nargs=ONE_OR_MORE),
-            Arg("-f", "--force", action="store_true", help="ignore errors"),
-        ]),
-        Cmd("set", None, "set TensorBoard attributes", [
-            Cmd("priority", partial(command.set_priority), "set TensorBoard priority", [
-                Arg("tensorboard_id", help="TensorBoard ID"),
-                Arg("priority", type=int, help="priority"),
-            ]),
-        ]),
-    ])
-]  # type: List[Any]
-
-# fmt: on
+args_description: ArgsDescription = [
+    Cmd(
+        "tensorboard",
+        None,
+        "manage TensorBoard instances",
+        [
+            Cmd(
+                "list ls",
+                partial(command.list_tasks),
+                "list TensorBoard instances",
+                [
+                    Arg("-q", "--quiet", action="store_true", help="only display the IDs"),
+                    Arg(
+                        "--all",
+                        "-a",
+                        action="store_true",
+                        help="show all TensorBoards (including other users')",
+                    ),
+                    cli.workspace.workspace_arg,
+                    Group(cli.output_format_args["json"], cli.output_format_args["csv"]),
+                ],
+                is_default=True,
+            ),
+            Cmd(
+                "start",
+                start_tensorboard,
+                "start new TensorBoard instance",
+                [
+                    Arg(
+                        "experiment_ids",
+                        type=int,
+                        nargs="*",
+                        help="experiment IDs to load into TensorBoard. At most 100 trials from "
+                        "the specified experiment will be loaded into TensorBoard. If the "
+                        "experiment has more trials, the 100 best-performing trials will "
+                        "be used.",
+                    ),
+                    Arg(
+                        "-t",
+                        "--trial-ids",
+                        nargs=ONE_OR_MORE,
+                        type=int,
+                        help="trial IDs to load into TensorBoard; at most 100 trials are "
+                        "allowed per TensorBoard instance",
+                    ),
+                    cli.workspace.workspace_arg,
+                    Arg(
+                        "--config-file",
+                        default=None,
+                        type=FileType("r"),
+                        help="command config file (.yaml)",
+                    ),
+                    Arg("-c", "--context", default=None, type=Path, help=command.CONTEXT_DESC),
+                    Arg(
+                        "-i",
+                        "--include",
+                        default=[],
+                        action="append",
+                        type=Path,
+                        help=command.INCLUDE_DESC,
+                    ),
+                    Arg("--config", action="append", default=[], help=command.CONFIG_DESC),
+                    Arg(
+                        "--no-browser",
+                        action="store_true",
+                        help="don't open TensorBoard in a browser after startup",
+                    ),
+                    Arg(
+                        "-d",
+                        "--detach",
+                        action="store_true",
+                        help="run in the background and print the ID",
+                    ),
+                ],
+            ),
+            Cmd(
+                "config",
+                partial(command.config),
+                "display TensorBoard config",
+                [Arg("tensorboard_id", type=str, help="TensorBoard ID")],
+            ),
+            Cmd(
+                "open",
+                open_tensorboard,
+                "open existing TensorBoard instance",
+                [Arg("tensorboard_id", help="TensorBoard ID")],
+            ),
+            Cmd(
+                "logs",
+                partial(task.logs),
+                "fetch TensorBoard instance logs",
+                [
+                    Arg("task_id", help="TensorBoard ID", metavar="tensorboard_id"),
+                    *task.common_log_options,
+                ],
+            ),
+            Cmd(
+                "kill",
+                partial(command.kill),
+                "kill TensorBoard instance",
+                [
+                    Arg("tensorboard_id", help="TensorBoard ID", nargs=ONE_OR_MORE),
+                    Arg("-f", "--force", action="store_true", help="ignore errors"),
+                ],
+            ),
+            Cmd(
+                "set",
+                None,
+                "set TensorBoard attributes",
+                [
+                    Cmd(
+                        "priority",
+                        partial(command.set_priority),
+                        "set TensorBoard priority",
+                        [
+                            Arg("tensorboard_id", help="TensorBoard ID"),
+                            Arg("priority", type=int, help="priority"),
+                        ],
+                    ),
+                ],
+            ),
+        ],
+    )
+]
```

## determined/cli/trial.py

```diff
@@ -10,15 +10,15 @@
 from termcolor import colored
 
 from determined import cli
 from determined.cli import render
 from determined.cli.master import format_log_entry
 from determined.common import api, constants
 from determined.common.api import authentication, bindings
-from determined.common.declarative_argparse import Arg, Cmd, Group
+from determined.common.declarative_argparse import Arg, ArgsDescription, Cmd, Group
 from determined.common.experimental import Determined
 
 from .checkpoint import render_checkpoint
 
 
 def _workload_container_unpack(
     container: bindings.v1WorkloadContainer,
@@ -278,15 +278,15 @@
 
 
 def create_json_file_in_dir(content: Any, file_path: str) -> None:
     with open(file_path, "w") as f:
         json.dump(content, f)
 
 
-logs_args_description = [
+logs_args_description: ArgsDescription = [
     Arg(
         "-f",
         "--follow",
         action="store_true",
         help="follow the logs of a running trial, similar to tail -f",
     ),
     Group(
@@ -344,17 +344,17 @@
     ),
     Arg(
         "--stdtype",
         dest="stdtypes",
         action="append",
         help="output stream to show logs from (repeat for multiple values)",
     ),
-]  # type: List[Any]
+]
 
-args_description = [
+args_description: ArgsDescription = [
     Cmd(
         "t|rial",
         None,
         "manage trials",
         [
             Cmd(
                 "describe",
@@ -448,16 +448,16 @@
             Cmd(
                 "logs",
                 trial_logs,
                 "fetch trial logs",
                 [
                     Arg("trial_id", type=int, help="trial ID"),
                     cli.output_format_args["json"],
-                ]
-                + logs_args_description,
+                    *logs_args_description,
+                ],
             ),
             Cmd(
                 "kill", kill_trial, "forcibly terminate a trial", [Arg("trial_id", help="trial ID")]
             ),
         ],
     ),
-]  # type: List[Any]
+]
```

## determined/cli/user.py

```diff
@@ -58,16 +58,19 @@
     token_store = authentication.TokenStore(parsed_args.master)
     token = authentication.do_login(parsed_args.master, username, password, certs.cli_cert)
     token_store.set_token(username, token)
     token_store.set_active(username)
 
 
 def log_out_user(parsed_args: Namespace) -> None:
-    # Log out of the user specified by the command line, or the active user.
-    authentication.logout(parsed_args.master, parsed_args.user, certs.cli_cert)
+    if parsed_args.all:
+        authentication.logout_all(parsed_args.master, certs.cli_cert)
+    else:
+        # Log out of the user specified by the command line, or the active user.
+        authentication.logout(parsed_args.master, parsed_args.user, certs.cli_cert)
 
 
 @login_sdk_client
 def rename(parsed_args: Namespace) -> None:
     user_obj = client.get_user_by_name(parsed_args.target_user)
     user_obj.rename(new_username=parsed_args.new_username)
 
@@ -157,15 +160,22 @@
         Cmd("rename", rename, "change username for user", [
             Arg("target_user", default=None, help="name of user whose username should be changed"),
             Arg("new_username", default=None, help="new username for target_user"),
         ]),
         Cmd("change-password", change_password, "change password for user", [
             Arg("target_user", nargs="?", default=None, help="name of user to change password of")
         ]),
-        Cmd("logout", log_out_user, "log out user", []),
+        Cmd("logout", log_out_user, "log out user", [
+            Arg(
+                "--all",
+                "-a",
+                action="store_true",
+                help="log out of all cached sessions for the current master",
+            ),
+        ]),
         Cmd("activate", activate_user, "activate user", [
             Arg("username", help="name of user to activate")
         ]),
         Cmd("deactivate", deactivate_user, "deactivate user", [
             Arg("username", help="name of user to deactivate")
         ]),
         Cmd("create", create_user, "create user", [
```

## determined/common/declarative_argparse.py

```diff
@@ -1,11 +1,14 @@
 import functools
 import itertools
+import sys
 from argparse import SUPPRESS, ArgumentDefaultsHelpFormatter, ArgumentParser, Namespace
-from typing import Any, Callable, List, NamedTuple, Optional, Tuple, cast
+from typing import Any, Callable, List, NamedTuple, Optional, Tuple, Union, cast
+
+from termcolor import colored
 
 
 def make_prefixes(desc: str) -> List[str]:
     parts = desc.split("|")
     ret = [parts[0]]
     for part in parts[1:]:
         ret.append(ret[-1] + part)
@@ -26,35 +29,64 @@
     => "checkout", ["c", "check", "co"]
     """
     prefixes = [make_prefixes(s) for s in spec.split()]
     main = prefixes[0].pop()
     return main, list(itertools.chain.from_iterable(prefixes))
 
 
+# ArgsDescription is a description of the subcommands and arguments for CLI arg parsing.
+ArgsDescription = List[Union["Arg", "Cmd", "Group", "ArgGroup", "BoolOptArg"]]
+
+
+def deprecation_warning(message: str, color: bool = True) -> str:
+    msg = f"DEPRECATED: {message}"
+    return colored(msg, "yellow") if color else msg
+
+
+def warn_on_usage(message: str) -> Callable:
+    """Wrap a function to print out a warning on usage."""
+
+    def decorator(func: Callable) -> Callable:
+        @functools.wraps(func)
+        def wrapper(*args: Any, **kwargs: Any) -> Any:
+            print(message, file=sys.stderr)
+            return func(*args, **kwargs)
+
+        return wrapper
+
+    return decorator
+
+
 # Classes used to represent the structure of an argument parser setup; these
 # are turned into actual `argparse` objects by `add_args`.
 class Cmd:
     """Describes a subcommand."""
 
     def __init__(
         self,
         name: str,
         func: Optional[Callable],
         help_str: str,
-        subs: List[Any],
+        subs: ArgsDescription,
         is_default: bool = False,
+        deprecation_message: Optional[str] = None,
     ) -> None:
         """
         `subs` is a list containing `Cmd`, `Arg`, and `Group` that describes
         the arguments, subcommands, and mutually exclusive argument groups
         for this command.
         """
         self.name = name
         self.help_str = help_str
+        self.deprecation_message = deprecation_message
         self.func = func
+        # wrap the fn in deprecation warning.
+        if self.deprecation_message and self.func:
+            self.func = warn_on_usage(deprecation_warning(self.deprecation_message))(self.func)
+
         if self.func:
             # Force the help string onto the actual function for later. This
             # can be used to print the help string
             self.func.__name__ = help_str
         self.subs = subs
         self.is_default = is_default
 
@@ -127,15 +159,15 @@
 
     def inner_func(args: Namespace) -> Any:
         parser.print_help()
 
     return inner_func
 
 
-def add_args(parser: ArgumentParser, description: List[Any], depth: int = 0) -> None:
+def add_args(parser: ArgumentParser, description: ArgsDescription, depth: int = 0) -> None:
     """
     Populate the given parser with arguments, as specified by the
     description. The description is a list of Arg, Cmd, and Group objects.
     """
     subparsers = None
     help_parser = None
 
@@ -166,14 +198,18 @@
             main_name, aliases = generate_aliases(thing.name)
 
             subparser_kwargs = {
                 "aliases": aliases,
                 "formatter_class": ArgumentDefaultsHelpFormatter,
             }
             if thing.help_str != SUPPRESS:
+                if thing.deprecation_message:
+                    thing.help_str += " " + deprecation_warning(
+                        thing.deprecation_message, color=False
+                    )
                 subparser_kwargs["help"] = thing.help_str
             subparser = subparsers.add_parser(main_name, **subparser_kwargs)
 
             subparser.set_defaults(func=thing.func)
             subparser.set_defaults(**{("_" + "sub" * depth + "command"): thing.name})
 
             # If this is the default subcommand, make calling the parent with
```

## determined/common/api/authentication.py

```diff
@@ -1,15 +1,15 @@
 import argparse
 import contextlib
 import functools
 import getpass
 import hashlib
 import json
 import pathlib
-from typing import Any, Callable, Dict, Iterator, NamedTuple, Optional, Tuple, cast
+from typing import Any, Callable, Dict, Iterator, List, NamedTuple, Optional, Tuple, cast
 
 import filelock
 
 import determined as det
 from determined.common import api, constants, util
 from determined.common.api import bindings, certs
 
@@ -214,14 +214,24 @@
     try:
         bindings.post_Logout(sess)
     except (api.errors.UnauthenticatedException, api.errors.APIException):
         # This session may have expired, but we don't care.
         pass
 
 
+def logout_all(master_address: Optional[str], cert: Optional[certs.Cert]) -> None:
+    master_address = master_address or util.get_default_master_address()
+    token_store = TokenStore(master_address)
+
+    users = token_store.get_all_users()
+
+    for user in users:
+        logout(master_address, user, cert)
+
+
 def _is_token_valid(master_address: str, token: str, cert: Optional[certs.Cert]) -> bool:
     """
     Find out whether the given token is valid by attempting to use it
     on the "api/v1/me" endpoint.
     """
     headers = {"Authorization": "Bearer {}".format(token)}
     try:
@@ -258,14 +268,17 @@
         substore = store.get("masters", {}).get(self.master_address, {})
         self._active_user = cast(str, substore.get("active_user"))
         self._tokens = cast(Dict[str, str], substore.get("tokens", {}))
 
     def get_active_user(self) -> Optional[str]:
         return self._active_user
 
+    def get_all_users(self) -> List[str]:
+        return list(self._tokens)
+
     def get_token(self, user: str) -> Optional[str]:
         token = self._tokens.get(user)
         if token is not None:
             assert isinstance(token, str), "invalid cache; token must be a string"
         return token
 
     def delete_token_cache(self) -> None:
```

## determined/common/api/bindings.py

```diff
@@ -61,14 +61,98 @@
 
 class GetTrialWorkloadsRequestFilterOption(enum.Enum):
     UNSPECIFIED = "FILTER_OPTION_UNSPECIFIED"
     CHECKPOINT = "FILTER_OPTION_CHECKPOINT"
     VALIDATION = "FILTER_OPTION_VALIDATION"
     CHECKPOINT_OR_VALIDATION = "FILTER_OPTION_CHECKPOINT_OR_VALIDATION"
 
+class PatchExperimentPatchCheckpointStorage:
+    saveExperimentBest: "typing.Optional[int]" = None
+    saveTrialBest: "typing.Optional[int]" = None
+    saveTrialLatest: "typing.Optional[int]" = None
+
+    def __init__(
+        self,
+        *,
+        saveExperimentBest: "typing.Union[int, None, Unset]" = _unset,
+        saveTrialBest: "typing.Union[int, None, Unset]" = _unset,
+        saveTrialLatest: "typing.Union[int, None, Unset]" = _unset,
+    ):
+        if not isinstance(saveExperimentBest, Unset):
+            self.saveExperimentBest = saveExperimentBest
+        if not isinstance(saveTrialBest, Unset):
+            self.saveTrialBest = saveTrialBest
+        if not isinstance(saveTrialLatest, Unset):
+            self.saveTrialLatest = saveTrialLatest
+
+    @classmethod
+    def from_json(cls, obj: Json) -> "PatchExperimentPatchCheckpointStorage":
+        kwargs: "typing.Dict[str, typing.Any]" = {
+        }
+        if "saveExperimentBest" in obj:
+            kwargs["saveExperimentBest"] = obj["saveExperimentBest"]
+        if "saveTrialBest" in obj:
+            kwargs["saveTrialBest"] = obj["saveTrialBest"]
+        if "saveTrialLatest" in obj:
+            kwargs["saveTrialLatest"] = obj["saveTrialLatest"]
+        return cls(**kwargs)
+
+    def to_json(self, omit_unset: bool = False) -> typing.Dict[str, typing.Any]:
+        out: "typing.Dict[str, typing.Any]" = {
+        }
+        if not omit_unset or "saveExperimentBest" in vars(self):
+            out["saveExperimentBest"] = self.saveExperimentBest
+        if not omit_unset or "saveTrialBest" in vars(self):
+            out["saveTrialBest"] = self.saveTrialBest
+        if not omit_unset or "saveTrialLatest" in vars(self):
+            out["saveTrialLatest"] = self.saveTrialLatest
+        return out
+
+class PatchExperimentPatchResources:
+    maxSlots: "typing.Optional[int]" = None
+    priority: "typing.Optional[int]" = None
+    weight: "typing.Optional[float]" = None
+
+    def __init__(
+        self,
+        *,
+        maxSlots: "typing.Union[int, None, Unset]" = _unset,
+        priority: "typing.Union[int, None, Unset]" = _unset,
+        weight: "typing.Union[float, None, Unset]" = _unset,
+    ):
+        if not isinstance(maxSlots, Unset):
+            self.maxSlots = maxSlots
+        if not isinstance(priority, Unset):
+            self.priority = priority
+        if not isinstance(weight, Unset):
+            self.weight = weight
+
+    @classmethod
+    def from_json(cls, obj: Json) -> "PatchExperimentPatchResources":
+        kwargs: "typing.Dict[str, typing.Any]" = {
+        }
+        if "maxSlots" in obj:
+            kwargs["maxSlots"] = obj["maxSlots"]
+        if "priority" in obj:
+            kwargs["priority"] = obj["priority"]
+        if "weight" in obj:
+            kwargs["weight"] = float(obj["weight"]) if obj["weight"] is not None else None
+        return cls(**kwargs)
+
+    def to_json(self, omit_unset: bool = False) -> typing.Dict[str, typing.Any]:
+        out: "typing.Dict[str, typing.Any]" = {
+        }
+        if not omit_unset or "maxSlots" in vars(self):
+            out["maxSlots"] = self.maxSlots
+        if not omit_unset or "priority" in vars(self):
+            out["priority"] = self.priority
+        if not omit_unset or "weight" in vars(self):
+            out["weight"] = None if self.weight is None else dump_float(self.weight)
+        return out
+
 class ResourcesSummaryDevices:
     devices: "typing.Optional[typing.Sequence[v1Device]]" = None
 
     def __init__(
         self,
         *,
         devices: "typing.Union[typing.Sequence[v1Device], None, Unset]" = _unset,
@@ -1418,35 +1502,39 @@
             "value": self.value,
         }
         return out
 
 class v1BulkExperimentFilters:
     archived: "typing.Optional[bool]" = None
     description: "typing.Optional[str]" = None
+    excludedExperimentIds: "typing.Optional[typing.Sequence[int]]" = None
     labels: "typing.Optional[typing.Sequence[str]]" = None
     name: "typing.Optional[str]" = None
     projectId: "typing.Optional[int]" = None
     states: "typing.Optional[typing.Sequence[experimentv1State]]" = None
     userIds: "typing.Optional[typing.Sequence[int]]" = None
 
     def __init__(
         self,
         *,
         archived: "typing.Union[bool, None, Unset]" = _unset,
         description: "typing.Union[str, None, Unset]" = _unset,
+        excludedExperimentIds: "typing.Union[typing.Sequence[int], None, Unset]" = _unset,
         labels: "typing.Union[typing.Sequence[str], None, Unset]" = _unset,
         name: "typing.Union[str, None, Unset]" = _unset,
         projectId: "typing.Union[int, None, Unset]" = _unset,
         states: "typing.Union[typing.Sequence[experimentv1State], None, Unset]" = _unset,
         userIds: "typing.Union[typing.Sequence[int], None, Unset]" = _unset,
     ):
         if not isinstance(archived, Unset):
             self.archived = archived
         if not isinstance(description, Unset):
             self.description = description
+        if not isinstance(excludedExperimentIds, Unset):
+            self.excludedExperimentIds = excludedExperimentIds
         if not isinstance(labels, Unset):
             self.labels = labels
         if not isinstance(name, Unset):
             self.name = name
         if not isinstance(projectId, Unset):
             self.projectId = projectId
         if not isinstance(states, Unset):
@@ -1458,14 +1546,16 @@
     def from_json(cls, obj: Json) -> "v1BulkExperimentFilters":
         kwargs: "typing.Dict[str, typing.Any]" = {
         }
         if "archived" in obj:
             kwargs["archived"] = obj["archived"]
         if "description" in obj:
             kwargs["description"] = obj["description"]
+        if "excludedExperimentIds" in obj:
+            kwargs["excludedExperimentIds"] = obj["excludedExperimentIds"]
         if "labels" in obj:
             kwargs["labels"] = obj["labels"]
         if "name" in obj:
             kwargs["name"] = obj["name"]
         if "projectId" in obj:
             kwargs["projectId"] = obj["projectId"]
         if "states" in obj:
@@ -1477,14 +1567,16 @@
     def to_json(self, omit_unset: bool = False) -> typing.Dict[str, typing.Any]:
         out: "typing.Dict[str, typing.Any]" = {
         }
         if not omit_unset or "archived" in vars(self):
             out["archived"] = self.archived
         if not omit_unset or "description" in vars(self):
             out["description"] = self.description
+        if not omit_unset or "excludedExperimentIds" in vars(self):
+            out["excludedExperimentIds"] = self.excludedExperimentIds
         if not omit_unset or "labels" in vars(self):
             out["labels"] = self.labels
         if not omit_unset or "name" in vars(self):
             out["name"] = self.name
         if not omit_unset or "projectId" in vars(self):
             out["projectId"] = self.projectId
         if not omit_unset or "states" in vars(self):
@@ -2785,14 +2877,56 @@
             out["slot"] = None if self.slot is None else self.slot.to_json(omit_unset)
         return out
 
 class v1EntityType(enum.Enum):
     UNSPECIFIED = "ENTITY_TYPE_UNSPECIFIED"
     PROJECT = "ENTITY_TYPE_PROJECT"
 
+class v1ExpMetricNamesResponse:
+    searcherMetrics: "typing.Optional[typing.Sequence[str]]" = None
+    trainingMetrics: "typing.Optional[typing.Sequence[str]]" = None
+    validationMetrics: "typing.Optional[typing.Sequence[str]]" = None
+
+    def __init__(
+        self,
+        *,
+        searcherMetrics: "typing.Union[typing.Sequence[str], None, Unset]" = _unset,
+        trainingMetrics: "typing.Union[typing.Sequence[str], None, Unset]" = _unset,
+        validationMetrics: "typing.Union[typing.Sequence[str], None, Unset]" = _unset,
+    ):
+        if not isinstance(searcherMetrics, Unset):
+            self.searcherMetrics = searcherMetrics
+        if not isinstance(trainingMetrics, Unset):
+            self.trainingMetrics = trainingMetrics
+        if not isinstance(validationMetrics, Unset):
+            self.validationMetrics = validationMetrics
+
+    @classmethod
+    def from_json(cls, obj: Json) -> "v1ExpMetricNamesResponse":
+        kwargs: "typing.Dict[str, typing.Any]" = {
+        }
+        if "searcherMetrics" in obj:
+            kwargs["searcherMetrics"] = obj["searcherMetrics"]
+        if "trainingMetrics" in obj:
+            kwargs["trainingMetrics"] = obj["trainingMetrics"]
+        if "validationMetrics" in obj:
+            kwargs["validationMetrics"] = obj["validationMetrics"]
+        return cls(**kwargs)
+
+    def to_json(self, omit_unset: bool = False) -> typing.Dict[str, typing.Any]:
+        out: "typing.Dict[str, typing.Any]" = {
+        }
+        if not omit_unset or "searcherMetrics" in vars(self):
+            out["searcherMetrics"] = self.searcherMetrics
+        if not omit_unset or "trainingMetrics" in vars(self):
+            out["trainingMetrics"] = self.trainingMetrics
+        if not omit_unset or "validationMetrics" in vars(self):
+            out["validationMetrics"] = self.validationMetrics
+        return out
+
 class v1Experiment:
     bestTrialId: "typing.Optional[int]" = None
     bestTrialSearcherMetric: "typing.Optional[float]" = None
     checkpointCount: "typing.Optional[int]" = None
     checkpointSize: "typing.Optional[str]" = None
     description: "typing.Optional[str]" = None
     displayName: "typing.Optional[str]" = None
@@ -6482,56 +6616,14 @@
     def to_json(self, omit_unset: bool = False) -> typing.Dict[str, typing.Any]:
         out: "typing.Dict[str, typing.Any]" = {
         }
         if not omit_unset or "batches" in vars(self):
             out["batches"] = self.batches
         return out
 
-class v1MetricNamesResponse:
-    searcherMetric: "typing.Optional[str]" = None
-    trainingMetrics: "typing.Optional[typing.Sequence[str]]" = None
-    validationMetrics: "typing.Optional[typing.Sequence[str]]" = None
-
-    def __init__(
-        self,
-        *,
-        searcherMetric: "typing.Union[str, None, Unset]" = _unset,
-        trainingMetrics: "typing.Union[typing.Sequence[str], None, Unset]" = _unset,
-        validationMetrics: "typing.Union[typing.Sequence[str], None, Unset]" = _unset,
-    ):
-        if not isinstance(searcherMetric, Unset):
-            self.searcherMetric = searcherMetric
-        if not isinstance(trainingMetrics, Unset):
-            self.trainingMetrics = trainingMetrics
-        if not isinstance(validationMetrics, Unset):
-            self.validationMetrics = validationMetrics
-
-    @classmethod
-    def from_json(cls, obj: Json) -> "v1MetricNamesResponse":
-        kwargs: "typing.Dict[str, typing.Any]" = {
-        }
-        if "searcherMetric" in obj:
-            kwargs["searcherMetric"] = obj["searcherMetric"]
-        if "trainingMetrics" in obj:
-            kwargs["trainingMetrics"] = obj["trainingMetrics"]
-        if "validationMetrics" in obj:
-            kwargs["validationMetrics"] = obj["validationMetrics"]
-        return cls(**kwargs)
-
-    def to_json(self, omit_unset: bool = False) -> typing.Dict[str, typing.Any]:
-        out: "typing.Dict[str, typing.Any]" = {
-        }
-        if not omit_unset or "searcherMetric" in vars(self):
-            out["searcherMetric"] = self.searcherMetric
-        if not omit_unset or "trainingMetrics" in vars(self):
-            out["trainingMetrics"] = self.trainingMetrics
-        if not omit_unset or "validationMetrics" in vars(self):
-            out["validationMetrics"] = self.validationMetrics
-        return out
-
 class v1MetricType(enum.Enum):
     UNSPECIFIED = "METRIC_TYPE_UNSPECIFIED"
     TRAINING = "METRIC_TYPE_TRAINING"
     VALIDATION = "METRIC_TYPE_VALIDATION"
 
 class v1Metrics:
     batchMetrics: "typing.Optional[typing.Sequence[typing.Dict[str, typing.Any]]]" = None
@@ -7217,65 +7309,81 @@
         if not omit_unset or "startIndex" in vars(self):
             out["startIndex"] = self.startIndex
         if not omit_unset or "total" in vars(self):
             out["total"] = self.total
         return out
 
 class v1PatchExperiment:
+    checkpointStorage: "typing.Optional[PatchExperimentPatchCheckpointStorage]" = None
     description: "typing.Optional[str]" = None
     labels: "typing.Optional[typing.Sequence[str]]" = None
     name: "typing.Optional[str]" = None
     notes: "typing.Optional[str]" = None
+    resources: "typing.Optional[PatchExperimentPatchResources]" = None
 
     def __init__(
         self,
         *,
         id: int,
+        checkpointStorage: "typing.Union[PatchExperimentPatchCheckpointStorage, None, Unset]" = _unset,
         description: "typing.Union[str, None, Unset]" = _unset,
         labels: "typing.Union[typing.Sequence[str], None, Unset]" = _unset,
         name: "typing.Union[str, None, Unset]" = _unset,
         notes: "typing.Union[str, None, Unset]" = _unset,
+        resources: "typing.Union[PatchExperimentPatchResources, None, Unset]" = _unset,
     ):
         self.id = id
+        if not isinstance(checkpointStorage, Unset):
+            self.checkpointStorage = checkpointStorage
         if not isinstance(description, Unset):
             self.description = description
         if not isinstance(labels, Unset):
             self.labels = labels
         if not isinstance(name, Unset):
             self.name = name
         if not isinstance(notes, Unset):
             self.notes = notes
+        if not isinstance(resources, Unset):
+            self.resources = resources
 
     @classmethod
     def from_json(cls, obj: Json) -> "v1PatchExperiment":
         kwargs: "typing.Dict[str, typing.Any]" = {
             "id": obj["id"],
         }
+        if "checkpointStorage" in obj:
+            kwargs["checkpointStorage"] = PatchExperimentPatchCheckpointStorage.from_json(obj["checkpointStorage"]) if obj["checkpointStorage"] is not None else None
         if "description" in obj:
             kwargs["description"] = obj["description"]
         if "labels" in obj:
             kwargs["labels"] = obj["labels"]
         if "name" in obj:
             kwargs["name"] = obj["name"]
         if "notes" in obj:
             kwargs["notes"] = obj["notes"]
+        if "resources" in obj:
+            kwargs["resources"] = PatchExperimentPatchResources.from_json(obj["resources"]) if obj["resources"] is not None else None
         return cls(**kwargs)
 
     def to_json(self, omit_unset: bool = False) -> typing.Dict[str, typing.Any]:
         out: "typing.Dict[str, typing.Any]" = {
             "id": self.id,
         }
+        if not omit_unset or "checkpointStorage" in vars(self):
+            out["checkpointStorage"] = None if self.checkpointStorage is None else self.checkpointStorage.to_json(omit_unset)
         if not omit_unset or "description" in vars(self):
             out["description"] = self.description
         if not omit_unset or "labels" in vars(self):
             out["labels"] = self.labels
         if not omit_unset or "name" in vars(self):
             out["name"] = self.name
         if not omit_unset or "notes" in vars(self):
             out["notes"] = self.notes
+        if not omit_unset or "resources" in vars(self):
+            out["resources"] = None if self.resources is None else self.resources.to_json(omit_unset)
         return out
 
 class v1PatchExperimentResponse:
     experiment: "typing.Optional[v1Experiment]" = None
 
     def __init__(
         self,
@@ -7536,14 +7644,36 @@
 
     def to_json(self, omit_unset: bool = False) -> typing.Dict[str, typing.Any]:
         out: "typing.Dict[str, typing.Any]" = {
             "project": self.project.to_json(omit_unset),
         }
         return out
 
+class v1PatchTemplateConfigResponse:
+
+    def __init__(
+        self,
+        *,
+        template: "v1Template",
+    ):
+        self.template = template
+
+    @classmethod
+    def from_json(cls, obj: Json) -> "v1PatchTemplateConfigResponse":
+        kwargs: "typing.Dict[str, typing.Any]" = {
+            "template": v1Template.from_json(obj["template"]),
+        }
+        return cls(**kwargs)
+
+    def to_json(self, omit_unset: bool = False) -> typing.Dict[str, typing.Any]:
+        out: "typing.Dict[str, typing.Any]" = {
+            "template": self.template.to_json(omit_unset),
+        }
+        return out
+
 class v1PatchTrialsCollectionRequest:
     filters: "typing.Optional[v1TrialFilters]" = None
     name: "typing.Optional[str]" = None
     sorter: "typing.Optional[v1TrialSorter]" = None
 
     def __init__(
         self,
@@ -8314,14 +8444,36 @@
             out["experimentId"] = self.experimentId
         if not omit_unset or "searcherOperations" in vars(self):
             out["searcherOperations"] = None if self.searcherOperations is None else [x.to_json(omit_unset) for x in self.searcherOperations]
         if not omit_unset or "triggeredByEvent" in vars(self):
             out["triggeredByEvent"] = None if self.triggeredByEvent is None else self.triggeredByEvent.to_json(omit_unset)
         return out
 
+class v1PostTemplateResponse:
+
+    def __init__(
+        self,
+        *,
+        template: "v1Template",
+    ):
+        self.template = template
+
+    @classmethod
+    def from_json(cls, obj: Json) -> "v1PostTemplateResponse":
+        kwargs: "typing.Dict[str, typing.Any]" = {
+            "template": v1Template.from_json(obj["template"]),
+        }
+        return cls(**kwargs)
+
+    def to_json(self, omit_unset: bool = False) -> typing.Dict[str, typing.Any]:
+        out: "typing.Dict[str, typing.Any]" = {
+            "template": self.template.to_json(omit_unset),
+        }
+        return out
+
 class v1PostTrialProfilerMetricsBatchRequest:
     batches: "typing.Optional[typing.Sequence[v1TrialProfilerMetricsBatch]]" = None
 
     def __init__(
         self,
         *,
         batches: "typing.Union[typing.Sequence[v1TrialProfilerMetricsBatch], None, Unset]" = _unset,
@@ -10213,44 +10365,40 @@
             out["cluster"] = self.cluster
         if not omit_unset or "workspace" in vars(self):
             out["workspace"] = self.workspace
         return out
 
 class v1SearchExperimentExperiment:
     bestTrial: "typing.Optional[trialv1Trial]" = None
-    experiment: "typing.Optional[v1Experiment]" = None
 
     def __init__(
         self,
         *,
+        experiment: "v1Experiment",
         bestTrial: "typing.Union[trialv1Trial, None, Unset]" = _unset,
-        experiment: "typing.Union[v1Experiment, None, Unset]" = _unset,
     ):
+        self.experiment = experiment
         if not isinstance(bestTrial, Unset):
             self.bestTrial = bestTrial
-        if not isinstance(experiment, Unset):
-            self.experiment = experiment
 
     @classmethod
     def from_json(cls, obj: Json) -> "v1SearchExperimentExperiment":
         kwargs: "typing.Dict[str, typing.Any]" = {
+            "experiment": v1Experiment.from_json(obj["experiment"]),
         }
         if "bestTrial" in obj:
             kwargs["bestTrial"] = trialv1Trial.from_json(obj["bestTrial"]) if obj["bestTrial"] is not None else None
-        if "experiment" in obj:
-            kwargs["experiment"] = v1Experiment.from_json(obj["experiment"]) if obj["experiment"] is not None else None
         return cls(**kwargs)
 
     def to_json(self, omit_unset: bool = False) -> typing.Dict[str, typing.Any]:
         out: "typing.Dict[str, typing.Any]" = {
+            "experiment": self.experiment.to_json(omit_unset),
         }
         if not omit_unset or "bestTrial" in vars(self):
             out["bestTrial"] = None if self.bestTrial is None else self.bestTrial.to_json(omit_unset)
-        if not omit_unset or "experiment" in vars(self):
-            out["experiment"] = None if self.experiment is None else self.experiment.to_json(omit_unset)
         return out
 
 class v1SearchExperimentsResponse:
 
     def __init__(
         self,
         *,
@@ -11208,30 +11356,34 @@
 class v1Template:
 
     def __init__(
         self,
         *,
         config: "typing.Dict[str, typing.Any]",
         name: str,
+        workspaceId: int,
     ):
         self.config = config
         self.name = name
+        self.workspaceId = workspaceId
 
     @classmethod
     def from_json(cls, obj: Json) -> "v1Template":
         kwargs: "typing.Dict[str, typing.Any]" = {
             "config": obj["config"],
             "name": obj["name"],
+            "workspaceId": obj["workspaceId"],
         }
         return cls(**kwargs)
 
     def to_json(self, omit_unset: bool = False) -> typing.Dict[str, typing.Any]:
         out: "typing.Dict[str, typing.Any]" = {
             "config": self.config,
             "name": self.name,
+            "workspaceId": self.workspaceId,
         }
         return out
 
 class v1Tensorboard:
     container: "typing.Optional[v1Container]" = None
     displayName: "typing.Optional[str]" = None
     exitStatus: "typing.Optional[str]" = None
@@ -13784,14 +13936,49 @@
         timeout=None,
         stream=False,
     )
     if _resp.status_code == 200:
         return v1EnableSlotResponse.from_json(_resp.json())
     raise APIHttpError("post_EnableSlot", _resp)
 
+def get_ExpMetricNames(
+    session: "api.Session",
+    *,
+    ids: "typing.Optional[typing.Sequence[int]]" = None,
+    periodSeconds: "typing.Optional[int]" = None,
+) -> "typing.Iterable[v1ExpMetricNamesResponse]":
+    _params = {
+        "ids": ids,
+        "periodSeconds": periodSeconds,
+    }
+    _resp = session._do_request(
+        method="GET",
+        path="/api/v1/experiments/metrics-stream/metric-names",
+        params=_params,
+        json=None,
+        data=None,
+        headers=None,
+        timeout=None,
+        stream=True,
+    )
+    if _resp.status_code == 200:
+        try:
+            for _line in _resp.iter_lines(chunk_size=1024 * 1024):
+                _j = json.loads(_line)
+                if "error" in _j:
+                    raise APIHttpStreamError(
+                        "get_ExpMetricNames",
+                        runtimeStreamError.from_json(_j["error"])
+                )
+                yield v1ExpMetricNamesResponse.from_json(_j["result"])
+        except requests.exceptions.ChunkedEncodingError:
+            raise APIHttpStreamError("get_ExpMetricNames", runtimeStreamError(message="ChunkedEncodingError"))
+        return
+    raise APIHttpError("get_ExpMetricNames", _resp)
+
 def get_GetActiveTasksCount(
     session: "api.Session",
 ) -> "v1GetActiveTasksCountResponse":
     _params = None
     _resp = session._do_request(
         method="GET",
         path="/api/v1/tasks/count",
@@ -15856,48 +16043,14 @@
                 )
                 yield v1MetricBatchesResponse.from_json(_j["result"])
         except requests.exceptions.ChunkedEncodingError:
             raise APIHttpStreamError("get_MetricBatches", runtimeStreamError(message="ChunkedEncodingError"))
         return
     raise APIHttpError("get_MetricBatches", _resp)
 
-def get_MetricNames(
-    session: "api.Session",
-    *,
-    experimentId: int,
-    periodSeconds: "typing.Optional[int]" = None,
-) -> "typing.Iterable[v1MetricNamesResponse]":
-    _params = {
-        "periodSeconds": periodSeconds,
-    }
-    _resp = session._do_request(
-        method="GET",
-        path=f"/api/v1/experiments/{experimentId}/metrics-stream/metric-names",
-        params=_params,
-        json=None,
-        data=None,
-        headers=None,
-        timeout=None,
-        stream=True,
-    )
-    if _resp.status_code == 200:
-        try:
-            for _line in _resp.iter_lines(chunk_size=1024 * 1024):
-                _j = json.loads(_line)
-                if "error" in _j:
-                    raise APIHttpStreamError(
-                        "get_MetricNames",
-                        runtimeStreamError.from_json(_j["error"])
-                )
-                yield v1MetricNamesResponse.from_json(_j["result"])
-        except requests.exceptions.ChunkedEncodingError:
-            raise APIHttpStreamError("get_MetricNames", runtimeStreamError(message="ChunkedEncodingError"))
-        return
-    raise APIHttpError("get_MetricNames", _resp)
-
 def post_MoveExperiment(
     session: "api.Session",
     *,
     body: "v1MoveExperimentRequest",
     experimentId: int,
 ) -> None:
     _params = None
@@ -16079,14 +16232,35 @@
         timeout=None,
         stream=False,
     )
     if _resp.status_code == 200:
         return v1PatchProjectResponse.from_json(_resp.json())
     raise APIHttpError("patch_PatchProject", _resp)
 
+def patch_PatchTemplateConfig(
+    session: "api.Session",
+    *,
+    body: "typing.Dict[str, typing.Any]",
+    templateName: str,
+) -> "v1PatchTemplateConfigResponse":
+    _params = None
+    _resp = session._do_request(
+        method="PATCH",
+        path=f"/api/v1/templates/{templateName}",
+        params=_params,
+        json=body,
+        data=None,
+        headers=None,
+        timeout=None,
+        stream=False,
+    )
+    if _resp.status_code == 200:
+        return v1PatchTemplateConfigResponse.from_json(_resp.json())
+    raise APIHttpError("patch_PatchTemplateConfig", _resp)
+
 def patch_PatchTrialsCollection(
     session: "api.Session",
     *,
     body: "v1PatchTrialsCollectionRequest",
 ) -> "v1PatchTrialsCollectionResponse":
     _params = None
     _resp = session._do_request(
@@ -16326,14 +16500,35 @@
         timeout=None,
         stream=False,
     )
     if _resp.status_code == 200:
         return
     raise APIHttpError("post_PostSearcherOperations", _resp)
 
+def post_PostTemplate(
+    session: "api.Session",
+    *,
+    body: "v1Template",
+    template_name: str,
+) -> "v1PostTemplateResponse":
+    _params = None
+    _resp = session._do_request(
+        method="POST",
+        path=f"/api/v1/templates/{template_name}",
+        params=_params,
+        json=body.to_json(True),
+        data=None,
+        headers=None,
+        timeout=None,
+        stream=False,
+    )
+    if _resp.status_code == 200:
+        return v1PostTemplateResponse.from_json(_resp.json())
+    raise APIHttpError("post_PostTemplate", _resp)
+
 def post_PostTrialProfilerMetricsBatch(
     session: "api.Session",
     *,
     body: "v1PostTrialProfilerMetricsBatchRequest",
 ) -> None:
     _params = None
     _resp = session._do_request(
@@ -16744,20 +16939,22 @@
     if _resp.status_code == 200:
         return v1ResourceAllocationRawResponse.from_json(_resp.json())
     raise APIHttpError("get_ResourceAllocationRaw", _resp)
 
 def get_SearchExperiments(
     session: "api.Session",
     *,
+    filter: "typing.Optional[str]" = None,
     limit: "typing.Optional[int]" = None,
     offset: "typing.Optional[int]" = None,
     projectId: "typing.Optional[int]" = None,
     sort: "typing.Optional[str]" = None,
 ) -> "v1SearchExperimentsResponse":
     _params = {
+        "filter": filter,
         "limit": limit,
         "offset": offset,
         "projectId": projectId,
         "sort": sort,
     }
     _resp = session._do_request(
         method="GET",
```

## determined/common/api/request.py

```diff
@@ -47,16 +47,16 @@
     service_address: str,
     description: str,
     resource_pool: str,
     task_type: str,
     currentSlotsExceeded: bool,
 ) -> str:
     wait_path = (
-        "/notebooks/{}/events".format(task_id)
-        if task_type == "notebook"
+        "/jupyter-lab/{}/events".format(task_id)
+        if task_type == "jupyter-lab"
         else "/tensorboard/{}/events?tail=1".format(task_id)
     )
     wait_path_url = service_address + wait_path
     public_url = os.environ.get("PUBLIC_URL", "/det")
     wait_page_url = "{}/wait/{}/{}?eventUrl={}&serviceAddr={}".format(
         public_url, task_type, task_id, wait_path_url, service_address
     )
```

## determined/core/_checkpoint.py

```diff
@@ -469,14 +469,20 @@
         self, metadata: Optional[Dict[str, Any]] = None, *, shard: bool = False
     ) -> Iterator[Tuple[pathlib.Path, str]]:
         """
         ``store_path()`` is a context manager which chooses a random path and prepares a directory
         you should save your model to.  When the context manager exits, the model is automatically
         uploaded (at least, for cloud-backed checkpoint storage backends).
 
+        .. note::
+            metadata must include a 'steps_completed' key in the current implementation.
+            Raises ValueError if the 'steps_completed' key is not present in the metadata
+            dictionary.
+
+
         When ``shard=False``, only the chief worker (``distributed.rank==0``) may call
         ``store_path()``.
 
         When ``shard=True``, ``store_path()`` becomes a synchronization point between workers, so
         all workers must call store_path(), even workers which will not write any checkpoint files.
 
         Example:
```

## determined/deploy/cli.py

```diff
@@ -1,18 +1,16 @@
-from typing import List, Union
-
 from determined.cli.top_arg_descriptions import deploy_cmd
-from determined.common.declarative_argparse import Arg, Cmd
+from determined.common.declarative_argparse import Arg, ArgsDescription
 
 from .aws.cli import args_description as aws_args_description
 from .gcp.cli import args_description as gcp_args_description
 from .gke.cli import args_description as gke_args_description
 from .local.cli import args_description as local_args_description
 
-args_subs: List[Union[Arg, Cmd]] = [
+args_subs: ArgsDescription = [
     Arg("--no-preflight-checks", action="store_true", help="Disable preflight checks"),
     Arg(
         "--no-wait-for-master",
         action="store_true",
         help="Do not wait for master to come up after AWS or GCP clusters are deployed",
     ),
     Arg(
```

## determined/deploy/aws/aws.py

```diff
@@ -1,10 +1,11 @@
 import sys
+import threading
 import time
-from typing import Any, Dict, List, Optional, Tuple
+from typing import Any, Callable, Dict, List, Optional, Tuple
 
 import boto3
 import tqdm
 from botocore.exceptions import ClientError, WaiterError
 
 from determined.deploy.aws import constants
 
@@ -18,14 +19,31 @@
 )
 
 
 class NoStackOutputError(Exception):
     pass
 
 
+def run_with_periodic_output(f: Callable[[], Any], output: str) -> None:
+    done = threading.Event()
+
+    def print_something() -> None:
+        while not done.wait(60):
+            print(output)
+
+    print_thread = threading.Thread(target=print_something, daemon=True)
+    print_thread.start()
+
+    try:
+        f()
+    finally:
+        done.set()
+        print_thread.join()
+
+
 def get_user(boto3_session: boto3.session.Session) -> str:
     sts = boto3_session.client("sts")
     response = sts.get_caller_identity()
     arn = response["Arn"]
     assert isinstance(arn, str), f"expected a string Arn but got {arn}"
     return arn.split("/")[-1]
 
@@ -146,15 +164,19 @@
             f"True - Deleting stack {stack_name}. This may take a few minutes... "
             f"Check the CloudFormation Console for updates"
         )
 
     else:
         print(f"False. {stack_name} does not exist")
     cfn.delete_stack(StackName=stack_name)
-    delete_waiter.wait(StackName=stack_name, WaiterConfig={"Delay": 10})
+
+    run_with_periodic_output(
+        lambda: delete_waiter.wait(StackName=stack_name, WaiterConfig={"Delay": 10}),
+        "Still waiting for stack...",
+    )
 
 
 def update_stack(
     stack_name: str,
     template_body: str,
     boto3_session: boto3.session.Session,
     deployment_type: str,
@@ -258,15 +280,18 @@
         StackName=stack_name,
         TemplateBody=template_body,
         Parameters=parameters,
         Capabilities=["CAPABILITY_IAM"],
         Tags=tags,
     )
 
-    create_waiter.wait(StackName=stack_name, WaiterConfig={"Delay": 10})
+    run_with_periodic_output(
+        lambda: create_waiter.wait(StackName=stack_name, WaiterConfig={"Delay": 10}),
+        "Still waiting for stack...",
+    )
 
 
 def list_stacks(boto3_session: boto3.session.Session) -> List[Dict[str, Any]]:
     cfn = boto3_session.client("cloudformation")
     response = cfn.describe_stacks()
 
     output = []
```

## determined/deploy/aws/templates/efs.yaml

```diff
@@ -97,15 +97,15 @@
     Type: String
     Description: Docker password to pull images that need authentication
     Default: ""
 
   Version:
     Type: String
     Description: Determined version or commit for master image
-    Default: 0.22.1-rc1
+    Default: 0.22.2-rc0
 
   DBPassword:
     Type: String
     Description: Password for database
     NoEcho: true
 
   MaxAuxContainersPerAgent:
```

## determined/deploy/aws/templates/fsx.yaml

```diff
@@ -97,15 +97,15 @@
     Type: String
     Description: Docker password to pull images that need authentication
     Default: ""
 
   Version:
     Type: String
     Description: Determined version or commit for master image
-    Default: 0.22.1-rc1
+    Default: 0.22.2-rc0
 
   DBPassword:
     Type: String
     Description: Password for database
     NoEcho: true
 
   MaxAuxContainersPerAgent:
```

## determined/deploy/aws/templates/govcloud.yaml

```diff
@@ -63,15 +63,15 @@
     Type: String
     Description: Docker password to pull images that need authentication
     Default: ""
 
   Version:
     Type: String
     Description: Determined version or commit for master docker image
-    Default: 0.22.1-rc1
+    Default: 0.22.2-rc0
 
   DBPassword:
     Type: String
     Description: Password for database (eg. "postgres")
     NoEcho: true
 
   MaxAuxContainersPerAgent:
```

## determined/deploy/aws/templates/secure.yaml

```diff
@@ -118,15 +118,15 @@
     Type: String
     Description: Docker password to pull images that need authentication
     Default: ""
 
   Version:
     Type: String
     Description: Determined version or commit for master image
-    Default: 0.22.1-rc1
+    Default: 0.22.2-rc0
 
   DBPassword:
     Type: String
     Description: Password for database
     NoEcho: true
 
   MaxAuxContainersPerAgent:
```

## determined/deploy/aws/templates/simple.yaml

```diff
@@ -89,15 +89,15 @@
     Type: String
     Description: Docker password to pull images that need authentication
     Default: ""
 
   Version:
     Type: String
     Description: Determined version or commit for master docker image
-    Default: 0.22.1-rc1
+    Default: 0.22.2-rc0
 
   DBPassword:
     Type: String
     Description: Password for database (eg. "postgres")
     NoEcho: true
 
   MaxAuxContainersPerAgent:
```

## determined/deploy/gcp/terraform/modules/compute/main.tf

```diff
@@ -9,14 +9,15 @@
   machine_type = var.master_instance_type
   zone = var.zone
   tags = [var.tag_master_port, var.tag_allow_internal, var.tag_allow_ssh]
   labels = var.labels
 
   boot_disk {
     initialize_params {
+      size = 200
       image = "ubuntu-os-cloud/ubuntu-2004-lts"
     }
   }
 
   service_account {
     email = var.service_account_email
     scopes = ["https://www.googleapis.com/auth/cloud-platform"]
```

## determined/pytorch/__init__.py

```diff
@@ -28,12 +28,13 @@
 from determined.pytorch._pytorch_context import PyTorchTrialContext
 from determined.pytorch._pytorch_trial import (
     PyTorchTrial,
     _PyTorchTrialController,
     TrainUnit,
     _TrainBoundary,
     _TrainBoundaryType,
+    _TrialState,
     Batch,
     Epoch,
 )
 from determined.pytorch._load import CheckpointLoadContext, load_trial_from_checkpoint_path
 from determined.pytorch._trainer import init, Trainer
```

## determined/pytorch/_pytorch_trial.py

```diff
@@ -217,15 +217,16 @@
         # Training loop state
         if local_training:
             self.trial_id = 0
             assert self.max_length, "max_length must be specified for local-training mode."
         else:
             self.trial_id = self.core_context.train._trial_id
 
-        self.state = _TrialState(trial_id=self.trial_id)
+        # Don't initialize the state here because it will be invalid until we load a checkpoint.
+        self.state = None  # type: Optional[_TrialState]
         self.start_from_batch = steps_completed
         self.val_from_previous_run = self.core_context.train._get_last_validation()
         self.step_zero_validation = step_zero_validation
 
         # Training configs
         self.latest_checkpoint = latest_checkpoint
         self.test_mode = test_mode
@@ -329,14 +330,15 @@
         if not self.is_chief:
             return {}
 
         # Only report on the chief worker
         avg_metrics = metrics.get("avg_metrics", {})
         batch_metrics = metrics.get("batch_metrics", [])
 
+        assert self.state
         det.pytorch._log_tb_metrics(
             self.context.get_tensorboard_writer(),
             "train",
             self.state.batches_trained,
             avg_metrics,
             batch_metrics,
         )
@@ -375,14 +377,16 @@
                 f"callbacks.{callback.__class__.__name__}.on_training_epoch_end"
             ):
                 callback.on_training_epoch_end(epoch_idx)
 
     def _checkpoint(self, already_exiting: bool) -> None:
         if self.is_chief:
             self.core_context.train.set_status("checkpointing")
+
+        assert self.state
         self.state.last_ckpt = self.state.batches_trained
 
         try:
             uuid = ""
             if self.is_chief:
                 metadata = {
                     "determined_version": det.__version__,
@@ -422,15 +426,15 @@
     def _evaluate_batch_defined(self) -> bool:
         return util.is_overridden(self.trial.evaluate_batch, PyTorchTrial)
 
     def _evaluate_full_dataset_defined(self) -> bool:
         return util.is_overridden(self.trial.evaluate_full_dataset, PyTorchTrial)
 
     def _set_data_loaders(self) -> None:
-        skip_batches = self.state.batches_trained
+        skip_batches = self.start_from_batch
 
         num_replicas = self.context.distributed.size
         rank = self.context.distributed.rank
 
         train_data = self.trial.build_training_data_loader()
         if isinstance(train_data, pytorch.DataLoader):
             self.training_loader = train_data.get_data_loader(
@@ -483,14 +487,15 @@
                         pytorch._dataset_repro_warning(
                             "build_validation_data_loader", validation_data
                         )
                     )
                 self.validation_loader = validation_data
 
     def _step_batch(self) -> None:
+        assert self.state
         self.state.batches_trained += 1
 
         epoch_len = self.context._epoch_len
         assert epoch_len, "Training dataloader not initialized."
 
         # True epoch-based training is not supported. Epoch end is calculated with batch.
         epoch_idx, batch_in_epoch_idx = divmod(self.state.batches_trained - 1, epoch_len)
@@ -504,32 +509,36 @@
             raise ShouldExit()
         if self.context.get_stop_requested():
             raise ShouldExit()
 
     def _report_searcher_progress(
         self, op: core.SearcherOperation, unit: Optional[core.Unit]
     ) -> None:
+        assert self.state
         if unit == core.Unit.BATCHES:
             op.report_progress(self.state.batches_trained)
         elif unit == core.Unit.RECORDS:
             assert self.global_batch_size, "global_batch_size must be specified for RECORDS"
             op.report_progress(self.global_batch_size * self.state.batches_trained)
         elif unit == core.Unit.EPOCHS:
             op.report_progress(self.state.epochs_trained)
 
     def _checkpoint_is_current(self) -> bool:
+        assert self.state
         # State always persists checkpoint step in batches
         return self.state.last_ckpt == self.state.batches_trained
 
     def _validation_is_current(self) -> bool:
+        assert self.state
         # State persists validation step in batches
         return self.state.last_val == self.state.batches_trained
 
     def _steps_until_complete(self, train_unit: TrainUnit) -> int:
         assert isinstance(train_unit.value, int), "invalid length type"
+        assert self.state
         if isinstance(train_unit, Batch):
             return train_unit.value - self.state.batches_trained
         elif isinstance(train_unit, Epoch):
             return train_unit.value - self.state.epochs_trained
         else:
             raise ValueError(f"Unrecognized train unit {train_unit}")
 
@@ -549,15 +558,15 @@
                 on_trial_shutdown()
 
         with contextlib.ExitStack() as exit_stack:
             for callback in self.callbacks.values():
                 with self.prof.record_timing(
                     f"callbacks.{callback.__class__.__name__}.on_trial_startup"
                 ):
-                    callback.on_trial_startup(self.state.batches_trained, self.latest_checkpoint)
+                    callback.on_trial_startup(self.start_from_batch, self.latest_checkpoint)
                 exit_stack.enter_context(
                     defer(on_shutdown, callback.__class__.__name__, callback.on_trial_shutdown)
                 )
 
             self._set_data_loaders()
 
             # We create the training_iterator (and training enumerator) here rather than in
@@ -583,14 +592,17 @@
             # If a load path is provided load weights and restore the data location.
             if self.latest_checkpoint is not None:
                 logging.info(f"Restoring trial from checkpoint {self.latest_checkpoint}")
                 with self.context._core.checkpoint.restore_path(
                     self.latest_checkpoint
                 ) as load_path:
                     self._load(load_path)
+            else:
+                # If we are not loading, initialize a fresh state.
+                self.state = _TrialState(trial_id=self.trial_id)
 
             if self.context.distributed.size > 1 and self.use_horovod:
                 hvd.broadcast_parameters(self.context._main_model.state_dict(), root_rank=0)
                 for optimizer in self.context.optimizers:
                     hvd.broadcast_optimizer_state(optimizer, root_rank=0)
 
             exit_stack.enter_context(self.prof)
@@ -600,14 +612,15 @@
                 ):
                     callback.on_training_start()
 
             self._run()
 
     def _run(self) -> None:
         ops: Iterator[det.core.SearcherOperation]
+        assert self.state
 
         try:
             if (
                 self.step_zero_validation
                 and self.val_from_previous_run is None
                 and self.state.batches_trained == 0
             ):
@@ -1000,14 +1013,15 @@
                 "validation step end callback."
             )
             metrics = self.context.distributed.broadcast(metrics)
 
         for callback in self.callbacks.values():
             callback.on_validation_end(metrics)
 
+        assert self.state
         self.state.last_val = self.state.batches_trained
 
         # Report metrics.
         if self.is_chief:
             # Skip reporting timings if evaluate_full_dataset() was defined.  This is far less
             # common than evaluate_batch() and we can't know how the user processed their
             # validation data.
@@ -1218,44 +1232,47 @@
             if wlsq_path.exists():
                 with wlsq_path.open("rb") as f:
                     self._load_wlsq_state(pickle.load(f))
 
     def _load_state(self, state: Any) -> None:
         # Load our state from the checkpoint if we are continuing training after a pause or restart.
         # If the trial_id doesn't match our current trial id, we're continuing training a previous
-        # trial and the state in the checkpoint should be discarded.
-
+        # trial and should start from a fresh state.
         if state.get("trial_id") != self.trial_id:
+            self.state = _TrialState(trial_id=self.trial_id)
             return
 
         self.state = _TrialState(**state)
+        assert self.state
 
         # Detect the case where the final validation we made was against this exact checkpoint.  In
         # that case, the master will know about the validation, but it would not appear in the
         # checkpoint state.  If the validation was before the last checkpoint, the checkpoint state
         # is already correct, while any validations after the last checkpoint aren't valid anymore
         # and can be safely ignored.
         if self.state.batches_trained == self.val_from_previous_run:
             self.state.last_val = self.state.batches_trained
 
     def _load_wlsq_state(self, state: Any) -> None:
         if state.get("trial_id") != self.trial_id:
+            self.state = _TrialState(trial_id=self.trial_id)
             return
 
         self.state = _TrialState(
             trial_id=state.get("trial_id"),
             last_ckpt=state.get("last_ckpt"),
             last_val=state.get("last_val"),
             step_id=state.get("step_id"),
             # steps_completed is a legacy field kept to support loading from older checkpoints.
             # checkpoints should only persist batches_trained and epochs_trained
             batches_trained=state.get("steps_completed"),
             epochs_trained=self._get_epoch_idx(state.get("steps_completed")),
         )
 
+        assert self.state
         if self.state.batches_trained == self.val_from_previous_run:
             self.state.last_val = self.state.batches_trained
 
     def _save(self, path: pathlib.Path) -> None:
         path.mkdir(parents=True, exist_ok=True)
 
         util.write_user_code(path, not self.local_training)
@@ -1295,14 +1312,15 @@
             checkpoint["amp_state"] = apex.amp.state_dict()
 
         for callback in self.callbacks.values():
             callback.on_checkpoint_save_start(checkpoint)
 
         torch.save(checkpoint, str(path.joinpath("state_dict.pth")))
 
+        assert self.state
         with path.joinpath("trial_state.pkl").open("wb") as f:
             pickle.dump(vars(self.state), f)
 
         trial_cls = type(self.trial)
         with open(path.joinpath("load_data.json"), "w") as f2:
             try:
                 exp_conf = self.context.get_experiment_config()  # type: Optional[Dict[str, Any]]
```

## Comparing `determined-0.22.1rc1.dist-info/METADATA` & `determined-0.22.2rc0.dist-info/METADATA`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: determined
-Version: 0.22.1rc1
+Version: 0.22.2rc0
 Summary: Determined Deep Learning Training Platform
 Home-page: https://determined.ai/
 Author: Determined AI
 Author-email: hello@determined.ai
 License: Apache License 2.0
 Classifier: License :: OSI Approved :: Apache Software License
 Requires-Python: >=3.6
```

## Comparing `determined-0.22.1rc1.dist-info/RECORD` & `determined-0.22.2rc0.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 determined/__init__.py,sha256=YP_VEqU7NSA2jILM39YzVkXHiEiHElFWAvQMqF8hA0A,1131
-determined/__version__.py,sha256=Zkgakjh89ajlZaixVMNWURCfCDI4LZMfyTG_73y2L98,27
+determined/__version__.py,sha256=k8Z531YiIghK2-4DuYKqHDRf6inkAi_EVqwLdNFvtc4,27
 determined/_env_context.py,sha256=vG1rREr-gp-rVjGUn_5mzKhRxC8qv0RwpNY4rABT_h4,1664
 determined/_execution.py,sha256=sFxJSNK3WnFxVfwCL_O8ZYOKjIvnPVi3pCQYq99Xy5w,8804
 determined/_experiment_config.py,sha256=kkHvFHQzkI3HlckUozKwjfaieWIgeEot9jyPtvQuLjs,2779
 determined/_import.py,sha256=czaz1MQU8w2tfkeD3rIAVDpRyS_7lH0K9Sn-_zm2luQ,4781
 determined/_info.py,sha256=Xm-H3VpeZwYWRPHMmg2Ig1jSeKVU5jekCnuUiqrzrXA,14901
 determined/_tf_rng.py,sha256=Z96_dEFOB2BRWyrthYN1A2FKxGe-fi0XKS_AEupLAnM,1272
 determined/_trial.py,sha256=5GAT_OKfXumm3ykuSRxY8ImTZAUTUBZ9agBVpcMjIEw,1214
@@ -21,62 +21,62 @@
 determined/util.py,sha256=2bQn9GtL1L1Ydc3wfCmlvO2LNbQBoorTuFZEvRmaXEs,15909
 determined/workload.py,sha256=UG-9Dt5vGf3mfz4No77o-XjBAXGc4TmUfE1BIYJMveE,6578
 determined/cli/__init__.py,sha256=bQTdOCnCglaql6QQf6i6bUVBCujBAnfpXZItfXmj-78,476
 determined/cli/__main__.py,sha256=xd-S-mXqQ92a37G50DzPszQZ5y1FYXMcQGR52GnTQVA,75
 determined/cli/_util.py,sha256=JAGG_HGeBRRELnOkE9XmGFe0fQtK3ttoZLi0Bt7Jdyo,3423
 determined/cli/agent.py,sha256=N5N1hJCTODgJZSde3v8pJS2rFYKgqJXz2fpoYw4iDM0,9810
 determined/cli/checkpoint.py,sha256=x6WE71x59AQoDo8zQuwC_-oAgcaKon5HDmzElbZCa3E,6409
-determined/cli/cli.py,sha256=Cld8TP59_-2u_0gt5ez39jW-hQtaadPkKxWTsSANzOI,12433
-determined/cli/command.py,sha256=sC5NDtIPCNFPjXxX6DoK_9xZKv-JhiBYMlaZh83P9Ac,13480
+determined/cli/cli.py,sha256=v92SUkawi0sDUrkG7Auw-wEHst-UIjwuyUPQS8CtbVM,12530
+determined/cli/command.py,sha256=X6J05UVhYEZAU2kkQj3VBa0dLdZud3jbINHTX_etRAY,14081
 determined/cli/dev.py,sha256=ekDh1KhnoNM_LcAYmgcucxiQuGr-W9IneZc2BYBnhMA,2138
 determined/cli/errors.py,sha256=VdmkMdIuW4bmU-kFeiPTu6SSTDzBQHxDsEGoKF7ePWY,739
-determined/cli/experiment.py,sha256=Ird96hhyBPd6sWcPlniNoByd633vjPaHxgv0jzdRRLo,50046
+determined/cli/experiment.py,sha256=_eaOtiGsThhoh8ZcfSdOB9yGN-rLe3QczdbSSkOunXU,50931
 determined/cli/job.py,sha256=cmg2s0lKimkguADkUjwfVhhEjKJNvB897lXjaA543ZE,8291
 determined/cli/master.py,sha256=ddeXOYMoy03AkVWp2MYMEqSlPv8Np_I9thItrBVmoGs,2137
 determined/cli/model.py,sha256=Kw6NGLNhAJYjzj72AMQFwovdcH55lmwQunODdb3ospY,8747
-determined/cli/notebook.py,sha256=Zb1MHgRLiMOaAh6RIcpxyTmfkdSpzQUZJNpDzjyIshY,5635
+determined/cli/notebook.py,sha256=F-8oWkReE7kgRLu2UOt3N_o9ZZmm-s9gFAafzjDZ-FQ,5641
 determined/cli/oauth.py,sha256=dN5gSlQAO1V8WXiULqjBefA9xZXuqqibemaXXgQHTN4,1761
 determined/cli/project.py,sha256=J9zrJ2Hl3CCX4XqWP9a-1QzgfNzIqxPmr3I2kxx5PK4,12190
 determined/cli/proxy.py,sha256=it_szkamnkVje9DI47RKeb5nhFhTpEFBXXFpsxvwGAA,10219
 determined/cli/rbac.py,sha256=jh9wZdHhYwWOiGgteKIDqjG_880AONbyeh1fEHrb5dQ,18787
 determined/cli/remote.py,sha256=4VYwJniNNyzmnNY-5_aVouJ_jGM5ibhdXKryOYQcejQ,3783
 determined/cli/render.py,sha256=iDIOfBX4eLlnmHFETXGDLBrrr30_kBDOpi4TvfiXYFs,4847
-determined/cli/resources.py,sha256=dJuysbZeAVwShM5bdhIeu2PX5GqBXin8VSDL0N11l9M,2386
+determined/cli/resources.py,sha256=31ovXQuf7S9Mpbuf5ueul2fKhBIa1Q3iH3OpMDAqiP4,2372
 determined/cli/shell.py,sha256=lNVpt9smd2ZPKW46_bETXxp7jQpFyvTtn5RiJiFvWqw,9718
-determined/cli/sso.py,sha256=5hGUJq1nlyAbKk6bHV4pPN5ZkW3j3tMezfUy8ql1Lnk,5193
+determined/cli/sso.py,sha256=J1tFaxUn6rlzJH2MGuZ6uIUnRuQGWzT4LyYf_6wJeiQ,5240
 determined/cli/task.py,sha256=BsFOoVG91eHEs44idpH2ac19AZ2z2Xu1wJ7-BwB7diM,6381
-determined/cli/template.py,sha256=FS0dssz1cX0tIsdvynXIntcFyXWGhMUjj8amPmI-_BI,2868
-determined/cli/tensorboard.py,sha256=EwFeSeIKV5183qbwrJFbpkX_Mk6HHkSAM_F4QPgoBkM,6718
+determined/cli/template.py,sha256=A3y5fxN-COzeZdZ5FMuKB_kzRf8nvx837mghlmKwkig,5354
+determined/cli/tensorboard.py,sha256=mcqwAWvUlCOuu3p6OwkJOYMhDCXA4V3NT4FhE-PNQ4s,8240
 determined/cli/top_arg_descriptions.py,sha256=ql_tbzsAmniYKlZ3YQ4bbCNKtDDmkp9Rf8V5dnED3c8,135
-determined/cli/trial.py,sha256=pFVK3MdMKF2Ixh90uOaNvCwQBOhNYKY6mBrgeDpd1no,15095
+determined/cli/trial.py,sha256=33RVMSSViTT6yt_xgxuqVTwj9X9BYqsM7FNB3bYPhY0,15112
 determined/cli/tunnel.py,sha256=zCWKTZ0C060XsA5Dc6-g0mqbV4Ll9PmQW9yA76ub_n8,1448
-determined/cli/user.py,sha256=xhGTSgd2sT1slsC0ZyfV7ENeH8z8xqwT-c97aQBpKs0,6560
+determined/cli/user.py,sha256=wUgkkIQtgqYG4RNXOktenvJtB0rKsbb2cH2985c_MZI,6875
 determined/cli/user_groups.py,sha256=gMWRSCDNoeYIWjuUMUPlKx73buQnmHdxYyb42p0Z_Z8,9754
 determined/cli/version.py,sha256=PaKvNqv3SWlJy8jmX33pqoG5ylVINVPRHNbUgPU3mlA,2557
 determined/cli/workspace.py,sha256=1PFqimxMJuOCBp1047_G8EF_7QTViWcOP3JlUwglqXk,15179
 determined/common/__init__.py,sha256=c9lF3AufKAwXW8_PMl3lbVtBN6yXmPzxI-8IsbS5RTE,352
 determined/common/_logging.py,sha256=q8wQXSRXRv0dAM5QaS8b374juPz2V3txi786PdCgSRM,498
 determined/common/check.py,sha256=7eK_uJj86VR473TCeYUgultitGJGWEGDKXC7PlU_pVM,8593
 determined/common/constants.py,sha256=nlIn6UueZ9-aIsWjDax2KbpDn7nJo6FE-WAzxcLfxvo,2255
 determined/common/context.py,sha256=1P9_iyXKs4fqiWxATpH9Mx17TtmGZ2iWN1cB4nlRl30,8222
-determined/common/declarative_argparse.py,sha256=H440Ipryf1bBKUsdGD8QVEu1c8HF3YGJAc-MBFSpS5U,7359
+determined/common/declarative_argparse.py,sha256=5BbwY5JUATEMsNbGWj0Ph-6e7oQKi9ydaZz_uCfTXZo,8612
 determined/common/requests.py,sha256=M6NYyQDiXxHq0lHc_OcTrnC4cGQYuXT57V8JNSIon14,1662
 determined/common/util.py,sha256=Jnf-40P5Kf8e2hixJ5Qf0kVwVck33eSlDU0pHBm-1zE,6349
 determined/common/api/__init__.py,sha256=rqCSau19J0fSunDQsIfaUUlpFpspQMPV16JXXKoF2zk,778
 determined/common/api/_session.py,sha256=k6j7joLzPUt-nfz99LFswd_FwQiMrWzw_qunBDO3TTI,3383
 determined/common/api/_util.py,sha256=bWa9qzxN2hHmyNfqndVWV8kVXwEG4I5mSCeNn6IMX2I,2840
 determined/common/api/analytics.py,sha256=ijoLQ1XHYty88SBpYjTUM-4793lxFfyLM9rnEE15Ghk,1450
-determined/common/api/authentication.py,sha256=b1mOtuvlS0cp4jwTkJRVcdMUW_fhTs9l3r13Dw_Bn2Y,15676
-determined/common/api/bindings.py,sha256=MB9QWNZOn_giAybI8uDGPgwdTWVLTVLUxqgeZMgrwbw,611974
+determined/common/api/authentication.py,sha256=pLnS6kpaI32RYnesxHyAlBwTEM2MVM2dkR5CWhDAdGw,16070
+determined/common/api/bindings.py,sha256=2nkGgBptjQodbK4VSc_FMlS3S_JwZyuti0tkO4DZjJ4,619513
 determined/common/api/certs.py,sha256=sltCyZYaGRxnS8LtBpDAMgGTBHaDF_9amKn7UID4-nw,7415
 determined/common/api/errors.py,sha256=WBftwTV5A0CW8erUGtMN1wGYIsVoQjK31FlTFxk0hto,2555
 determined/common/api/logs.py,sha256=gavGnESDPo2v7zJsqRuLOohzYlT975d3fmuzu2wrhIc,3235
 determined/common/api/metric.py,sha256=dR6Opp8sZjRsB3fhZkLKYxLrGkiq1se1Pxsf39udtNw,247
 determined/common/api/profiler.py,sha256=pJ2G9oGFfWrWNmqLXxDlcNfak4C_vgAtUkSEM58cbYY,3147
-determined/common/api/request.py,sha256=yxIe56WjCF0XF63aapeguoeMJg6aSGaujKoa1hlTqhU,10411
+determined/common/api/request.py,sha256=Q5w-Slj2Jl8V8gFbL5EPaW8m4AEWI0b2X709ex2BQRs,10416
 determined/common/api/checkpoint/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 determined/common/api/checkpoint/torch_load.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 determined/common/experimental/__init__.py,sha256=6WWT1MwtmYbxfotWstMocQYwbqjmLnTBTNkwra9I_z0,502
 determined/common/experimental/determined.py,sha256=EaauuLUqNTR_yBearZfSXuXoVh8OYi235gLHiIkag-g,15864
 determined/common/experimental/experiment.py,sha256=yKB_Wkgoe_9XKWMg61qnPdCtFWKG-OEzO9WcwntSDl8,11398
 determined/common/experimental/model.py,sha256=6yxsrjQOYv_bTDvi5xw8WNfAv7l4UHgl2bVEJLpRP-k,12639
 determined/common/experimental/oauth2_scim_client.py,sha256=m1wWw4M_QRIyYXc2CC5Mi6aeyaLSIGrAr9wig4bV8qc,306
@@ -92,55 +92,55 @@
 determined/common/storage/boto3_credential_manager.py,sha256=pKb5OabIB53P-Q28Ba-_Vf9LzUgIcgaFhtfBTmDTyqY,4447
 determined/common/storage/cloud.py,sha256=gfv026i7syfE3rVS-1_bFXEGixagKZ7DeopG4l6DNF4,1014
 determined/common/storage/gcs.py,sha256=8-A37OF7pkDViZKWYkO55CI54_eghgEGcto-PAvHfFw,5789
 determined/common/storage/hdfs.py,sha256=LoGxgzXaOHwMv7DXwJndVYq1PRj4eXLLBiYi-ZLrtY0,2070
 determined/common/storage/s3.py,sha256=Q1BEmZJ-rKTnDG_WH8sGuPJ-JFeERH9-HOZ6Ckpc3Xs,6195
 determined/common/storage/shared.py,sha256=NjIAzl09iw4UTkZWUGnFmhBzvzLm946Cu5PqfrbfXAo,7816
 determined/core/__init__.py,sha256=DojWVPUz2esaYHa6Ew1ul4pDG5Kw5tM2jxLGb_HyW68,747
-determined/core/_checkpoint.py,sha256=b7K-BE1_GVRuRkKYVmXSLhW5D1JSljHJIMvX2nWoPDo,29468
+determined/core/_checkpoint.py,sha256=3pd2DP2zH561817wSZxo4v3kW39n7V3_jwpDQ95cImQ,29691
 determined/core/_context.py,sha256=q8EM0DO28q3JlObF8pnn1teD2WZcZFbuk1uzweThiwM,10984
 determined/core/_distributed.py,sha256=ittb2-UpitI0vD4nMTKlYd86aB4A4eX-dhDyOSxjfv4,16194
 determined/core/_preempt.py,sha256=PRSTglEO5Rrf-QDm0HLNvuZYV2XDZGwifSGHMj6eVqQ,12738
 determined/core/_searcher.py,sha256=3xHycD5l1UPALTgukcUckjUVGtIo5me5EzY7XEPIAPk,15041
 determined/core/_tensorboard_mode.py,sha256=9A9FKYB77F26wkDTe4LNJWKBn9_4Th3cFzCMWjkl7Lc,932
 determined/core/_train.py,sha256=vfXmBAYCplIKiqRfgarfxnmQxcmseE8dlZSmoPrGYHg,10462
 determined/deploy/__init__.py,sha256=ws1TqRk5eBmOWyQ2zS5wL7-_-QU4pbC4ZJBapG7OvR4,40
-determined/deploy/cli.py,sha256=CR6S8nnR47O0p6wPfzvI0RvqApFo9g69swELLc_7bCk,1057
+determined/deploy/cli.py,sha256=52jC9NDzNg0dl-voz_fClyW2Ac5kFW95Od50_MVb-2g,1031
 determined/deploy/errors.py,sha256=6PPO8hrAczDcv3pklrGJRG-8bE1ydHP8BmGHx5T0UOg,94
 determined/deploy/healthcheck.py,sha256=8d_YE6I17pndG9PWDBM1Gs3AKxHUzSUFixPExhFPdDM,1472
 determined/deploy/aws/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-determined/deploy/aws/aws.py,sha256=V8YNjk5h4Iv2k_Cf8oPlGxFv8jb6QOAZaua2JJAGXls,19015
+determined/deploy/aws/aws.py,sha256=8grVdGM2oNDCX1_XHddroQ4kLcla_wSqkLYiHRMbSTU,19597
 determined/deploy/aws/cli.py,sha256=QbWQYTtpLrfovyw6wPFcwaThk09aMYnXHx8sAkznaqA,24035
 determined/deploy/aws/constants.py,sha256=V5aOrV8SvW_ZrNZO4IvwGBB9L60FLELhtkSVR6io_1w,2998
 determined/deploy/aws/gen_vcpu_mapping.py,sha256=XmbbozPADD7RxXhEc1Nkyqm7cElpCgDM_hYo4HB3ezg,1420
 determined/deploy/aws/master_config_inject.py,sha256=_ISaZQIfvDsAyOeDzA7ssE40s6RA-7kMJxqgFiu4k3w,2201
 determined/deploy/aws/preflight.py,sha256=M5T-DYr_wkn2mSjHj2irjq80Br5ODKBmQ7_kTQ9ac1w,4911
 determined/deploy/aws/vcpu_mapping.yaml,sha256=czutxPBg3wIocgCYIKTiv1u8xZtH61hFFqiVig74tPM,17324
 determined/deploy/aws/deployment_types/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 determined/deploy/aws/deployment_types/base.py,sha256=4fv1ivcYs43L5qEcG99uiJmfMig4b4gyc7-uhuN1xos,5624
 determined/deploy/aws/deployment_types/govcloud.py,sha256=BjLMhQy9QreojfjBacO2Lg-g-fIVvq4cSDQc_HsDDC4,1593
 determined/deploy/aws/deployment_types/secure.py,sha256=E-EHO1PnlZoi4dXf17PLhSE18ceRjPklTf__2PsHGgQ,3094
 determined/deploy/aws/deployment_types/simple.py,sha256=tNzqZyyWSjkHaAi8OHJJ10B6wTHN4SclOwrx3RHv4BY,1349
 determined/deploy/aws/deployment_types/vpc.py,sha256=4k4pb8ehXO_INC88KMhvwPdqzOI3U4RQtyqpR8n5gRo,1400
 determined/deploy/aws/templates/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-determined/deploy/aws/templates/efs.yaml,sha256=TIoWxFfwYcnxc8s84u3vCSQX-WggaPhxmVk8rQ-HlAs,29259
-determined/deploy/aws/templates/fsx.yaml,sha256=HlzWMZqjPKiLh4JjPpePCxiobJvgyeTE8-Y_XjFcHXM,29969
-determined/deploy/aws/templates/govcloud.yaml,sha256=SZQ-ZSaUj0yYRsiE7UQlY2BeZDk6lod-dMpN7nE5WnA,23518
-determined/deploy/aws/templates/secure.yaml,sha256=IqueCVpqxIedbg6I4UnuRNooqIHxfyXaDMCVlJ4IMPM,29153
-determined/deploy/aws/templates/simple.yaml,sha256=QedUttnLTusjSDdHlUac6Jl7NR5ZYtZoPmT5OWF8sH8,24926
+determined/deploy/aws/templates/efs.yaml,sha256=gd861CdFFZ_stV6ZGeWSPhTTiSlduqXz9Du1IyEjC_o,29259
+determined/deploy/aws/templates/fsx.yaml,sha256=o0muOe8o3iY61t3Q80Q3vCRk1g5zNeYXlDb209mY28g,29969
+determined/deploy/aws/templates/govcloud.yaml,sha256=foU--C6mcb42b978zKHxAn67a-DASiybDYnmp8iZnbY,23518
+determined/deploy/aws/templates/secure.yaml,sha256=DDlQFnz_xW6WVlSnGWTBgPZJebopmGQ99HkFO0tZhOs,29153
+determined/deploy/aws/templates/simple.yaml,sha256=6rKha6knuDJa0sWR58b1oMOWb8Jmc8yhS61FKibh1uo,24926
 determined/deploy/gcp/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 determined/deploy/gcp/cli.py,sha256=Ww4a7FSRSDVFy8Qd01oqaZHG6O3BewOula9SqjcsyuU,19015
 determined/deploy/gcp/constants.py,sha256=yEVXwcPybx-R0F2Foj0DCcbAYmCZePKLn3avCP0PS4o,772
 determined/deploy/gcp/gcp.py,sha256=f_Z5roqcXDQzYFH5OZhHFB6bzdkrAAwpZFCcSSQYiXY,12420
 determined/deploy/gcp/preflight.py,sha256=pITWn2fxVKr154OVJA4iPnvYEnNuZVd03dPyaGDX8IM,2380
 determined/deploy/gcp/terraform/main.tf,sha256=5VaCs9G0Fc4U4ypATT_6Ra9tasz398XdrkhIYTdcDNk,5376
 determined/deploy/gcp/terraform/master.yaml.tmpl,sha256=YPrqZ5sJeX_TJ-T3TUR98ov9tX_lNBXhpghSXC-3zMY,1569
 determined/deploy/gcp/terraform/outputs.tf,sha256=eO9pEL4-BpY_-5Na8bErqbLyB0Sjj-ECq667xRgpZ2U,1487
 determined/deploy/gcp/terraform/variables.tf,sha256=Xm-2lKfIrIU-inYU1T-ti7l84mIfEv6Az5B3duIXkuE,3767
-determined/deploy/gcp/terraform/modules/compute/main.tf,sha256=zaN9yYlZmGwB_KRHoFrAwvlkXXXJfzzTdvlS1PcOEMc,6105
+determined/deploy/gcp/terraform/modules/compute/main.tf,sha256=IQ_A8vbnqfHAWcxYw-wiHmxh8bbbScQNzVQrEpfHotY,6122
 determined/deploy/gcp/terraform/modules/compute/outputs.tf,sha256=EIzZvOVIklr8unbZ25oJi4dIwWWK1LARHLtd_1Wgt-4,424
 determined/deploy/gcp/terraform/modules/compute/variables.tf,sha256=cDoNqUvbrvEIf_QTm7y9Ovp7LkgHzUMq8JIB85XdCtA,1574
 determined/deploy/gcp/terraform/modules/database/main.tf,sha256=o0KjYPC-jUttHKwVHgZhOLEiP8EBIGW_MvEQao1KsBk,1222
 determined/deploy/gcp/terraform/modules/database/outputs.tf,sha256=NOIEX85hzj5-OSp0XIfq-rXQnzWKD7ybRDtGZ2MMF2o,283
 determined/deploy/gcp/terraform/modules/database/variables.tf,sha256=D-CjpKWsgfFe6Zak0ACbwyEgCjfrWXWUbyBEmfSigYs,320
 determined/deploy/gcp/terraform/modules/filestore/main.tf,sha256=gz8aoLKsmZrN_jzE9u_Hn33ckYJeXw5a8KnOFUHIHO0,522
 determined/deploy/gcp/terraform/modules/filestore/outputs.tf,sha256=ps5MKV64_Etro0cOgRJeFm73PYcoDuy0OYHoSvtrVjo,184
@@ -197,23 +197,23 @@
 determined/launch/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 determined/launch/deepspeed.py,sha256=DaE-9QbMp46e11SBJcxyVlYKLsEE7Yqhiet5vvPCO70,13720
 determined/launch/horovod.py,sha256=Grs-6CqjEj_zGJg1Sp7hN8asmlNb7520-555T9zOh6E,10813
 determined/launch/torch_distributed.py,sha256=k3ihiWJ-j5LJP60Ou7Uf3n9h8PVz-WNB6c1pKMMEx9E,4574
 determined/launch/wrap_rank.py,sha256=wuy2e9XsrXq7V7zxM8OhAyeCAEBsXOgtwnNXM5dgSbg,4502
 determined/layers/__init__.py,sha256=Uw66Sylnjbil07vwegIxDWruBXWS-Lt4l140vhwZB3U,98
 determined/layers/_workload_sequencer.py,sha256=TmEk2FR5UxjifQjz1UrD5m0aN6rpq8krWi63ChmFzcg,19401
-determined/pytorch/__init__.py,sha256=4AMCoAmNgHAFiV6f0CHfjpDViVFv41Oc1cg2HZa53Ds,1134
+determined/pytorch/__init__.py,sha256=eEZgClUTL6fp2TjpicSY6cglvGcKIdktPTv2jsWn7ug,1151
 determined/pytorch/_callback.py,sha256=h_gsiuGQ3BQ4wEgoBY2ICEO7mSV4x7WKsHJnbMMtjbU,5459
 determined/pytorch/_data.py,sha256=HBBR7xDSD8glVN6W3FufHevD_Z5c8i98J4Kr_pg9308,16294
 determined/pytorch/_experimental.py,sha256=alOckCDugmP_Q-YoKtedE9RwhZI1ud1G-63HpFEeStw,3670
 determined/pytorch/_load.py,sha256=_7H3faSeduUAgWuQe_ZHaJIPD8H-yiN8Raf1XTs2_hU,12510
 determined/pytorch/_lr_scheduler.py,sha256=5mDlNPknOaa_U-R_AiXawcuJeKh0pbBu1ONtY4IK93I,3286
 determined/pytorch/_metric_utils.py,sha256=4LBvaec5GCLpPki8vmFerH8L0H6OriVUQDByiW_lPwY,8275
 determined/pytorch/_pytorch_context.py,sha256=cUTn2CkC9hVFUIiw6XYff1p9CAqeUa5Ca0GdlTuORbA,45136
-determined/pytorch/_pytorch_trial.py,sha256=_wl1GEVr8OnIA9wsdRapfKmVI9OnUJ16v1iYlFZysbE,67819
+determined/pytorch/_pytorch_trial.py,sha256=Erb1ANq128rqiWvho9sW-tE_a_Bv7SERcNnnTBqhIJM,68474
 determined/pytorch/_reducer.py,sha256=B24ubjL1rrQE-7Lp0ObDikShaO-eN5Dp_jp8Sc_kzRI,21406
 determined/pytorch/_trainer.py,sha256=jo5tXhOTX5JVcCZOajS6jUksW0gVk4l6OrfcFHmAgSQ,13510
 determined/pytorch/samplers.py,sha256=I4fU64xjwGi2PRGyznsqHe_QUmlWBHNsTVfe_2OzwDQ,9561
 determined/pytorch/deepspeed/__init__.py,sha256=loC0PUxi7Y21cFjeP3KFxV3omSaTpw4TwOQb1sTp0q8,347
 determined/pytorch/deepspeed/_deepspeed_context.py,sha256=peq9-vLRcmbQCkUNd3AekzRH7c_oj3OIg_Idc6w0cIk,17524
 determined/pytorch/deepspeed/_deepspeed_trial.py,sha256=xeeNOM8wRT4--uPP72ZHg5u2oyi2ljXVC1cNXALNqZo,42777
 determined/pytorch/deepspeed/_mpu.py,sha256=NFyfpLc12wv5HT13WlkN7uos-YgKu08px-ksycPuABE,1987
@@ -238,12 +238,12 @@
 determined/tensorboard/fetchers/gcs.py,sha256=TBCIKfdT6NsDiWRtWuo3NP-YKV2l6hf8zAVyOrFopWY,1733
 determined/tensorboard/fetchers/s3.py,sha256=8Vprb72laPQfPAwr48RMBCzei2IShcAsrQqYxxizTCA,2476
 determined/tensorboard/fetchers/shared.py,sha256=7p-l7hyCuViVaf4hiqxjBmB4Sxl3_F61ojFtaFmX3cc,1634
 determined/tensorboard/metric_writers/__init__.py,sha256=QBZlDYJslTPnllbOOwzbV_XtKlsLwf9SR8YcL3MdJtY,91
 determined/tensorboard/metric_writers/callback.py,sha256=pwNoskesXSRWaU7EimdhwEq0QP3HkkqgyCjrwd9Mc0g,2113
 determined/tensorboard/metric_writers/pytorch.py,sha256=dfEZRibe9Tkps768n_uLrYOWe8TOtrg9hfCsI2pKayc,2936
 determined/tensorboard/metric_writers/tensorflow.py,sha256=fQA1jtA6xCFEGoT5bf2YgZ4YBr9KbWRewfMOwTyCxh4,4385
-determined-0.22.1rc1.dist-info/METADATA,sha256=vcEwM82fbqlV1r5ZbWDOEdVcrrQiSBBTv-5kpX3FLmM,1262
-determined-0.22.1rc1.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-determined-0.22.1rc1.dist-info/entry_points.txt,sha256=77kPxwpCZJKt-eI0btTdFhbgHTB1vYCIeaxnrbu9cPg,53
-determined-0.22.1rc1.dist-info/top_level.txt,sha256=6KMmvfzgIXKT6XhfIA5qmqlIv8-Yk90UBTekhDjhk0U,11
-determined-0.22.1rc1.dist-info/RECORD,,
+determined-0.22.2rc0.dist-info/METADATA,sha256=jF8eDmAaAqruzfZ23hxAumnubRApnrqMpEaLhuWTDPM,1262
+determined-0.22.2rc0.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+determined-0.22.2rc0.dist-info/entry_points.txt,sha256=77kPxwpCZJKt-eI0btTdFhbgHTB1vYCIeaxnrbu9cPg,53
+determined-0.22.2rc0.dist-info/top_level.txt,sha256=6KMmvfzgIXKT6XhfIA5qmqlIv8-Yk90UBTekhDjhk0U,11
+determined-0.22.2rc0.dist-info/RECORD,,
```

