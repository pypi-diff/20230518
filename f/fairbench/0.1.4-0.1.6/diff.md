# Comparing `tmp/fairbench-0.1.4-py3-none-any.whl.zip` & `tmp/fairbench-0.1.6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,34 +1,34 @@
-Zip file size: 21479 bytes, number of entries: 32
+Zip file size: 22091 bytes, number of entries: 32
 -rw-rw-rw-  2.0 fat      196 b- defN 23-May-14 10:32 fairbench/__init__.py
 -rw-rw-rw-  2.0 fat      512 b- defN 23-Jan-15 16:07 fairbench/accumulate.py
 -rw-rw-rw-  2.0 fat     1790 b- defN 23-Jan-15 16:07 fairbench/algorithms.py
 -rw-rw-rw-  2.0 fat     1817 b- defN 23-Jan-19 20:24 fairbench/export.py
--rw-rw-rw-  2.0 fat     9339 b- defN 23-Jan-14 23:06 fairbench/fork.py
+-rw-rw-rw-  2.0 fat     9339 b- defN 23-May-17 23:49 fairbench/fork.py
 -rw-rw-rw-  2.0 fat     1744 b- defN 23-Jan-15 16:07 fairbench/output.py
 -rw-rw-rw-  2.0 fat     2393 b- defN 23-Jan-15 16:07 fairbench/reduction.py
 -rw-rw-rw-  2.0 fat     1146 b- defN 23-Jan-15 16:07 fairbench/reporting.py
 -rw-rw-rw-  2.0 fat       38 b- defN 23-May-14 10:33 fairbench/bench/__init__.py
--rw-rw-rw-  2.0 fat      565 b- defN 23-May-14 10:59 fairbench/bench/loader.py
+-rw-rw-rw-  2.0 fat      583 b- defN 23-May-14 15:09 fairbench/bench/loader.py
 -rw-rw-rw-  2.0 fat      122 b- defN 23-May-13 22:58 fairbench/forks/__init__.py
--rw-rw-rw-  2.0 fat     1414 b- defN 23-May-14 12:09 fairbench/forks/categorical.py
--rw-rw-rw-  2.0 fat     1903 b- defN 23-May-14 02:18 fairbench/forks/explanation.py
--rw-rw-rw-  2.0 fat    16297 b- defN 23-May-14 13:50 fairbench/forks/fork.py
+-rw-rw-rw-  2.0 fat     1507 b- defN 23-May-14 15:09 fairbench/forks/categorical.py
+-rw-rw-rw-  2.0 fat     1903 b- defN 23-May-17 23:49 fairbench/forks/explanation.py
+-rw-rw-rw-  2.0 fat    20783 b- defN 23-May-18 01:16 fairbench/forks/fork.py
 -rw-rw-rw-  2.0 fat      154 b- defN 23-Jan-14 23:08 fairbench/metrics/__init__.py
--rw-rw-rw-  2.0 fat     1816 b- defN 23-Jan-19 20:21 fairbench/metrics/classification.py
+-rw-rw-rw-  2.0 fat     1816 b- defN 23-May-15 14:34 fairbench/metrics/classification.py
 -rw-rw-rw-  2.0 fat     2007 b- defN 23-Jan-15 16:07 fairbench/metrics/disparate_impact.py
 -rw-rw-rw-  2.0 fat     1450 b- defN 23-Jan-15 16:07 fairbench/metrics/disparate_mistreatment.py
 -rw-rw-rw-  2.0 fat      207 b- defN 23-Jan-15 14:06 fairbench/reports/__init__.py
--rw-rw-rw-  2.0 fat      753 b- defN 23-Jan-15 17:03 fairbench/reports/accumulate.py
--rw-rw-rw-  2.0 fat     1630 b- defN 23-May-14 03:42 fairbench/reports/adhoc.py
+-rw-rw-rw-  2.0 fat     1240 b- defN 23-May-18 00:41 fairbench/reports/accumulate.py
+-rw-rw-rw-  2.0 fat     1630 b- defN 23-May-17 23:49 fairbench/reports/adhoc.py
 -rw-rw-rw-  2.0 fat     1411 b- defN 23-Jan-15 17:07 fairbench/reports/base.py
--rw-rw-rw-  2.0 fat     4980 b- defN 23-Jan-15 17:07 fairbench/reports/reduction.py
--rw-rw-rw-  2.0 fat      875 b- defN 23-May-14 03:44 fairbench/reports/surrogate.py
+-rw-rw-rw-  2.0 fat     4980 b- defN 23-May-17 23:49 fairbench/reports/reduction.py
+-rw-rw-rw-  2.0 fat      883 b- defN 23-May-14 15:09 fairbench/reports/surrogate.py
 -rw-rw-rw-  2.0 fat      155 b- defN 23-Feb-20 08:42 fairbench/reports/reduction/__init__.py
--rw-rw-rw-  2.0 fat      856 b- defN 23-Feb-20 08:37 fairbench/reports/reduction/expanders.py
--rw-rw-rw-  2.0 fat     1587 b- defN 23-Feb-20 08:42 fairbench/reports/reduction/reduce.py
+-rw-rw-rw-  2.0 fat      856 b- defN 23-May-14 19:29 fairbench/reports/reduction/expanders.py
+-rw-rw-rw-  2.0 fat     1587 b- defN 23-May-17 23:49 fairbench/reports/reduction/reduce.py
 -rw-rw-rw-  2.0 fat     2604 b- defN 23-Feb-20 08:40 fairbench/reports/reduction/reducers.py
--rw-rw-rw-  2.0 fat      784 b- defN 23-May-14 15:08 fairbench-0.1.4.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-May-14 15:08 fairbench-0.1.4.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       10 b- defN 23-May-14 15:08 fairbench-0.1.4.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     2688 b- defN 23-May-14 15:08 fairbench-0.1.4.dist-info/RECORD
-32 files, 63335 bytes uncompressed, 17157 bytes compressed:  72.9%
+-rw-rw-rw-  2.0 fat      786 b- defN 23-May-18 01:42 fairbench-0.1.6.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-May-18 01:42 fairbench-0.1.6.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       10 b- defN 23-May-18 01:42 fairbench-0.1.6.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     2689 b- defN 23-May-18 01:42 fairbench-0.1.6.dist-info/RECORD
+32 files, 68430 bytes uncompressed, 17769 bytes compressed:  74.0%
```

## zipnote {}

```diff
@@ -78,20 +78,20 @@
 
 Filename: fairbench/reports/reduction/reduce.py
 Comment: 
 
 Filename: fairbench/reports/reduction/reducers.py
 Comment: 
 
-Filename: fairbench-0.1.4.dist-info/METADATA
+Filename: fairbench-0.1.6.dist-info/METADATA
 Comment: 
 
-Filename: fairbench-0.1.4.dist-info/WHEEL
+Filename: fairbench-0.1.6.dist-info/WHEEL
 Comment: 
 
-Filename: fairbench-0.1.4.dist-info/top_level.txt
+Filename: fairbench-0.1.6.dist-info/top_level.txt
 Comment: 
 
-Filename: fairbench-0.1.4.dist-info/RECORD
+Filename: fairbench-0.1.6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## fairbench/fork.py

```diff
@@ -288,22 +288,22 @@
 def call(obj, method, *args, **kwargs):
     if callable(method):
         return method(obj, *args, **kwargs)
     return getattr(obj, method)(*args, **kwargs)
 
 
 """
-def compare(**kwargs):
-    for modal in kwargs.values():
+def compare(**todict):
+    for modal in todict.values():
         assert isinstance(modal, Modal)
     branches = set(
         [
             branch
-            for arg in list(kwargs.values())
+            for arg in list(todict.values())
             if isinstance(arg, Modal)
             for branch in arg.branches
         ]
     )
     return Modal(
-        **{branch: {key: kwargs[key].branches[branch] for key in kwargs} for branch in branches}
+        **{branch: {key: todict[key].branches[branch] for key in todict} for branch in branches}
     )
 """
```

## fairbench/bench/loader.py

```diff
@@ -1,16 +1,18 @@
 import os, wget
 import pandas as pd
 
 
 def read_csv(uci, *args, **kwargs):
     path = "data/" + uci.replace("\\", "/")
     if not os.path.exists(path):
-        url = "https://archive.ics.uci.edu/ml/machine-learning-databases/"+uci
+        url = "https://archive.ics.uci.edu/ml/machine-learning-databases/" + uci
         os.makedirs("/".join(path.split("/")[:-1]), exist_ok=True)
         wget.download(url, path)
     return pd.read_csv(path, *args, **kwargs)
 
 
 def features(df, numeric, categorical):
-    dfs = [df[col] for col in numeric] + [pd.get_dummies(df[col]) for col in categorical]
+    dfs = [df[col] for col in numeric] + [
+        pd.get_dummies(df[col]) for col in categorical
+    ]
     return pd.concat(dfs, axis=1).values
```

## fairbench/forks/categorical.py

```diff
@@ -3,47 +3,56 @@
 
 
 class Categorical(dict):
     def __and__(self, other):
         ret = Categorical()
         for k, v in self.items():
             for k2, v2 in other.items():
-                ret[k+"&"+k2] = v*v2
+                ret[k + "&" + k2] = v * v2
         return ret
 
     def __or__(self, other):
         ret = Categorical()
         for k, v in self.items():
             ret[k] = v
         for k, v in other.items():
             assert k not in ret
             ret[k] = v
         return ret
 
     def __repr__(self):
-        return "Categorical: "+super().__repr__()
+        return "Categorical: " + super().__repr__()
 
 
 class Transform:
     def __init__(self, method):
         self._method = method
 
     def __matmul__(self, other):
         ret = self._method(other)
         assert isinstance(ret, dict)  # sanity check to avoid errors later on
-        return Categorical(ret)  # the Categorical is unfolded by Fork constructors (native dicts are not)
-
-    def __call__(self, other):  # allow traditional call in case someone finds it easier to read
+        return Categorical(
+            ret
+        )  # the Categorical is unfolded by Fork constructors (native dicts are not)
+
+    def __call__(
+        self, other
+    ):  # allow traditional call in case someone finds it easier to read
         return self.__matmul__(other)
 
 
 @Transform
 def binary(x):
     x = tobackend(x)
-    return {"1": x, "0": 1-x}
+    return {"1": x, "0": 1 - x}
 
 
 @Transform
 def categories(x):
     assert isinstance(x, Iterable)
     vals = list(set(x))
-    return {str(val.numpy()) if istensor(val) else str(val): tobackend([1 if val == xval else 0 for xval in x]) for val in vals}
+    return {
+        str(val.numpy())
+        if istensor(val)
+        else str(val): tobackend([1 if val == xval else 0 for xval in x])
+        for val in vals
+    }
```

## fairbench/forks/explanation.py

```diff
@@ -19,15 +19,15 @@
             not isinstance(value, float)
             and not isinstance(value, int)
             and "tensor" not in value.__class__.__name__.lower()
             and "array" not in value.__class__.__name__
         ):
             raise Exception("Can not set non-numeric as explainable", value)
         if explain is not None and kwargs:
-            raise Exception("Cannot create explainable with both kwargs and a Fork")
+            raise Exception("Cannot create explainable with both todict and a Fork")
 
     def __float__(self):
         return tofloat(self.value)
 
     def numpy(self):
         return self.value.numpy()
```

## fairbench/forks/fork.py

```diff
@@ -1,16 +1,32 @@
 from makefun import wraps
 import eagerpy as ep
 import numpy as np
 import inspect
 import sys
+from collections.abc import Mapping
 
 _backend = "numpy"
 
 
+class Forklike(dict):
+    def __getattribute__(self, name):
+        if name in dir(Fork):
+            return object.__getattribute__(self, name)
+        return self[name]
+
+
+def _result(ret):
+    if ret.__class__.__name__ == "Future":
+        ret = ret.result()
+    if isinstance(ret, dict):
+        return Forklike(ret)
+    return ret
+
+
 def setbackend(backend_name: str):
     assert backend_name in ["torch", "tensorflow", "jax", "numpy"]
     global _backend
     _backend = backend_name
 
 
 def tobackend(value):
@@ -75,54 +91,61 @@
     # TODO: maybe applying this as a wrapper to methods instead of submitting to dask can be faster
     if isinstance(value, ep.Tensor):
         return value.raw
 
     return value
 
 
-class Fork(object):
+class Fork(Mapping):
     def __init__(self, *args, _prefix=True, **branches):
         for arg in args:
             if not isinstance(arg, dict):
                 raise TypeError(
                     "Forks can only support dicts (holding branch values) as positional arguments"
                 )
             for k, v in arg.items():
                 if k in branches:
                     raise TypeError(f"Branch {k} provided multiple times")
                 branches[k] = v
         self._branches = dict()
         for k, v in branches.items():
             if isinstance(v, dict) and v.__class__.__name__ == "Categorical":
                 for k2, v2 in v.items():
-                    self._branches[k+"="+k2 if _prefix else k2] = v2
+                    self._branches[k + "=" + k2 if _prefix else k2] = v2
             else:
                 self._branches[k] = v
 
     def __getattribute__(self, name):
         if name in ["_branches", "_repr_html_"] or name in dir(Fork):
             return object.__getattribute__(self, name)
-        if name.startswith('_'):
+        if name.startswith("_"):
             raise AttributeError(name)
         if name in self._branches:
             ret = self._branches[name]
-            if ret.__class__.__name__ == "Future":
-                ret = ret.result()
-            return ret
+            return _result(ret)
 
-        def method(*args, **kwargs):
-            return call(self, name, *args, **kwargs)
+        #def method(*args, **kwargs):
+        #    return call(self, name, *args, **kwargs)
+        #return method
 
-        return method
+        return Fork({k: v.__getattribute__(name) if isinstance(v, Fork) else call(v, "__getattribute__", name) for k, v in self._branches.items()})
+
+
+    def extract(self, *args):
+        import fairbench as fb
+        ret = dict()
+        for arg in args:
+            ret = ret | fb.todict(**{arg: self[arg]})
+        return ret
 
     def branches(self, branch_names=None, zero_mask=False):
         return {
-            branch: (value.result() if value.__class__.__name__ == "Future" else value)
+            branch: _result(value)
             if branch_names is None or not zero_mask or branch in branch_names
-            else (value.result() if value.__class__.__name__ == "Future" else value) * 0
+            else _result(value) * 0
             for branch, value in self._branches.items()
             if branch_names is None or zero_mask or branch in branch_names
         }
 
     def withcomplements(self):
         # find missing branch complements
         branches = self.branches()
@@ -170,14 +193,41 @@
             if astensor(new_mask).abs().sum() == 0:
                 continue
             new_branches[
                 (delimiter.join(candidates)) if len(candidates) > 1 else candidates[0]
             ] = new_mask
         return Fork(new_branches)
 
+    def __len__(self):
+        keys = None
+        for k, v in self.branches().items():
+            assert isinstance(v, dict)
+            v_keys = set(v.keys())
+            if keys is None:
+                keys = v_keys
+            else:
+                assert len(v_keys-keys) == 0
+                assert len(keys-v_keys) == 0
+        return len(keys)
+
+    def __iter__(self):
+        keys = None
+        for k, v in self.branches().items():
+            assert isinstance(v, dict)
+            v_keys = set(v.keys())
+            if keys is None:
+                keys = v_keys
+            else:
+                assert len(v_keys-keys) == 0
+                assert len(keys-v_keys) == 0
+        return keys.__iter__()
+
+    def __delitem__(self, name):
+        return call(self, "__delitem__", name)
+
     def __getitem__(self, name):
         return call(self, "__getitem__", name)
 
     def __setitem__(self, name, value):
         return call(self, "__setitem__", name, value)
 
     def __abs__(self):
@@ -229,30 +279,37 @@
 
     def __str__(self):
         return "\n".join(
             k + ": " + str(fromtensor(v)) for k, v in self.branches().items()
         )
 
     def __repr__(self):
-        #from IPython.display import display_html, HTML
-        #display_html(HTML(self.__repr_html__()))
+        # from IPython.display import display_html, HTML
+        # display_html(HTML(self.__repr_html__()))
         return super().__repr__()
 
     def _repr_html_(self):
         return self.__repr_html__()
 
     def __repr_html__(self, override=None):
-        if override is not None and not isinstance(override, dict) and not isinstance(override, Fork):
+        if (
+            override is not None
+            and not isinstance(override, dict)
+            and not isinstance(override, Fork)
+        ):
             return override
 
-        complex_contents = any(isinstance(v, dict) for k, v in (self.branches() if override is None else override).items())
+        complex_contents = any(
+            isinstance(v, dict)
+            for k, v in (self.branches() if override is None else override).items()
+        )
         if complex_contents:
             html = ""
             for k, v in (self.branches() if override is None else override).items():
-                html += "<div style=\"display: inline-block; float: left;\">"
+                html += '<div style="display: inline-block; float: left;">'
                 html += "<h3>{}</h3>".format(k)
                 html += "{}".format(self.__repr_html__(v))
                 html += "</div>"
             return html
 
         html = "<table>"
         for k, v in (self.branches() if override is None else override).items():
@@ -372,14 +429,92 @@
             return Fork(**submitted)
         except KeyError as e:
             raise KeyError(str(e) + " not provided for an input")
 
     return wrapper
 
 
+def forks(method):
+    def wrapper(*args, **kwargs):
+        branches = set(
+            [
+                branch
+                for arg in list(args) + list(kwargs.values())
+                if isinstance(arg, Fork)
+                for branch in arg._branches
+            ]
+        )
+        if not branches:
+            return fromtensor(
+                method(
+                    *(astensor(arg) for arg in args),
+                    **{key: astensor(arg) for key, arg in kwargs.items()},
+                )
+            )
+        args = [
+            arg
+            if isinstance(arg, Fork)
+            else Fork(**{branch: arg for branch in branches})
+            for arg in args
+        ]
+        kwargs = {
+            key: arg
+            if isinstance(arg, Fork)
+            else Fork(**{branch: arg for branch in branches})
+            for key, arg in kwargs.items()
+        }
+        try:
+            argnames = inspect.getfullargspec(method)[0]
+            if "branch" not in kwargs and "branch" in argnames:
+                kwargs["branch"] = None
+            submitted = {
+                branch: _client.submit(
+                    fromtensor,
+                    _client.submit(
+                        method,
+                        *(
+                            _client.submit(
+                                astensor,
+                                arg._branches[branch],
+                                workers=branch,
+                                allow_other_workers=True,
+                                pure=False,
+                            )
+                            for arg in args
+                        ),
+                        **{
+                            key: branch
+                            if key == "branch"
+                            else _client.submit(
+                                astensor,
+                                arg._branches[branch],
+                                workers=branch,
+                                allow_other_workers=True,
+                                pure=False,
+                            )
+                            for key, arg in kwargs.items()
+                        },
+                        workers=branch,
+                        allow_other_workers=True,
+                        pure=False,
+                    ),
+                    workers=branch,
+                    allow_other_workers=True,
+                    pure=False,
+                )
+                for branch in branches
+            }
+            submitted = {branch: value for branch, value in submitted.items()}
+            return Fork(**submitted)
+        except KeyError as e:
+            raise KeyError(str(e) + " not provided for an input")
+
+    return wrapper
+
+
 def parallel_primitive(method):
     @wraps(method)
     def wrapper(*args, **kwargs):
         branches = set(
             [
                 branch
                 for arg in list(args) + list(kwargs.values())
@@ -472,28 +607,34 @@
         assert isinstance(arg, Fork)
         ret |= arg._branches
     return Fork(ret)
 
 
 @parallel_primitive
 def call(obj, method, *args, **kwargs):
+    if method == "__getattribute__" and isinstance(obj, dict) and len(args) == 1 and len(kwargs) == 0:
+        return obj[args[0]]
     if callable(method):
         return method(obj, *args, **kwargs)
-    return getattr(obj, method)(*args, **kwargs)
+    attr = getattr(obj, method)
+    if not callable(attr):
+        return attr
+    return attr(*args, **kwargs)
+
 
 
 """
-def compare(**kwargs):
-    for modal in kwargs.values():
+def compare(**todict):
+    for modal in todict.values():
         assert isinstance(modal, Modal)
     branches = set(
         [
             branch
-            for arg in list(kwargs.values())
+            for arg in list(todict.values())
             if isinstance(arg, Modal)
             for branch in arg.branches
         ]
     )
     return Modal(
-        **{branch: {key: kwargs[key].branches[branch] for key in kwargs} for branch in branches}
+        **{branch: {key: todict[key].branches[branch] for key in todict} for branch in branches}
     )
 """
```

## fairbench/reports/accumulate.py

```diff
@@ -1,28 +1,44 @@
-from fairbench.forks.fork import parallel, parallel_primitive
+from fairbench.forks.fork import parallel, parallel_primitive, astensor
 import eagerpy as ep
 
 
 """
 This module provides helper methods to concatenate tensors stored within Forks of tensor or Forks of dicts of tensors
 and use the final output in one report at the end.
 """
 
 
 @parallel_primitive
-def kwargs(**kwargs):
+def todict(**kwargs):
     if not kwargs:
         return None
     return kwargs
 
 
 @parallel_primitive
 def concatenate(*data):
     data = [d for d in data if d is not None]
     if len(data) == 1:
         return data[0]
     isdict = isinstance(data[0], dict)
     for d in data:
         assert isinstance(d, dict) == isdict
     if isdict:
-        return {k: ep.concatenate([d[k] for d in data]) for k in data[0]}
-    return ep.concatenate(data)
+        return {k: ep.concatenate([astensor(d[k]) for d in data]) for k in data[0]}
+    return ep.concatenate([astensor(d) for d in data])
+
+
+def extract(**kwargs):
+    ret = dict()
+    for k, v in kwargs.items():
+        try:
+            if callable(v):
+                v = v()  # TODO: this is a hack to supplement the fact that object members are returns as functions by getattr on Forks
+        except TypeError:
+            pass
+        try:
+            v = v[k]
+        except AttributeError:
+            pass
+        ret = ret | todict(**{k: v})
+    return ret
```

## fairbench/reports/adhoc.py

```diff
@@ -1,10 +1,10 @@
 from fairbench.reports.base import report, reportargsparse
 from fairbench.reports import reduction as fb
-from fairbench.reports.accumulate import kwargs as tokwargs
+from fairbench.reports.accumulate import todict as tokwargs
 from fairbench.forks.fork import combine
 from fairbench.reports.surrogate import surrogate_positives
 from fairbench import metrics
 
 
 common_metrics = (metrics.accuracy, metrics.prule, metrics.dfpr, metrics.dfnr)
 acc_metrics = (metrics.accuracy, metrics.pr, metrics.tpr, metrics.tnr)
```

## fairbench/reports/reduction.py

```diff
@@ -1,13 +1,13 @@
 from fairbench.forks.fork import Fork, astensor
 from typing import Iterable
 import eagerpy as ep
 from fairbench.forks.explanation import Explainable
 
-# from fairbench.reports.accumulate import kwargs as tokwargs
+# from fairbench.reports.accumulate import todict as tokwargs
 
 
 def abs(value):
     if value < 0:
         return -value
     return value
```

## fairbench/reports/surrogate.py

```diff
@@ -1,15 +1,17 @@
 from fairbench.reports import reduce, todata, identical
 from fairbench.forks.fork import Fork, multibranch_tensors
 from sklearn.linear_model import LogisticRegression
 import numpy as np
 
 
 @multibranch_tensors
-def surrogate_positives(predictions, sensitive, surrogate_model=LogisticRegression(max_iter=1000)):
+def surrogate_positives(
+    predictions, sensitive, surrogate_model=LogisticRegression(max_iter=1000)
+):
     predictions = np.round(reduce(predictions, identical, name=None).numpy())
     X = reduce(sensitive, todata, name=None).numpy()
     surrogate_model = surrogate_model.fit(X, predictions)
     prediction_branches = dict()
     for branches in sensitive.intersections():
         Xbranch = np.array(
             [[1 if branch in branches else 0 for branch in sensitive._branches]]
```

## fairbench/reports/reduction/reduce.py

```diff
@@ -1,11 +1,11 @@
 from fairbench.forks.fork import Fork, astensor
 from fairbench.forks.explanation import Explainable
 
-# from fairbench.reports.accumulate import kwargs as tokwargs
+# from fairbench.reports.accumulate import todict as tokwargs
 
 
 def reduce(fork: Fork, method, expand=None, transform=None, branches=None, name=""):
     if name == "":
         name = method.__name__
         if expand is not None:
             name += expand.__name__
```

## Comparing `fairbench-0.1.4.dist-info/METADATA` & `fairbench-0.1.6.dist-info/METADATA`

 * *Files 10% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 Metadata-Version: 2.1
 Name: fairbench
-Version: 0.1.4
+Version: 0.1.6
 Summary: Fairness model assessment framework
-Home-page: https://github.com/maniospas/FairBench
+Home-page: https://github.com/mever-team/FairBench
 Author: Emmanouil (Manios) Krasanakis
 Author-email: maniospas@hotmail.com
 License: UNKNOWN
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Operating System :: OS Independent
@@ -16,9 +16,9 @@
 Requires-Dist: distributed
 Requires-Dist: makefun
 Requires-Dist: matplotlib
 Requires-Dist: wget
 Requires-Dist: scikit-learn
 Requires-Dist: pandas
 
-For tutorials, documentation, and contribution guidelines, please visit the project's homepage at https://github.com/maniospas/FairBench
+For tutorials, documentation, and contribution guidelines, please visit the project's homepage at https://github.com/mever-team/FairBench
```

## Comparing `fairbench-0.1.4.dist-info/RECORD` & `fairbench-0.1.6.dist-info/RECORD`

 * *Files 20% similar despite different names*

```diff
@@ -1,32 +1,32 @@
 fairbench/__init__.py,sha256=0Q1JGj_lTF1FSPMwOo7_1yCBo1dQ410nADc80kiVL5c,196
 fairbench/accumulate.py,sha256=vyDGY-RTP-aX3ygiHc56WPefRFWQOCjg7KJ4kC3kwFg,512
 fairbench/algorithms.py,sha256=CF2WcAWQKKfNRJ4yvNqIjuNdLaCBrSIpI_XNhmfiUkY,1790
 fairbench/export.py,sha256=pDb_sUSzlGAXTMn0iHA4wktJQNyi5TtT_TvfGVmE5ok,1817
-fairbench/fork.py,sha256=tF1_So0QpF9EXUnJVppvY2FuE6kRNCVvNTEBvnGN6Lw,9339
+fairbench/fork.py,sha256=VAgJ6MeD5a6mK_BMrIJdXPxLpp7wz0wjTSy59IJOSJU,9339
 fairbench/output.py,sha256=wvusKkx72F9i0EZoWpM8vR3NYTkpJTc8rtj5oLTKkRA,1744
 fairbench/reduction.py,sha256=PkHMY4B8SuwwV7-dq_dQXW2bhx2tr8jQ7iAXy9kilVE,2393
 fairbench/reporting.py,sha256=jcZtJXjTQAstzTPMjcnQei053k_LUkVrA1oLVsfOIog,1146
 fairbench/bench/__init__.py,sha256=piA_S0SAZ96_-MxdcGO_V7pCKngOFBeAv8KGj9rkGRA,38
-fairbench/bench/loader.py,sha256=DNTEU0wYilF7phfUXoMFGE_T-nlDqtUpI4qm3ivkUY4,565
+fairbench/bench/loader.py,sha256=BXmttN9Ee-TA6FAb1gXMhlJutDN2B6XIea6TU0Cre14,583
 fairbench/forks/__init__.py,sha256=eBRDSxc31Pc1yKCc1VjFBvPMsBVaOzVOfXHpkYQodG0,122
-fairbench/forks/categorical.py,sha256=raJWPL17YigqwtQtIoAtUSvQujmv6PJnZ0ep5QdA5OQ,1414
-fairbench/forks/explanation.py,sha256=eh4QJGP2jPNdAVtynjwQmwJbtQMtyi2KXcjU0QujDsI,1903
-fairbench/forks/fork.py,sha256=KsFNdCyyQ0ETmX4yxdHpQlpsG7XqGbREmMzBpCbwhlw,16297
+fairbench/forks/categorical.py,sha256=zJeM53DiEDoV01dHjBlmhRH1dnMMjavFllSCxzZMy9I,1507
+fairbench/forks/explanation.py,sha256=rQjkNuemRDvjSp4R2Gw8Mv2o8-Fd_mrbrIM_v7opEY0,1903
+fairbench/forks/fork.py,sha256=vNLsLmXc83nkJtlNlfGr5RWx0CYx0Z2N1R5c8-STG7U,20783
 fairbench/metrics/__init__.py,sha256=i2kNaDKTfTSEh1aGZ83ByaVXwv0gYE-guFNjj9XlF6I,154
 fairbench/metrics/classification.py,sha256=263Wz5ILnq3OxyzPopLAM-tWszcsC2v1F6SSKqqDuVo,1816
 fairbench/metrics/disparate_impact.py,sha256=rLO82wWOSDI4s5aK9WjehIbuUrCLuog7pOV8SSBVEZI,2007
 fairbench/metrics/disparate_mistreatment.py,sha256=4xtayr0k5Z7ZAtlrFevDiUjQloJ6uhqPucgxPFrwES8,1450
 fairbench/reports/__init__.py,sha256=YQm7A6K3PUB4uNOw3iDu2RUaoWa07Rsn3GJr4wZkn2M,207
-fairbench/reports/accumulate.py,sha256=LsJZhRqzZdMztjVijEKOyBqMXRJGTY2FlpWFBPIQGMY,753
-fairbench/reports/adhoc.py,sha256=Umbq1QHVvbhKDTw1teCkCHAchNBbj6w9xAJzvbfCwP0,1630
+fairbench/reports/accumulate.py,sha256=u2uji30jXdgp1zejWBw8Lm1xT2rygDbpeeNZKhTeTI8,1240
+fairbench/reports/adhoc.py,sha256=wiQoxn5vnBoeB5EowZVXtxjWgGbTkVYQ07JPRa3MdTI,1630
 fairbench/reports/base.py,sha256=yM36cbXToi-LfKVWO1mG2So42fuRnSUqDTcBy1V0vQQ,1411
-fairbench/reports/reduction.py,sha256=Mfxz5TLZ11H2RUbhlEnxEPL8J9ICGGWnA--6GLULx1g,4980
-fairbench/reports/surrogate.py,sha256=AMeRFG9TViLU9oRK4uh4mLCfQVNL0Hn0EZ_r91TqaUQ,875
+fairbench/reports/reduction.py,sha256=zSo8Whi-tW8trPmN946e2gyLp6xR7b8WMZzYyPmWgIc,4980
+fairbench/reports/surrogate.py,sha256=LnV6kkNPMGL2SYEBSSIFWjkXQ8N5m2k4y5as2zUyDt8,883
 fairbench/reports/reduction/__init__.py,sha256=a3c0w4bKV3f6NXnGMPPGFRxdfg_YIrcccy_mEBSr8zk,155
 fairbench/reports/reduction/expanders.py,sha256=BR6R9VwcFjbPC8WROrrE823oGwcbjuTgXyKBWjwvs3o,856
-fairbench/reports/reduction/reduce.py,sha256=3fNGImdQq5DR2adqtZgtPTKNIiA8eP31bHtc4rvCMeM,1587
+fairbench/reports/reduction/reduce.py,sha256=rqV4n9P8THxgQPVvdXP1hetjr_w3KswyLlS9vpM7xJQ,1587
 fairbench/reports/reduction/reducers.py,sha256=5NA8FbXLieB9iV22aqPyOrpy7MZLtFviHiedxrMGMv0,2604
-fairbench-0.1.4.dist-info/METADATA,sha256=v4H3Qfulv8YcQrSHa0YrYGw53BPwlfcD5V87--ExCH4,784
-fairbench-0.1.4.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
-fairbench-0.1.4.dist-info/top_level.txt,sha256=V_xpM0npsVDF1PcMECNA-pE1JrkHNp3p62aiR-7iqDk,10
-fairbench-0.1.4.dist-info/RECORD,,
+fairbench-0.1.6.dist-info/METADATA,sha256=9vhbT1TNJDkypF7m-_91qt7lY7FBrM9DUMYdj-N_jF0,786
+fairbench-0.1.6.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
+fairbench-0.1.6.dist-info/top_level.txt,sha256=V_xpM0npsVDF1PcMECNA-pE1JrkHNp3p62aiR-7iqDk,10
+fairbench-0.1.6.dist-info/RECORD,,
```

